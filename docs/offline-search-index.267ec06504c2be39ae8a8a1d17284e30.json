












































































[{"body":"\nOverview This course introduces algorithms, statistical methods and data analysis programming routines relevant for genome biology. It consists of three main components: lectures, hands-on practicals and student course projects. The lecture topics cover databases, sequence (NGS) analysis, phylogenetics, comparative genomics, genome-wide profiling methods, network biology and more. The hands-on practicals include homework assignments and course projects focusing on data analysis programming of next generation genome data using command-line tools on a computer cluster and the programming environment R. Depending on student interests, one or more specialty topics may be included, such as the analysis of single cell (e.g. scRNA-Seq) experiments, multi-omics data, or the development of web-based analysis tools (e.g. Shiny Apps).\nWho should take this class? Students with a strong interest and motivation in acquiring the skills required for mastering the computational aspects of modern genome research. The class is mainly targeting graduate students but senior undergraduate students are welcome to enroll as well. The main audience of this class are usually students from bioscience, biomedical and bioengineering programs as well as CS and statistics students with interest in computational biology.\nCan I audit this class? It is possible to audit this class. However, due to the emphasis on active participation in practicals and course projects, students usually learn much more if they enroll into the class rather than auditing it in a passive manner.\n","categories":"","description":"","excerpt":"\nOverview This course introduces algorithms, statistical methods and …","ref":"/about/introduction/","tags":"","title":"Introduction"},{"body":"  GitHub in GEN242  Note, this class will make heavy use of GitHub Homework assignments will be submitted to private GitHub repositories: one repository for each student Course projects will also use private GitHub repositories: one repository for each course project (shared among students of each project) Each student will need a personal GitHub account. They can be created here. GitHub provides an unlimited number of free public repositories to each user. Via GitHub Education students can sign up for free private GitHub accounts (see here). All private GitHub accounts required for this class will be provided by the instructor via GitHub Classroom For beginners this quick guide may be useful  What are Git and GitHub?  Git is a distributed version control system similar to SVN GitHub is an online social coding service based on Git Combined Git/GitHub: environment for version control and social coding  Installing Git  Install on Windows, OS X and Linux When using it from RStudio, it needs to find the Git executable  Git Basics from Command-Line Also try interactive git tutorial.\n  Finding help from command-line\ngit \u003ccommand\u003e --help    Initialize a directory as a Git repository\ngit init    Add specific files to Git repository (staging area)\ngit add myfile    Add all files recursively\nTo ignore specific files (e.g. temp files), list them in a .gitignore file in your repository’s root directory. Regular expressions are supported. See here for more details.\ngit add -A :/    After editing file(s) in your repos, record a snapshot of the staging area\ngit commit -am \"some edits\"    GitHub Basics from Command-Line   Generate a new remote repository on GitHub online or use hub command-line wrapper for this. To avoid errors with the online method, do not initialize the new repository with README, license, or .gitignore files. You can add these files after your project has been pushed to GitHub.\ngit remote add origin https://github.com/\u003cuser_name\u003e/\u003crepos_name\u003e.git    Push updates to remote. Next time one can just use git push\ngit push -u origin master    Clone existing remote repository\ngit clone https://github.com/\u003cuser_name\u003e/\u003crepos_name\u003e.git    Before working on project, update local git repos\ngit pull    Make changes and recommit local to remote\ngit commit -am \"some edits\"; git push -u origin master    Exercise Run the following git/github excercise from the command-line.\ngit clone https://github.com/\u003cuser or org\u003e/\u003crepo name\u003e cd \u003crepo name\u003e git pull touch test # Creates empty file for testing git add -A git commit -am \"some edits\" git push -u origin master ##-\u003e Edit test file online and then run `git pull` to inspect changes  Online file upload This could be useful for new users who want to upload their homework assignments to GitHub but are not familiar enough with the command-line yet.\n Press Create new file button on your repository. Under the file path window add required subdirectory structure and a dummy file name (e.g. Homework/HW1/dummy.txt) After this press Upload files and upload any file (e.g. homework) to the newly create directory. After this the initial dummy file can be deleted. The latter is necessary since empty directories are not visible on GitHub.  Using GitHub from RStudio   After installing Git (see here), set path to Git executable in Rstudio:\n Tools \u003e Global Options \u003e Git/SVN    If needed, log in to GitHub account and create repository. Use option Initialize this repository with a README.\n  Clone repository by copying \u0026 pasting URL from repository into RStudio’s ‘Clone Git Repository’ window:\n File \u003e New Project \u003e Version Control \u003e Git \u003e Provide URL    Now do some work (e.g. add an R script), commit and push changes as follows:\n Tools \u003e Version Control \u003e Commit    Check files in staging area and press Commit Button\n  To commit changes to GitHub, press Push Button\n  Shortcuts to automate above routines are here\n  To resolve password issues, follow instructions here.\n  ","categories":"","description":"","excerpt":"  GitHub in GEN242  Note, this class will make heavy use of GitHub …","ref":"/manuals/github/github/","tags":"","title":"GitHub Introduction"},{"body":"  GitHub in GEN242  Note, this class will make heavy use of GitHub Homework assignments will be submitted and graded on GitHub Classroom Course projects will also use private GitHub repositories: one repository for each course project (shared among students of each project) Each student will need a personal GitHub account. They can be created here. GitHub provides an unlimited number of free public repositories to each user. Via GitHub Education students can sign up for an extended number of free private GitHub accounts (see here). For beginners this quick guide may be useful  What are Git and GitHub?  Git is a version control system similar to SVN GitHub is an online social coding service based on Git Combined Git/GitHub: environment for version control and social coding  Installing Git  Install on Windows, OS X and Linux When using it from RStudio, it needs to find the Git executable  Git Basics from Command-Line Also try interactive git tutorial.\n  Finding help from command-line\ngit \u003ccommand\u003e --help    Initialize a directory as a Git repository\ngit init    Add specific files to Git repository (staging area)\ngit add myfile    Add all files recursively\nTo ignore specific files (e.g. temp files), list them in a .gitignore file in your repository’s root directory. Regular expressions are supported. See here for more details.\ngit add -A :/    After editing file(s) in your repos, record a snapshot of the staging area\ngit commit -am \"some edits\"    GitHub Basics from Command-Line   Generate a new remote repository on GitHub online or use hub or GitHub CLI command-line wrappers for this. To avoid errors with the online method, do not initialize the new repository with README, license, or .gitignore files. You can add these files after your project has been pushed to GitHub.\ngit remote add origin https://github.com/\u003cuser_name\u003e/\u003crepos_name\u003e.git    Push updates to remote. Next time one can just use git push\ngit push -u origin master    Clone existing remote repository\ngit clone https://github.com/\u003cuser_name\u003e/\u003crepos_name\u003e.git    Before working on project, update local git repos\ngit pull    Make changes and recommit local to remote\ngit commit -am \"some edits\"; git push -u origin master    Exercise Run the following git/github excercise from the command-line. Do this after creating a GitHub repos according to the instructions above or online as outlined here.\ngit clone https://github.com/\u003cuser or org\u003e/\u003crepo name\u003e cd \u003crepo name\u003e git pull touch test # Creates empty file for testing git add test # or use '-A' for all git commit -am \"some edits\" git push ##-\u003e Edit test file online and then run `git pull` to inspect changes  Online file upload Useful for new users who want to upload their homework assignments to GitHub but are not familiar enough with the command-line yet.\n Press Add file button on your repository, and then Upload files. Under the file path window add required subdirectory structure and a dummy file name (e.g. Homework/HW1/dummy.txt) After this press Upload files and upload any file (e.g. homework) to the newly create directory. After this the initial dummy file can be deleted. The latter is necessary since empty directories are not visible on GitHub.  Using GitHub from RStudio   After installing Git (see here), set path to Git executable in Rstudio:\n Tools \u003e Global Options \u003e Git/SVN    If needed, log in to GitHub account and create repository. Use option Initialize this repository with a README.\n  Clone repository by copying \u0026 pasting URL from repository into RStudio’s ‘Clone Git Repository’ window:\n File \u003e New Project \u003e Version Control \u003e Git \u003e Provide URL    Now do some work (e.g. add an R script), commit and push changes as follows:\n Tools \u003e Version Control \u003e Commit    Check files in staging area and press Commit Button\n  To commit changes to GitHub, press Push Button\n  Shortcuts to automate above routines are here\n  To resolve password issues, follow instructions here.\n  ","categories":"","description":"","excerpt":"  GitHub in GEN242  Note, this class will make heavy use of GitHub …","ref":"/tutorials/github/github/","tags":"","title":"GitHub Introduction"},{"body":"Course title Data Analysis in Genome Biology GEN242 - Spring 2021\nPrintable syllabus See Google Doc version here.\nInstructor Name: Thomas Girke Email: thomas.girke@ucr.edu Office location: virtual via Zoom Office hour: Tue 4:30 - 5:30 PM \u0026 Fri 4:00 - 5:00 PM Zoom URL: privately shared\nTA Name: Le Zhang Email: le.zhang001@email.ucr.edu Office location: virtual via Zoom Office hour: Tue 11:00 - 12:00 PM Zoom URL: privately shared\nDescription Introduction to algorithms, statistical methods and data analysis programming routines relevant for genome biology. The class consists of three main components: lectures, hands-on practicals and student course projects. The lecture topics cover databases, sequence (NGS) analysis, phylogenetics, comparative genomics, genome-wide profiling methods, network biology and more. The hands-on practicals include homework assignments and course projects focusing on data analysis programming of next generation genome data using command-line tools on a computer cluster and the programming environment R. Credit: 4 units (2x 1.5 hours lectures, 1 hour discussion)\nObjectives of course  Acquire understanding of algorithms used in bioinformatics Obtain hands-on experience in large scale data analysis.  Prerequisites The main prerequisite for this course is a strong interest in acquiring the skills required for mastering the computational aspects of modern genome research.\nStructure of course Two lectures per week (1.5 hours each) plus one discussion section (1 hour). During the first weeks the discussion section will be used for data analysis tutorials using Linux command-line tools and R.\nTime Lecture: Tue/Thu 2:00-3:20 PM Discussion: Thu 3:30-4:20 PM\nLocation Online via video conferencing software\nGrading  Homework assignments: 40% Scientific paper presentation: 20% Course project presentations: 20% Final project report: 20%  Grading policy: Given the diverse educational background of the students in GEN242, all assignments are designed to be solvable by students from both experimental and quantitative disciplines, including those with no or only limited prior experience in programming and/or data modeling. The weight of each of the four gradable components in this class is given above in percent. (1) The homeworks include 8-10 assignments throughout the class. They cover algorithms and data analysis programming problems using the R language. The grading of these assignments is mainly based on correctness, reproducibility and reusability of the analysis code. (2-4) Students will work in groups of 3-5 members on a Challenge Project addressing a specific data analysis problem in genome data sciences. As part of their project, students will present a scientific paper (2) closely related to their project (see reading list for details). The results of the Challenge Projects (3) will be presented and discussed by each student at the end of the course. In addition, each student will write a detailed analysis report (4) of the assigned course project. The latter will be written in the style of a scientific publication and should include a detailed description of the results including all analysis code to fully reproduce the project results followed by a critical discussion of the outcomes. The grading of both the paper and project presentations (2-3) includes anonymous feedback from all students as well as the instructor, where understanding of the material, clarity of the oral presentations and critical thinking are the main grading criteria. The final project reports (4) will be graded by the instructor with an emphasis on scientific and coding accuracy, overall understanding of the topic, as well as reproducibility of the results.\nMaterials needed Students are expected to bring to each class meeting a laptop with a functional wireless connection and a recent internet browser version (e.g. Firefox, Chrome or Safari) preinstalled. Tablet computers with mobile operating systems are not suitable for running the required software. User accounts on a research computer cluster will be provided at the beginning of the course. To log in to the cluster, students also need to install a terminal application for their operating system (e.g. iTerm2 on OS X, and PuTTY or MobaXterm on Windows) as well as a file exchange software such as FileZilla. In addition, a recent version of R and RStudio should be installed on each laptop.\nIf possible students may want to attend class sessions from a monitor setup with either one large monitor (wide enough to display several windows) or two separate monitors. This allows simultaneous viewing of presentations on one screen and following along hands-on practicals on the other screen.\nSchedule Note: this schedule is from a previous offering of this class. The final schedule will be released during the first two weeks to include student suggestions.\n   Week Topic     Week 1 Course Introduction    Databases and Software for Genome Biology    Discussion: Introduction to Linux and HPC    Reading: A1, T1, T2   Week 2 Sequencing Technologies    Discussion: Introduction to R    Reading: A2-A4, T3   Week 3 Sequence Alignments and Searching    Multiple Sequence Alignments    Discussion: Programming in R    Reading: A5-A6, T4   Week 4 Short Read Alignment Algorithms    Discussion: Basics of NGS Analysis    Reading: A7-A10, T5   Week 5 Gene Expression Analysis using Microarrays and RNA-Seq    Discussion: NGS Workflow Overview; RNA-Seq Analysis    Reading: A11-A15, T6-T7   Week 6 Analysis of ChIP-Seq and VAR-Seq Experiments    Discussion: ChIP-Seq and VAR-Seq Analysis    Reading: A16-A18, T8-T9   Week 7 Students present publication related to their chosen course project    Discussion: Q\u0026A about papers    Reading: A19-A23   Week 8 Clustering algorithms    Pathway and GO annotation systems    Discussion: Gene Set Enrichment Analysis    Reading: A24-A26, T6 (Sec 3.14-3.15), T10   Week 9 Genome and Transcriptome Assembly Algorithms    Profile HMMs for Protein Family Modeling    Introduction to Phylogenetics    Discussion: Graphics and Data Visualization    Reading: A27-A29, T11   Week 10 Final presentations of student data analysis projects    Discussion: Tips and tricks for efficient data analysis programming    Reading: A30-A31, T3 (Sec 12,13-17)    Reading list Note: this reading list is from a previous offering of this class. The list will be finalized during the first two weeks to include student suggestions.\nJournal articles A1. Huber W, Carey VJ, Gentleman R, Anders S, Carlson M, Carvalho BS, Bravo HC, Davis S, Gatto L, Girke T, et al (2015) Orchestrating high-throughput genomic analysis with Bioconductor. Nat Methods 12: 115–121\nA2. Metzker, M. L., Jan 2010. Sequencing technologies - the next generation. Nat Rev Genet 11 (1), 31–46.\nA3. Needleman SB, Wunsch CD (1970) A general method applicable to the search for similarities in the amino acid sequence of two proteins. J Mol Biol 48, 443-453.\nA4. Smith TF, Waterman MS (1981) Identification of common molecular subsequences. J Mol Biol 147, 195-197.\nA5. Corpet F (1988) Multiple sequence alignment with hierarchical clustering. Nucleic Acids Res 16, 10881-90.\nA6. Altschul, S. F., Gish, W., Miller, W., Myers, E. W., Lipman, D. J., Oct 1990. Basic local alignment search tool. J Mol Biol 215 (3), 403–410.\nA7. Li, H, Durbin, R (2009) Fast and accurate short read alignment with Burrows-Wheeler transform. Bioinformatics, 25: 1754-1760.\nA8. Dobin, A., Davis, C.A., Schlesinger, F., Drenkow, J., Zaleski, C., Jha, S., Batut, P., Chaisson, M., Gingeras, T.R., 2012. STAR: ultrafast universal RNA-seq aligner. Bioinformatics 29, 15–21.\nA9. Langmead, B, Salzberg, S L (2012) Fast gapped-read alignment with Bowtie 2. Nat Methods, 9: 357-359.\nA10. Kim D, Langmead B, Salzberg SL (2015) HISAT: a fast spliced aligner with low memory requirements. Nat Methods 12: 357–360\nA11. Bray NL, Pimentel H, Melsted P, Pachter L (2016) Near-optimal probabilistic RNA-seq quantification. Nat Biotechnol. doi: 10.1038/nbt.3519\nA12. Love MI, Huber W, Anders S (2014) Moderated estimation of fold change and dispersion for RNA-seq data with DESeq2. Genome Biol 15: 550\nA13. Zhou X, Lindsay H, Robinson MD (2014) Robustly detecting differential expression in RNA sequencing data using observation weights. Nucleic Acids Res 42: e91\nA14. Anders, S, Reyes, A, Huber, W (2012) Detecting differential usage of exons from RNA-seq data. Genome Res, 22: 2008-2017.\nA15. Soneson, C, Delorenzi, M (2013) A comparison of methods for differential expression analysis of RNA-seq data. BMC Bioinformatics, 14: 91-91.\nA16. Zhang Y, Liu T, Meyer CA, Eeckhoute J, Johnson DS, Bernstein BE, Nussbaum C, Myers RM, Brown M, Li W, et al (2008) Model-based analysis of ChIP-Seq (MACS). Genome Biol. doi: 10.1186/gb-2008-9-9-r137\nA17. Wilbanks EG, Facciotti MT (2010) Evaluation of algorithm performance in ChIP-seq peak detection. PLoS One. doi: 10.1371/journal.pone.0011471.\nA18. Landt et al. (2012) ChIP-seq guidelines and practices of the ENCODE and modENCODE consortia. Genome Res, 22: 1813-1831.\nA19. McLeay, Robert C, and Timothy L Bailey. 2010. “Motif Enrichment Analysis: A Unified Framework and an Evaluation on ChIP Data.” BMC Bioinformatics 11: 165.\nA20. Machanick, P, Bailey, T L (2011) MEME-ChIP: motif analysis of large DNA datasets. Bioinformatics, 27: 1696-1697.\nA21. Tompa, M, N Li, T L Bailey, G M Church, B De Moor, E Eskin, A V Favorov, et al. 2005. “Assessing Computational Tools for the Discovery of Transcription Factor Binding Sites.” Nature Biotechnology 23 (1): 137–44.\nA22. DePristo MA, Banks E, Poplin R, Garimella KV, Maguire JR, Hartl C, Philippakis AA, del Angel G, Rivas MA, Hanna M, et al (2011) A framework for variation discovery and genotyping using next-generation DNA sequencing data. Nat Genet 43: 491–498.\nA23. Shihab HA, Rogers MF, Gough J, Mort M, Cooper DN, Day INM, Gaunt TR, Campbell C (2015) An integrative approach to predicting the functional effects of non-coding and coding sequence variation. Bioinformatics 31: 1536–1543.\nA24. Raymond JW, Blankley CJ, Willett P (2003) Comparison of chemical clustering methods using graph- and fingerprint-based similarity measures. J Mol Graph Model 21: 421–433.\nA25. Subramanian A, Tamayo P, Mootha VK, Mukherjee S, Ebert BL, Gillette MA, Paulovich A, Pomeroy SL, Golub TR, Lander ES, et al (2005) Gene set enrichment analysis: a knowledge-based approach for interpreting genome-wide expression profiles. Proc Natl Acad Sci U S A 102: 15545–15550.\nA26. Ashburner M, Ball CA, Blake JA, Botstein D, Butler H, Cherry JM, Davis AP, Dolinski K, Dwight SS, Eppig JT, et al (2000) Gene ontology: tool for the unification of biology. The Gene Ontology Consortium. Nat Genet 25: 25–29.\nA27. Zyla J, Marczyk M, Domaszewska T, Kaufmann SHE, Polanska J, Weiner J (2019) Gene set enrichment for reproducible science: comparison of CERNO and eight other algorithms. Bioinformatics 35: 5146–5154\nA28. Alkan, C, Sajjadian, S, Eichler, E E (2011) Limitations of next-generation genome sequence assembly. Nat Methods, 8: 61-65.\nA29. Eddy SR (1998) Profile hidden Markov models. Bioinformatics 14: 755–763.\nA30. Grabherr, M G, Haas, B J, Yassour, M, Levin, J Z, Thompson, D A, Amit, I, Adiconis, X, Fan, L, Raychowdhury, R, Zeng, Q, Chen, Z, Mauceli, E, Hacohen, N, Gnirke, A, Rhind, N, di Palma, F, Birren, B W, Nusbaum, C, Lindblad-Toh, K, Friedman, N, Regev, A (2011) Full-length transcriptome assembly from RNA-Seq data without a reference genome. Nat Biotechnol, 29: 644-652.\nA31. Zeitouni, B, Boeva, V, Janoueix-Lerosey, I, Loeillet, S, Legoix-ne, P, Nicolas, A, Delattre, O, Barillot, E (2010) SVDetect: a tool to identify genomic structural variations from paired-end and mate-pair sequencing data. Bioinformatics, 26: 1895-1896.\nA32. Ronquist F, Teslenko M, van der Mark P, Ayres DL, Darling A, Höhna S, Larget B, Liu L, Suchard MA, Huelsenbeck JP (2012) MrBayes 3.2: efficient Bayesian phylogenetic inference and model choice across a large model space. Syst Biol 61: 539–542.\nTutorials T1. GitHub Introduction\nT2. Introduction to Computer Clusters and Linux\nT3. Introduction to R\nT4. Programming in R\nT5. NGS Analysis Basics\nT6. NGS Workflows\nT7. RNA-Seq Workflow\nT8. ChIP-Seq Workflow\nT9. VAR-Seq Workflow\nT10. Unsupervised Learning\nT11. Data Visualization\nBooks Note: there is no need to purchase any books for this course as most reading material will be based on journal articles!\nGeneral Jonathan Pevsner (2009) Bioinformatics and Functional Genomics. Wiley-Blackwell; 2nd Edition, 992 pages.\nAlgorithms Jones N and Pevzner P (2004) An Introduction to Bioinformatics Algorithms. MIT Press, Massachusetts, 435 pages.\nSequence Analysis Durbin, R, Eddy, S, Krogh, A, Mitchison, G. (1998) Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids. Cambridge University Press, UK, 356 pages.\nParida L (2008) Pattern Discovery in Bioinformatics: Theory \u0026 Algorithms. CRC Press, London, 526 pages.\nProfiling Bioinformatics Gentleman, R, Carey, V, Dudoit, S, Irizarry, R, Huber, W (2005) Bioinformatics and Computational Biology Solutions Using R and Bioconductor. Springer, New York, 473 pages.\nPhylogenetics Felsenstein, J (2004) Inferring Phylogenies. Sinauer, Massachusetts, 664 pages.\nParadis (2006) Analysis of Phylogenetics and Evolution with R. Springer, New York, 211 pages.\n","categories":"","description":"","excerpt":"Course title Data Analysis in Genome Biology GEN242 - Spring 2021 …","ref":"/about/syllabus/","tags":"","title":"Syllabus - GEN242"},{"body":"  HPCC Cluster Overview The HPCC Cluster (formerly called biocluster) is a shared research computing system available at UCR. The HPCC website is available here.\nWhat Is a Computer Cluster?   A computer cluster is an assembly of CPU units, so called computer nodes that work together to perform many computations in parallel. To achieve this, an internal network (e.g. Infiniband interconnect) connects the nodes to a larger unit, while a head node controls the load and traffic across the entire system.\n  Usually, users log into the head node to submit their computer requests via srun to a queuing system provided by resource management and scheduling software, such as SGE, Slurm or TORQUE/MAUI. The queuing system distributes the processes to the computer nodes in a controlled fashion.\n  Because the head node controls the entire system, users should never run computing jobs on the head node directly!\n  For code testing purposes, one can log into one of the nodes with srun --pty bash -l and run jobs interactively. Alternatively, one can log into the test node owl via ssh.\n  Hardware Infrastructure Computer nodes  Over 4,500 CPU cores 48 AMD computer nodes, each with 64 CPU cores and 512GB RAM 40 Intel computer nodes, each with 32 CPU cores and 512GB RAM 6 high-memory nodes, each 32 CPU cores and 1024GB RAM 12 GPU nodes, each with 5,000 cuda cores  Interconnect  FDR IB @56Gbs  Storage  Parallel GPFS storage system with 2.1 PB usable space Backup of same architecture and similar amount  User traffic  Computing tasks need to be submitted via srun HPCC Cluster headnode only for login, not for computing tasks! Monitor cluster activity: squeue or jobMonitor (qstatMonitor)  Manuals  HPCC Cluster Manual Linux Manual  Linux Basics Log into HPCC Cluster  Login command on OS X or Linux  ssh -XY user@cluster.hpcc.ucr.edu  Type password\n  Windows: provide same information in a terminal application like Putty or MobaXterm.\n Host name: cluster.hpcc.ucr.edu User name: … Password: …    Important Linux Commands Finding help\nman \u003cprogram_name\u003e  List content of current directory\nls  Print current working directory\npwd  Search in files and directories\ngrep  Word count\nwc  Create directory\nmkdir  Delete files and directories\nrm  Move and rename files\nmv  Copy files from internet to pwd\nwget  Viewing files\nless  File Exchange GUI applications\n Windows: WinSCP Mac OS X: CyberDuck Win/OS X/Linux: FileZilla  SCP command-line tool\nscp file user@remotehost:/home/user/ # From local to remote scp user@remotehost:/home/user/file . # From remote to local  STD IN/OUT/ERR, Redirect \u0026 Wildcards Wildcard * to specify many files\nfile.*  Redirect ls output to file\nls \u003e file  Specify file as input to command\ncommand \u003c myfile  Append output of command to file\ncommand \u003e\u003e myfile  Pipe STDOUT of one command to another command\ncommand1 | command2  Turn off progress info\ncommand \u003e /dev/null  Pipe output of grep to wc\ngrep pattern file | wc  Print STDERR to file\ngrep pattern nonexistingfile 2 \u003e mystderr  Homework Assignment (HW2) See HW2 page here.\nPermissions and ownership List directories and files\nls -al  The previous command shows something like this for each file/dir: drwxrwxrwx. The meaning of this syntax is as follows:\n d: directory rwx: read, write and execute permissions, respectively  first triplet: user permissions (u) second triplet: group permissions (g) third triplet: world permissions (o)    Example for assigning write and execute permissions to user, group and world\nchmod ugo+rx my_file   + causes the permissions selected to be added - causes them to be removed = causes them to be the only permissions that the file has.  When performing the same operation on many files with subdirectories then one can use -R for recursive behavior.\nchmod -R ugo+rx my_dir  Since directories have to be executable the capital X option can be useful which applies only to directories but not to files. The following will assign drwxr-xr-x to directories and -rw-r--r-- to files and hidden files.\nchmod -R ugo-x,u+rwX,go+rX,go-w ./* ./.[!.]*  Syntax for changing user \u0026 group ownership\nchown \u003cuser\u003e:\u003cgroup\u003e \u003cfile or dir\u003e  Symbolic Links Symbolic links are short nicknames to files and directories that save typing of their full paths.\nln -s original_filename new_nickname  Software and module system  Over 750 software tools are currently installed on HPCC Cluster Most common research databases used in bioinformatics are available Support of most common programming languages used in research computing A module system is used to facilitate the management of software tools. This includes any number of versions of each software. New software install requests can be sent to support@hpcc.ucr.edu. To use software manged under the module system, users need to learn using some basic commands. The most common commands are listed below.  Print available modules\nmodule avail  Print available modules starting with R\nmodule avail R  Load default module R\nmodule load R  Load specific module R version\nmodule load R/3.2.2  List loaded modules\nmodule list  Unload module R\nmodule unload R  Unload specific module R\nmodule unload R/3.2.3-dev  Big data storage Each user account on HPCC Cluster comes only with 20GB of disk space. Much more disk space is available in a dedicated bigdata directory. How much space depends on the subscription of each user group. The path of bigdata and bigdata-shared is as follows:\n /bigdata/labname/username /bigdata/labname/shared  All lab members share the same bigdata pool. The course number gen242 is used as labname for user accounts adminstered under GEN242.\nThe disk usage of home and bigdata can be monitored on the HPCC Cluster Dashboard.\nQueuing system: Slurm HPCC Cluster uses Slurm as queuing and load balancing system. To control user traffic, any type of compute intensive jobs need to be submitted via the sbatch or srun (see below) to the computer nodes. Much more detailed information on this topic can be found on these sites:\n UCR HPCC Manual Slurm Documentation Torque/Slurm Comparison Switching from Torque to Slurm Slurm Quick Start Tutorial  Job submission with sbatch Print information about queues/partitions available on a cluster.\nsinfo  Compute jobs are submitted with sbatch via a submission script (here script_name.sh).\nsbatch script_name.sh  The following sample submission script (script_name.sh) executes an R script named my_script.R.\n#!/bin/bash -l #SBATCH --nodes=1 #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --mem-per-cpu=1G #SBATCH --time=1-00:15:00 # 1 day and 15 minutes #SBATCH --mail-user=useremail@address.com #SBATCH --mail-type=ALL #SBATCH --job-name=\"some_test\" #SBATCH -p batch # Choose queue/parition from: intel, batch, highmem, gpu, short Rscript my_script.R  Interactive session: logs user into node\nsrun --pty bash -l  Interactive session with specific resource requests\nsrun --x11 --partition=short --mem=2gb --cpus-per-task 4 --ntasks 1 --time 1:00:00 --pty bash -l  STDOUT and STDERROR of jobs will be written to files named slurm-\u003cjobid\u003e.out or to custom a file specified under #SBATCH --output in the submission script.\nMonitoring jobs with squeue List all jobs in queue\nsqueue  List jobs of a specific user\nsqueue -u \u003cuser\u003e  Print more detailed information about a job\nscontrol show job \u003cJOBID\u003e  Custom command to summarize and visualize cluster activity\njobMonitor  Deleting and altering jobs Delete a single job\nscancel -i \u003cJOBID\u003e  Delete all jobs of a user\nscancel -u \u003cusername\u003e  Delete all jobs of a certain name\nscancel --name \u003cmyJobName\u003e  Altering jobs with scontrol update. The below example changes the walltime (\u003cNEW_TIME\u003e) of a specific job (\u003cJOBID\u003e).\nscontrol update jobid=\u003cJOBID\u003e TimeLimit=\u003cNEW_TIME\u003e  Resource limits Resourse limits for users can be viewed as follows.\nsacctmgr show account $GROUP format=Account,User,Partition,GrpCPUs,GrpMem,GrpNodes --ass | grep $USER  Similarly, one can view the limits of the group a user belongs to.\nsacctmgr show account $GROUP format=Account,User,Partition,GrpCPUs,GrpMem,GrpNodes,GrpTRES%30 --ass | head -3  Text/code editors The following list includes examples of several widely used code editors.\n Vi/Vim/Neovim: Non-graphical (terminal-based) editor. Vi is guaranteed to be available on any system. Vim and Nvim (Neovim) are the improved versions of vi. Emacs: Non-graphical or window-based editor. You still need to know keystroke commands to use it. Installed on all Linux distributions and on most other Unix systems. Pico: Simple terminal-based editor available on most versions of Unix. Uses keystroke commands, but they are listed in logical fashion at bottom of screen. Nano: A simple terminal-based editor which is default on modern Debian systems. Atom: Modern text editor developed by GitHub project.  Why does it matter? To work efficiently on remote systems like a computer cluster, it is essential to learn how to work in a pure command-line interface. GUI environments like RStudio and similar coding environments are not suitable for this. In addition, there is a lot of value of knowing how to work in an environment that is not restricted to a specific programming language. Therefore, this class embraces RStudio where it is useful, but for working on remote systems like HPCC Cluster, it uses Nvim and Tmux. Both are useful for many programming languages. Combinded with the nvim-r plugin they also provide a powerful command-line working environment for R. The following provides a brief introduction to this environment.\nVim overview The following opens a file (here myfile) with nvim (or vim)\nnvim myfile.txt # for neovim (or 'vim myfile.txt' for vim)  Once you are in Nvim, there are three main modes: normal, insert and command mode. The most important commands for switching between the three modes are:\n i: The i key brings you from the normal mode to the insert mode. The latter is used for typing. Esc: The Esc key brings you from the insert mode back to the normal mode. :: The : key starts the command mode at the bottom of the screen.  Use the arrow keys to move your cursor in the text. Using Fn Up/Down key allows to page through the text quicker. In the following command overview, all commands starting with : need to be typed in the command mode. All other commands are typed in the normal mode after pushing the Esc key.\nImportant modifier keys to control vim/nvim\n :w: save changes to file. If you are in editing mode you have to hit Esc first. :q: quit file that has not been changed :wq: save and quit file :!q: quit file without saving any changes  Useful resources for learning vim/nvim  Interactive Vim Tutorial Official Vim Documentation HPCC Linux Manual  Nvim-R-Tmux essentials Terminal-based Working Environment for R: Nvim-R-Tmux.\n Nvim-R-Tmux IDE for R Basics Tmux is a terminal multiplexer that allows to split terminal windows and to detach/reattach to existing terminal sessions. Combinded with the nvim-r plugin it provides a powerful command-line working environment for R where users can send code from a script to the R console or command-line. Both tmux and the nvim-r plugin need to be installed on a system. On HPCC Cluster both are configured in each user account. If this is not the case then follow the quick configuration instructions given in the following subsection.\nQuick configuration in user accounts of UCR’s HPCC Skip these steps if Nvim-R-Tmux is already configured in your account. Or follow the detailed instructions to install Nvim-R-Tmux from scratch on your own system.\n Log in to your user account on HPCC and execute install_nvimRtmux. Alternatively, follow these step-by-step install commands. To enable the nvim-R-tmux environment, log out and in again. Follow usage instructions of next section.  Basic usage of Nvim-R-Tmux The official and much more detailed user manual for Nvim-R is available here. The following gives a short introduction into the basic usage of Nvim-R-Tmux:\n1. Start tmux session (optional)\nNote, running Nvim from within a tmux session is optional. Skip this step if tmux functionality is not required (e.g. reattaching to sessions on remote systems).\ntmux # starts a new tmux session tmux a # attaches to an existing session  2. Open nvim-connected R session\nOpen a *.R or *.Rmd file with nvim and intialize a connected R session with \\rf. This command can be remapped to other key combinations, e.g. uncommenting lines 10-12 in .config/nvim/init.vim will remap it to the F2 key. Note, the resulting split window among Nvim and R behaves like a split viewport in nvim or vim meaning the usage of Ctrl-w w followed by i and Esc is important for navigation.\nnvim myscript.R # or *.Rmd file  3. Send R code from nvim to the R pane\nSingle lines of code can be sent from nvim to the R console by pressing the space bar. To send several lines at once, one can select them in nvim’s visual mode and then hit the space bar. Please note, the default command for sending code lines in the nvim-r-plugin is \\l. This key binding has been remapped in the provided .config/nvim/init.vim file to the space bar. Most other key bindings (shortcuts) still start with the \\ as LocalLeader, e.g. \\rh opens the help for a function/object where the curser is located in nvim. More details on this are given below.\nImportant keybindings for nvim The main advantages of Neovim compared to Vim are its better performance and its built-in terminal emulator facilitating the communication among Neovim and interactive programming environments such as R. Since the Vim and Neovim environments are managed independently, one can run them in parallel on the same system without interfering with each other. The usage of Neovim is almost identical to Vim.\nNvim commands\n \\rf: opens vim-connected R session. If you do this the first time in your user account, you might be asked to create an R directory under ~/. If so approve this action by pressing y. spacebar: sends code from vim to R; here remapped in init.vim from default \\l :split or :vsplit: splits viewport (similar to pane split in tmux) gz: maximizes size of viewport in normal mode (similar to Tmux’s Ctrl-a z zoom utility) Ctrl-w w: jumps cursor to R viewport and back; toggle between insert (i) and command (Esc) mode is required for navigation and controlling the environment. Ctrl-w r: swaps viewports Ctrl-w =: resizes splits to equal size :resize \u003c+5 or -5\u003e: resizes height by specified value :vertical resize \u003c+5 or -5\u003e: resizes width by specified value Ctrl-w H or Ctrl-w K: toggles between horizontal/vertical splits Ctrl-spacebar: omni completion for R objects/functions when nvim is in insert mode. Note, this has been remapped in init.vim from difficult to type default Ctrl-x Ctrl-o. :h nvim-R: opens nvim-R’s user manual; navigation works the same as for any Vim/Nvim help document :Rhelp fct_name: opens help for a function from nvim’s command mode with text completion support Ctrl-s and Ctrl-x: freezes/unfreezes vim (some systems)  Important keybindings for tmux Pane-level commands\n Ctrl-a %: splits pane vertically Ctrl-a \": splits pane horizontally Ctrl-a o: jumps cursor to next pane Ctrl-a Ctrl-o: swaps panes Ctrl-a \u003cspace bar\u003e: rotates pane arrangement Ctrl-a Alt \u003cleft or right\u003e: resizes to left or right Ctrl-a Esc \u003cup or down\u003e: resizes to left or right  Window-level comands\n Ctrl-a n: switches to next tmux window Ctrl-a Ctrl-a: switches to previous tmux window Ctrl-a c: creates a new tmux window Ctrl-a 1: switches to specific tmux window selected by number  Session-level comands\n Ctrl-a d: detaches from current session Ctrl-a s: switch between available tmux sesssions $ tmux new -s \u003cname\u003e: starts new session with a specific name $ tmux ls: lists available tmux session(s) $ tmux attach -t \u003cid\u003e: attaches to specific tmux session $ tmux attach: reattaches to session $ tmux kill-session -t \u003cid\u003e: kills a specific tmux session Ctrl-a : kill-session: kills a session from tmux command mode that can be initiated with Ctrl-a :  Nvim IDEs for other languages For other languages, such as Bash, Python and Ruby, one can use the vimcmdline plugin for nvim (or vim). To install it, one needs to copy from the vimcmdline resository the directories ftplugin, plugin and syntax and their files to ~/.config/nvim/. For user accounts of UCR’s HPCC, the above install script install_nvimRtmux includes the install of vimcmdline (since 09-Jun-18).\nThe usage of vimcmdline is very similar to nvim-R. To start a connected terminal session, one opens with nvim a code file with the extension of a given language (e.g. *.sh for Bash or *.py for Python), while the corresponding interactive interpreter session is initiated by pressing the key sequence \\s (corresponds to \\rf under nvim-R). Subsequently, code lines can be sent with the space bar. More details are available here.\n","categories":"","description":"","excerpt":"  HPCC Cluster Overview The HPCC Cluster (formerly called biocluster) …","ref":"/manuals/linux/linux/","tags":"","title":"Introduction to HPCC Cluster and Linux"},{"body":"  HPCC Cluster Overview The HPCC Cluster (formerly called biocluster) is a shared research computing system available at UCR. The HPCC website is available here.\nWhat Is a Computer Cluster?   A computer cluster is an assembly of CPU units, so called computer nodes that work together to perform many computations in parallel. To achieve this, an internal network (e.g. Infiniband interconnect) connects the nodes to a larger unit, while a head node controls the load and traffic across the entire system.\n  Usually, users log into the head node to submit their computer requests via srun to a queuing system provided by resource management and scheduling software, such as SGE, Slurm or TORQUE/MAUI. The queuing system distributes the processes to the computer nodes in a controlled fashion.\n  Because the head node controls the entire system, users should never run computing jobs on the head node directly!\n  For code testing purposes, one can log into one of the nodes with srun --pty bash -l and run jobs interactively. Alternatively, one can log into the test node owl via ssh.\n  Hardware Infrastructure Computer nodes  Over 8,000 CPU cores 130 Intel, AMD and GPU nodes 32-128 CPU cores per node 256-1,024 GB of RAM per node 12 GPU nodes, each with total of over 80,000 cuda cores  Interconnect  FDR IB @56Gbs  Storage  Parallel GPFS storage system with 3.0 PB usable space File system scales to over 50 PB Backup of same architecture and similar amount  User traffic  Computing tasks need to be submitted via sbatch or srun HPCC Cluster headnode only for login, not for computing tasks! Monitor cluster activity: squeue or jobMonitor (qstatMonitor)  Manuals  HPCC Cluster Manual Linux Manual  Linux Basics Log into HPCC Cluster  Login command on OS X or Linux  ssh -XY user@cluster.hpcc.ucr.edu  Type password\n  Windows: provide same information in a terminal application like Putty or MobaXterm.\n Host name: cluster.hpcc.ucr.edu User name: … Password: …    Important Linux Commands Finding help\nman \u003cprogram_name\u003e  List content of current directory\nls  Print current working directory\npwd  Search in files and directories\ngrep  Word count\nwc  Create directory\nmkdir  Delete files and directories\nrm  Move and rename files\nmv  Copy files from internet to pwd\nwget  Viewing files\nless  File Exchange GUI applications\n Windows: WinSCP Mac OS X: CyberDuck Win/OS X/Linux: FileZilla  SCP command-line tool\nscp file user@remotehost:/home/user/ # From local to remote scp user@remotehost:/home/user/file . # From remote to local  STD IN/OUT/ERR, Redirect \u0026 Wildcards Wildcard * to specify many files\nfile.*  Redirect ls output to file\nls \u003e file  Specify file as input to command\ncommand \u003c myfile  Append output of command to file\ncommand \u003e\u003e myfile  Pipe STDOUT of one command to another command\ncommand1 | command2  Turn off progress info\ncommand \u003e /dev/null  Pipe output of grep to wc\ngrep pattern file | wc  Print STDERR to file\ngrep pattern nonexistingfile 2 \u003e mystderr  Homework Assignment (HW2) See HW2 page here.\nPermissions and ownership List directories and files\nls -al  The previous command shows something like this for each file/dir: drwxrwxrwx. The meaning of this syntax is as follows:\n d: directory rwx: read, write and execute permissions, respectively  first triplet: user permissions (u) second triplet: group permissions (g) third triplet: world permissions (o)    Example for assigning write and execute permissions to user, group and world\nchmod ugo+rx my_file   + causes the permissions selected to be added - causes them to be removed = causes them to be the only permissions that the file has.  When performing the same operation on many files with subdirectories then one can use -R for recursive behavior.\nchmod -R ugo+rx my_dir  Since directories have to be executable the capital X option can be useful which applies only to directories but not to files. The following will assign drwxr-xr-x to directories and -rw-r--r-- to files and hidden files.\nchmod -R ugo-x,u+rwX,go+rX,go-w ./* ./.[!.]*  Syntax for changing user \u0026 group ownership\nchown \u003cuser\u003e:\u003cgroup\u003e \u003cfile or dir\u003e  Symbolic Links Symbolic links are short nicknames to files and directories that save typing of their full paths.\nln -s original_filename new_nickname  Software and module system  Over 2,000 software tools are currently installed on HPCC Cluster Custom installs in user accounts via various mechanisms, e.g. environment management systems such as conda Most common research databases used in bioinformatics are available Support of most common programming languages used in research computing A module system is used to facilitate the management of software tools. This includes any number of versions of each software. New software install requests can be sent to support@hpcc.ucr.edu. To use software manged under the module system, users need to learn using some basic commands. The most common commands are listed below.  Print available modules\nmodule avail  Print available modules starting with R\nmodule avail R  Load default module R\nmodule load R  Load specific module R version\nmodule load R/3.2.2  List loaded modules\nmodule list  Unload module R\nmodule unload R  Unload specific module R\nmodule unload R/3.2.3-dev  Big data storage Each user account on HPCC Cluster comes only with 20GB of disk space. Much more disk space is available in a dedicated bigdata directory. How much space depends on the subscription of each user group. The path of bigdata and bigdata-shared is as follows:\n /bigdata/labname/username /bigdata/labname/shared  All lab members share the same bigdata pool. The course number gen242 is used as labname for user accounts adminstered under GEN242 (here /bigdata/gen242/shared).\nThe disk usage of home and bigdata can be monitored on the HPCC Cluster Dashboard.\nQueuing system: Slurm HPCC Cluster uses Slurm as queuing and load balancing system. To control user traffic, any type of compute intensive jobs need to be submitted via the sbatch or srun (see below) to the computer nodes. Much more detailed information on this topic can be found on these sites:\n UCR HPCC Manual Slurm Documentation Torque/Slurm Comparison Switching from Torque to Slurm Slurm Quick Start Tutorial  Job submission with sbatch Print information about queues/partitions available on a cluster.\nsinfo  Compute jobs are submitted with sbatch via a submission script (here script_name.sh).\nsbatch script_name.sh  The following sample submission script (script_name.sh) executes an R script named my_script.R.\n#!/bin/bash -l #SBATCH --nodes=1 #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --mem-per-cpu=1G #SBATCH --time=1-00:15:00 # 1 day and 15 minutes #SBATCH --mail-user=useremail@address.com #SBATCH --mail-type=ALL #SBATCH --job-name=\"some_test\" #SBATCH -p batch # Choose queue/parition from: intel, batch, highmem, gpu, short Rscript my_script.R  Interactive session: logs user into node\nsrun --pty bash -l  Interactive session with specific resource requests\nsrun --x11 --partition=short --mem=2gb --cpus-per-task 4 --ntasks 1 --time 1:00:00 --pty bash -l  STDOUT and STDERROR of jobs will be written to files named slurm-\u003cjobid\u003e.out or to custom a file specified under #SBATCH --output in the submission script.\nMonitoring jobs with squeue List all jobs in queue\nsqueue  List jobs of a specific user\nsqueue -u \u003cuser\u003e  Print more detailed information about a job\nscontrol show job \u003cJOBID\u003e  Custom command to summarize and visualize cluster activity\njobMonitor  Deleting and altering jobs Delete a single job\nscancel -i \u003cJOBID\u003e  Delete all jobs of a user\nscancel -u \u003cusername\u003e  Delete all jobs of a certain name\nscancel --name \u003cmyJobName\u003e  Altering jobs with scontrol update. The below example changes the walltime (\u003cNEW_TIME\u003e) of a specific job (\u003cJOBID\u003e).\nscontrol update jobid=\u003cJOBID\u003e TimeLimit=\u003cNEW_TIME\u003e  Resource limits Resourse limits for users can be viewed as follows.\nsacctmgr show account $GROUP format=Account,User,Partition,GrpCPUs,GrpMem,GrpNodes --ass | grep $USER  Similarly, one can view the limits of the group a user belongs to.\nsacctmgr show account $GROUP format=Account,User,Partition,GrpCPUs,GrpMem,GrpNodes,GrpTRES%30 --ass | head -3  Text/code editors The following list includes examples of several widely used code editors.\n Vi/Vim/Neovim: Non-graphical (terminal-based) editor. Vi is guaranteed to be available on any system. Vim and Nvim (Neovim) are the improved versions of vi. Emacs: Non-graphical or window-based editor. You still need to know keystroke commands to use it. Installed on all Linux distributions and on most other Unix systems. Pico: Simple terminal-based editor available on most versions of Unix. Uses keystroke commands, but they are listed in logical fashion at bottom of screen. Nano: A simple terminal-based editor which is default on modern Debian systems. Atom: Modern text editor developed by GitHub project.  Why does it matter? To work efficiently on remote systems like a computer cluster, it is essential to learn how to work in a pure command-line interface. GUI environments like RStudio and similar coding environments are not suitable for this. In addition, there is a lot of value of knowing how to work in an environment that is not restricted to a specific programming language. Therefore, this class embraces RStudio where it is useful, but for working on remote systems like HPCC Cluster, it uses Nvim and Tmux. Both are useful for many programming languages. Combinded with the nvim-r plugin they also provide a powerful command-line working environment for R. The following provides a brief introduction to this environment.\nVim overview The following opens a file (here myfile) with nvim (or vim)\nnvim myfile.txt # for neovim (or 'vim myfile.txt' for vim)  Once you are in Nvim, there are three main modes: normal, insert and command mode. The most important commands for switching between the three modes are:\n i: The i key brings you from the normal mode to the insert mode. The latter is used for typing. Esc: The Esc key brings you from the insert mode back to the normal mode. :: The : key starts the command mode at the bottom of the screen.  Use the arrow keys to move your cursor in the text. Using Fn Up/Down key allows to page through the text quicker. In the following command overview, all commands starting with : need to be typed in the command mode. All other commands are typed in the normal mode after pushing the Esc key.\nImportant modifier keys to control vim/nvim\n :w: save changes to file. If you are in editing mode you have to hit Esc first. :q: quit file that has not been changed :wq: save and quit file :!q: quit file without saving any changes  Useful resources for learning vim/nvim  Interactive Vim Tutorial Official Vim Documentation HPCC Linux Manual  Nvim-R-Tmux essentials Terminal-based Working Environment for R: Nvim-R-Tmux.\n Nvim-R-Tmux IDE for R Basics Tmux is a terminal multiplexer that allows to split terminal windows and to detach/reattach to existing terminal sessions. Combinded with the nvim-r plugin it provides a powerful command-line working environment for R where users can send code from a script to the R console or command-line. Both tmux and the nvim-r plugin need to be installed on a system. On HPCC Cluster both are configured in each user account. If this is not the case then follow the quick configuration instructions given in the following subsection.\nQuick configuration in user accounts of UCR’s HPCC Skip these steps if Nvim-R-Tmux is already configured in your account. Or follow the detailed instructions to install Nvim-R-Tmux from scratch on your own system.\n Log in to your user account on HPCC and execute install_nvimRtmux. Alternatively, follow these step-by-step install commands. To enable the nvim-R-tmux environment, log out and in again. Follow usage instructions of next section.  Basic usage of Nvim-R-Tmux The official and much more detailed user manual for Nvim-R is available here. The following gives a short introduction into the basic usage of Nvim-R-Tmux:\n1. Start tmux session (optional)\nNote, running Nvim from within a tmux session is optional. Skip this step if tmux functionality is not required (e.g. reattaching to sessions on remote systems).\ntmux # starts a new tmux session tmux a # attaches to an existing session  2. Open nvim-connected R session\nOpen a *.R or *.Rmd file with nvim and intialize a connected R session with \\rf. This command can be remapped to other key combinations, e.g. uncommenting lines 10-12 in .config/nvim/init.vim will remap it to the F2 key. Note, the resulting split window among Nvim and R behaves like a split viewport in nvim or vim meaning the usage of Ctrl-w w followed by i and Esc is important for navigation.\nnvim myscript.R # or *.Rmd file  3. Send R code from nvim to the R pane\nSingle lines of code can be sent from nvim to the R console by pressing the space bar. To send several lines at once, one can select them in nvim’s visual mode and then hit the space bar. Please note, the default command for sending code lines in the nvim-r-plugin is \\l. This key binding has been remapped in the provided .config/nvim/init.vim file to the space bar. Most other key bindings (shortcuts) still start with the \\ as LocalLeader, e.g. \\rh opens the help for a function/object where the curser is located in nvim. More details on this are given below.\nImportant keybindings for nvim The main advantages of Neovim compared to Vim are its better performance and its built-in terminal emulator facilitating the communication among Neovim and interactive programming environments such as R. Since the Vim and Neovim environments are managed independently, one can run them in parallel on the same system without interfering with each other. The usage of Neovim is almost identical to Vim.\nNvim commands\n \\rf: opens vim-connected R session. If you do this the first time in your user account, you might be asked to create an R directory under ~/. If so approve this action by pressing y. spacebar: sends code from vim to R; here remapped in init.vim from default \\l :split or :vsplit: splits viewport (similar to pane split in tmux) gz: maximizes size of viewport in normal mode (similar to Tmux’s Ctrl-a z zoom utility) Ctrl-w w: jumps cursor to R viewport and back; toggle between insert (i) and command (Esc) mode is required for navigation and controlling the environment. Ctrl-w r: swaps viewports Ctrl-w =: resizes splits to equal size :resize \u003c+5 or -5\u003e: resizes height by specified value :vertical resize \u003c+5 or -5\u003e: resizes width by specified value Ctrl-w H or Ctrl-w K: toggles between horizontal/vertical splits Ctrl-spacebar: omni completion for R objects/functions when nvim is in insert mode. Note, this has been remapped in init.vim from difficult to type default Ctrl-x Ctrl-o. :h nvim-R: opens nvim-R’s user manual; navigation works the same as for any Vim/Nvim help document :Rhelp fct_name: opens help for a function from nvim’s command mode with text completion support Ctrl-s and Ctrl-x: freezes/unfreezes vim (some systems)  Important keybindings for tmux Pane-level commands\n Ctrl-a %: splits pane vertically Ctrl-a \": splits pane horizontally Ctrl-a o: jumps cursor to next pane Ctrl-a Ctrl-o: swaps panes Ctrl-a \u003cspace bar\u003e: rotates pane arrangement Ctrl-a Alt \u003cleft or right\u003e: resizes to left or right Ctrl-a Esc \u003cup or down\u003e: resizes to left or right  Window-level comands\n Ctrl-a n: switches to next tmux window Ctrl-a Ctrl-a: switches to previous tmux window Ctrl-a c: creates a new tmux window Ctrl-a 1: switches to specific tmux window selected by number  Session-level comands\n Ctrl-a d: detaches from current session Ctrl-a s: switch between available tmux sesssions $ tmux new -s \u003cname\u003e: starts new session with a specific name $ tmux ls: lists available tmux session(s) $ tmux attach -t \u003cid\u003e: attaches to specific tmux session $ tmux attach: reattaches to session $ tmux kill-session -t \u003cid\u003e: kills a specific tmux session Ctrl-a : kill-session: kills a session from tmux command mode that can be initiated with Ctrl-a :  Nvim IDEs for other languages For other languages, such as Bash, Python and Ruby, one can use the vimcmdline plugin for nvim (or vim). To install it, one needs to copy from the vimcmdline resository the directories ftplugin, plugin and syntax and their files to ~/.config/nvim/. For user accounts of UCR’s HPCC, the above install script install_nvimRtmux includes the install of vimcmdline (since 09-Jun-18).\nThe usage of vimcmdline is very similar to nvim-R. To start a connected terminal session, one opens with nvim a code file with the extension of a given language (e.g. *.sh for Bash or *.py for Python), while the corresponding interactive interpreter session is initiated by pressing the key sequence \\s (corresponds to \\rf under nvim-R). Subsequently, code lines can be sent with the space bar. More details are available here.\n","categories":"","description":"","excerpt":"  HPCC Cluster Overview The HPCC Cluster (formerly called biocluster) …","ref":"/tutorials/linux/linux/","tags":"","title":"Introduction to HPCC Cluster and Linux"},{"body":"Detailed course schedule Note: this schedule is preliminary and subject to changes.\n ","categories":"","description":"","excerpt":"Detailed course schedule Note: this schedule is preliminary and …","ref":"/about/schedule/","tags":"","title":"Course Schedule"},{"body":"       document.addEventListener(\"DOMContentLoaded\", function() { document.querySelector(\"h1\").className = \"title\"; });  document.addEventListener(\"DOMContentLoaded\", function() { var links = document.links; for (var i = 0, linksLength = links.length; i Overview What is R? R is a powerful statistical environment and programming language for the analysis and visualization of data. The associated Bioconductor and CRAN package repositories provide many additional R packages for statistical data analysis for a wide array of research areas. The R software is free and runs on all common operating systems.\nWhy Using R?  Complete statistical environment and programming language Efficient functions and data structures for data analysis Powerful graphics Access to fast growing number of analysis packages Most widely used language in bioinformatics Is standard for data mining and biostatistical analysis Technical advantages: free, open-source, available for all OSs  Books and Documentation  simpleR - Using R for Introductory Statistics (John Verzani, 2004) - URL Bioinformatics and Computational Biology Solutions Using R and Bioconductor (Gentleman et al., 2005) - URL More on this see “Finding Help” section in UCR Manual - URL  R Working Environments    R Projects and Interfaces\n Some R working environments with support for syntax highlighting and utilities to send code to the R console:\n RStudio: excellent choice for beginners (Cheat Sheet) Basic R code editors provided by Rguis gedit, Rgedit, RKWard, Eclipse, Tinn-R, Notepad++, NppToR Vim-R-Tmux: R working environment based on vim and tmux Emacs (ESS add-on package)  Example: RStudio New integrated development environment (IDE) for R. Highly functional for both beginners and advanced.\n   RStudio IDE\n Some userful shortcuts: Ctrl+Enter (send code), Ctrl+Shift+C (comment/uncomment), Ctrl+1/2 (switch window focus)\nExample: Nvim-R-Tmux Terminal-based Working Environment for R: Nvim-R-Tmux.\n   Nvim-R-Tmux IDE for R\n R Package Repositories  CRAN (\u003e11,000 packages) general data analysis - URL Bioconductor (\u003e1,100 packages) bioscience data analysis - URL Omegahat (\u003e90 packages) programming interfaces - URL  Installation of R Packages   Install R for your operating system from CRAN.\n  Install RStudio from RStudio.\n  Install CRAN Packages from R console like this:\ninstall.packages(c(\"pkg1\", \"pkg2\")) install.packages(\"pkg.zip\", repos=NULL)    Install Bioconductor packages as follows:\nif (!requireNamespace(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\") # Installs BiocManager if not available yet BiocManager::version() # Reports Bioconductor version BiocManager::install(c(\"pkg1\", \"pkg2\")) # Installs packages specified under \"pkg1\"    For more details consult the Bioc Install page and BiocInstaller package.\n  Getting Around Startup and Closing Behavior   Starting R: The R GUI versions, including RStudio, under Windows and Mac OS X can be opened by double-clicking their icons. Alternatively, one can start it by typing R in a terminal (default under Linux).\n  Startup/Closing Behavior: The R environment is controlled by hidden files in the startup directory: .RData, .Rhistory and .Rprofile (optional).\n  Closing R:\n  q()  Save workspace image? [y/n/c]:   Note: When responding with y, then the entire R workspace will be written to the .RData file which can become very large. Often it is sufficient to just save an analysis protocol in an R source file. This way one can quickly regenerate all data sets and objects.  Navigating directories Create an object with the assignment operator \u003c- or =\nobject \u003c- ...  Instead of the assignment operator one can use the assign function\nassign(\"x\", function(arguments))  List objects in current R session\nls()  Return content of current working directory\ndir()  Return path of current working directory\ngetwd()  Change current working directory\nsetwd(\"/home/user\")  Basic Syntax General R command syntax\nobject \u003c- function_name(arguments) object \u003c- object[arguments]  Finding help\n?function_name  Load a library/package\nlibrary(\"my_library\")  List functions defined by a library\nlibrary(help=\"my_library\")  Load library manual (PDF or HTML file)\nvignette(\"my_library\")  Execute an R script from within R\nsource(\"my_script.R\")  Execute an R script from command-line (the first of the three options is preferred)\n$ Rscript my_script.R $ R CMD BATCH my_script.R $ R --slave \u003c my_script.R  Data Types Numeric data Example: 1, 2, 3, ...\nx \u003c- c(1, 2, 3) x  ## [1] 1 2 3  is.numeric(x)  ## [1] TRUE  as.character(x)  ## [1] \"1\" \"2\" \"3\"  Character data Example: \"a\", \"b\", \"c\", ...\nx \u003c- c(\"1\", \"2\", \"3\") x  ## [1] \"1\" \"2\" \"3\"  is.character(x)  ## [1] TRUE  as.numeric(x)  ## [1] 1 2 3  Complex data Example: mix of both\nc(1, \"b\", 3)  ## [1] \"1\" \"b\" \"3\"  Logical data Example: TRUE of FALSE\nx \u003c- 1:10 \u003c 5 x  ## [1] TRUE TRUE TRUE TRUE FALSE FALSE FALSE FALSE FALSE FALSE  !x  ## [1] FALSE FALSE FALSE FALSE TRUE TRUE TRUE TRUE TRUE TRUE  which(x) # Returns index for the 'TRUE' values in logical vector  ## [1] 1 2 3 4  Data Objects Object types Vectors (1D) Definition: numeric or character\nmyVec \u003c- 1:10; names(myVec) \u003c- letters[1:10] myVec \u003c- setNames(1:10, letters[1:10]) # Same as above in single step myVec[1:5]  ## a b c d e ## 1 2 3 4 5  myVec[c(2,4,6,8)]  ## b d f h ## 2 4 6 8  myVec[c(\"b\", \"d\", \"f\")]  ## b d f ## 2 4 6  Factors (1D) Definition: vectors with grouping information\nfactor(c(\"dog\", \"cat\", \"mouse\", \"dog\", \"dog\", \"cat\"))  ## [1] dog cat mouse dog dog cat ## Levels: cat dog mouse  Matrices (2D) Definition: two dimensional structures with data of same type\nmyMA \u003c- matrix(1:30, 3, 10, byrow = TRUE) class(myMA)  ## [1] \"matrix\" \"array\"  myMA[1:2,]  ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] 1 2 3 4 5 6 7 8 9 10 ## [2,] 11 12 13 14 15 16 17 18 19 20  myMA[1, , drop=FALSE]  ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] 1 2 3 4 5 6 7 8 9 10  Data Frames (2D) Definition: two dimensional objects with data of variable types\nmyDF \u003c- data.frame(Col1=1:10, Col2=10:1) myDF[1:2, ]  ## Col1 Col2 ## 1 1 10 ## 2 2 9  Arrays Definition: data structure with one, two or more dimensions\nLists Definition: containers for any object type\nmyL \u003c- list(name=\"Fred\", wife=\"Mary\", no.children=3, child.ages=c(4,7,9)) myL  ## $name ## [1] \"Fred\" ## ## $wife ## [1] \"Mary\" ## ## $no.children ## [1] 3 ## ## $child.ages ## [1] 4 7 9  myL[[4]][1:2]  ## [1] 4 7  Functions Definition: piece of code\nmyfct \u003c- function(arg1, arg2, ...) { function_body }  Subsetting of data objects (1.) Subsetting by positive or negative index/position numbers\nmyVec \u003c- 1:26; names(myVec) \u003c- LETTERS myVec[1:4]  ## A B C D ## 1 2 3 4  (2.) Subsetting by same length logical vectors\nmyLog \u003c- myVec \u003e 10 myVec[myLog]  ## K L M N O P Q R S T U V W X Y Z ## 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  (3.) Subsetting by field names\nmyVec[c(\"B\", \"K\", \"M\")]  ## B K M ## 2 11 13  (4.) Subset with $ sign: references a single column or list component by its name\niris$Species[1:8]  ## [1] setosa setosa setosa setosa setosa setosa setosa setosa ## Levels: setosa versicolor virginica  Important Utilities Combining Objects The c function combines vectors and lists\nc(1, 2, 3)  ## [1] 1 2 3  x \u003c- 1:3; y \u003c- 101:103 c(x, y)  ## [1] 1 2 3 101 102 103  iris$Species[1:8]  ## [1] setosa setosa setosa setosa setosa setosa setosa setosa ## Levels: setosa versicolor virginica  The cbind and rbind functions can be used to append columns and rows, respecively.\nma \u003c- cbind(x, y) ma  ## x y ## [1,] 1 101 ## [2,] 2 102 ## [3,] 3 103  rbind(ma, ma)  ## x y ## [1,] 1 101 ## [2,] 2 102 ## [3,] 3 103 ## [4,] 1 101 ## [5,] 2 102 ## [6,] 3 103  Accessing Dimensions of Objects Length and dimension information of objects\nlength(iris$Species)  ## [1] 150  dim(iris)  ## [1] 150 5  Accessing Name Slots of Objects Accessing row and column names of 2D objects\nrownames(iris)[1:8]  ## [1] \"1\" \"2\" \"3\" \"4\" \"5\" \"6\" \"7\" \"8\"  colnames(iris)  ## [1] \"Sepal.Length\" \"Sepal.Width\" \"Petal.Length\" \"Petal.Width\" \"Species\"  Return name field of vectors and lists\nnames(myVec)  ## [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\" \"T\" \"U\" \"V\" \"W\" \"X\" ## [25] \"Y\" \"Z\"  names(myL)  ## [1] \"name\" \"wife\" \"no.children\" \"child.ages\"  Sorting Objects The function sort returns a vector in ascending or descending order\nsort(10:1)  ## [1] 1 2 3 4 5 6 7 8 9 10  The function order returns a sorting index for sorting an object\nsortindex \u003c- order(iris[,1], decreasing = FALSE) sortindex[1:12]  ## [1] 14 9 39 43 42 4 7 23 48 3 30 12  iris[sortindex,][1:2,]  ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 14 4.3 3.0 1.1 0.1 setosa ## 9 4.4 2.9 1.4 0.2 setosa  sortindex \u003c- order(-iris[,1]) # Same as decreasing=TRUE  Sorting multiple columns\niris[order(iris$Sepal.Length, iris$Sepal.Width),][1:2,]  ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 14 4.3 3.0 1.1 0.1 setosa ## 9 4.4 2.9 1.4 0.2 setosa  Operators and Calculations Comparison Operators Comparison operators: ==, !=, \u003c, \u003e, \u003c=, \u003e=\n1==1  ## [1] TRUE  Logical operators: AND: \u0026, OR: |, NOT: !\nx \u003c- 1:10; y \u003c- 10:1 x \u003e y \u0026 x \u003e 5  ## [1] FALSE FALSE FALSE FALSE FALSE TRUE TRUE TRUE TRUE TRUE  Basic Calculations To look up math functions, see Function Index here\nx + y  ## [1] 11 11 11 11 11 11 11 11 11 11  sum(x)  ## [1] 55  mean(x)  ## [1] 5.5  apply(iris[1:6,1:3], 1, mean)  ## 1 2 3 4 5 6 ## 3.333333 3.100000 3.066667 3.066667 3.333333 3.666667  Reading and Writing External Data Import of tabular data Import of a tab-delimited tabular file\nmyDF \u003c- read.delim(\"myData.xls\", sep=\"\\t\")  Import of Excel file. Note: working with tab- or comma-delimited files is more flexible and preferred.\nlibrary(gdata) myDF \u003c- read.xls\"myData.xls\")  Import of Google Sheets. The following example imports a sample Google Sheet from here. Detailed instructions for interacting from R with Google Sheets with the required googlesheets package are here.\nlibrary(\"googlesheets\"); library(\"dplyr\"); library(knitr) gs_auth() # Creates authorizaton token (.httr-oauth) in current directory if not present sheetid \u003c-\"1U-32UcwZP1k3saKeaH1mbvEAOfZRdNHNkWK2GI1rpPM\" gap \u003c- gs_key(sheetid) mysheet \u003c- gs_read(gap, skip=4) myDF \u003c- as.data.frame(mysheet) myDF  Export of tabular data write.table(myDF, file=\"myfile.xls\", sep=\"\\t\", quote=FALSE, col.names=NA)  Line-wise import myDF \u003c- readLines(\"myData.txt\")  Line-wise export writeLines(month.name, \"myData.txt\")  Export R object mylist \u003c- list(C1=iris[,1], C2=iris[,2]) # Example to export saveRDS(mylist, \"mylist.rds\")  Import R object mylist \u003c- readRDS(\"mylist.rds\")  Copy and paste into R On Windows/Linux systems\nread.delim(\"clipboard\")  On Mac OS X systems\nread.delim(pipe(\"pbpaste\"))  Copy and paste from R On Windows/Linux systems\nwrite.table(iris, \"clipboard\", sep=\"\\t\", col.names=NA, quote=F)  On Mac OS X systems\nzz \u003c- pipe('pbcopy', 'w') write.table(iris, zz, sep=\"\\t\", col.names=NA, quote=F) close(zz)  Homework 3A Homework 3A: Object Subsetting Routines and Import/Export\nUseful R Functions Unique entries Make vector entries unique with unique\nlength(iris$Sepal.Length)  ## [1] 150  length(unique(iris$Sepal.Length))  ## [1] 35  Count occurrences Count occurrences of entries with table\ntable(iris$Species)  ## ## setosa versicolor virginica ## 50 50 50  Aggregate data Compute aggregate statistics with aggregate\naggregate(iris[,1:4], by=list(iris$Species), FUN=mean, na.rm=TRUE)  ## Group.1 Sepal.Length Sepal.Width Petal.Length Petal.Width ## 1 setosa 5.006 3.428 1.462 0.246 ## 2 versicolor 5.936 2.770 4.260 1.326 ## 3 virginica 6.588 2.974 5.552 2.026  Intersect data Compute intersect between two vectors with %in%\nmonth.name %in% c(\"May\", \"July\")  ## [1] FALSE FALSE FALSE FALSE TRUE FALSE TRUE FALSE FALSE FALSE FALSE FALSE  Merge data frames Join two data frames by common field entries with merge (here row names by.x=0). To obtain only the common rows, change all=TRUE to all=FALSE. To merge on specific columns, refer to them by their position numbers or their column names.\nframe1 \u003c- iris[sample(1:length(iris[,1]), 30), ] frame1[1:2,]  ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 72 6.1 2.8 4.0 1.3 versicolor ## 45 5.1 3.8 1.9 0.4 setosa  dim(frame1)  ## [1] 30 5  my_result \u003c- merge(frame1, iris, by.x = 0, by.y = 0, all = TRUE) dim(my_result)  ## [1] 150 11  dplyr Environment Modern object classes and methods for handling data.frame like structures are provided by the dplyr and data.table packages. The following gives a short introduction to the usage and functionalities of the dplyr package. More detailed tutorials on this topic can be found here:\n dplyr: A Grammar of Data Manipulation Introduction to dplyr Tutorial on dplyr Cheatsheet for Joins from Jenny Bryan Tibbles Intro to data.table package Big data with dplyr and data.table Fast lookups with dplyr and data.table  Installation The dplyr environment has evolved into an ecosystem of packages. To simplify package management, one can install and load the entire collection via the tidyverse package. For more details on tidyverse see here.\ninstall.packages(\"tidyverse\")  Construct a tibble (tibble) library(tidyverse) as_tibble(iris) # coerce data.frame to tibble tbl  ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cfct\u003e ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## # … with 140 more rows  Alternative functions producing the same result include as_data_frame and tbl_df:\nas_data_frame(iris) tbl_df(iris)  Reading and writing tabular files While the base R read/write utilities can be used for data.frames, best time performance with the least amount of typing is achieved with the export/import functions from the readr package. For very large files the fread function from the data.table package achieves the best time performance.\nImport with readr Import functions provided by readr include:\n read_csv(): comma separated (CSV) files read_tsv(): tab separated files read_delim(): general delimited files read_fwf(): fixed width files read_table(): tabular files where colums are separated by white-space. read_log(): web log files  Create a sample tab delimited file for import\nwrite_tsv(iris, \"iris.txt\") # Creates sample file  Import with read_tsv\niris_df \u003c- read_tsv(\"iris.txt\") # Import with read_tbv from readr package iris_df  ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## # … with 140 more rows  To import Google Sheets directly into R, see here.\nFast table import with fread The fread function from the data.table package provides the best time performance for reading large tabular files into R.\nlibrary(data.table) iris_df \u003c- as_data_frame(fread(\"iris.txt\")) # Import with fread and conversion to tibble iris_df  ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## # … with 140 more rows  Note: to ignore lines starting with comment signs, one can pass on to fread a shell command for preprocessing the file. The following example illustrates this option.\nfread(\"grep -v '^#' iris.txt\")  Export with readr Export function provided by readr inlcude\n write_delim(): general delimited files write_csv(): comma separated (CSV) files write_excel_csv(): excel style CSV files write_tsv(): tab separated files  For instance, the write_tsv function writes a data.frame or tibble to a tab delimited file with much nicer default settings than the base R write.table function.\nwrite_tsv(iris_df, \"iris.txt\")  Column and row binds The equivalents to base R’s rbind and cbind are bind_rows and bind_cols, respectively.\nbind_cols(iris_df, iris_df)  ## # A tibble: 150 x 10 ## Sepal.Length...1 Sepal.Width...2 Petal.Length...3 Petal.Width...4 Species...5 Sepal.Length...6 ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e \u003cdbl\u003e ## 1 5.1 3.5 1.4 0.2 setosa 5.1 ## 2 4.9 3 1.4 0.2 setosa 4.9 ## 3 4.7 3.2 1.3 0.2 setosa 4.7 ## 4 4.6 3.1 1.5 0.2 setosa 4.6 ## 5 5 3.6 1.4 0.2 setosa 5 ## 6 5.4 3.9 1.7 0.4 setosa 5.4 ## 7 4.6 3.4 1.4 0.3 setosa 4.6 ## 8 5 3.4 1.5 0.2 setosa 5 ## 9 4.4 2.9 1.4 0.2 setosa 4.4 ## 10 4.9 3.1 1.5 0.1 setosa 4.9 ## # … with 140 more rows, and 4 more variables: Sepal.Width...7 \u003cdbl\u003e, Petal.Length...8 \u003cdbl\u003e, ## # Petal.Width...9 \u003cdbl\u003e, Species...10 \u003cchr\u003e  bind_rows(iris_df, iris_df)  ## # A tibble: 300 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## # … with 290 more rows  Extract column as vector The subsetting operators [[ and $can be used to extract from a tibble single columns as vector.\niris_df[[5]][1:12]  ## [1] \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" ## [11] \"setosa\" \"setosa\"  iris_df$Species[1:12]  ## [1] \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" ## [11] \"setosa\" \"setosa\"  Important dplyr functions  filter() and slice() arrange() select() and rename() distinct() mutate() and transmute() summarise() sample_n() and sample_frac()  Slice and filter functions Filter function filter(iris_df, Sepal.Length \u003e 7.5, Species==\"virginica\")  ## # A tibble: 6 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 7.6 3 6.6 2.1 virginica ## 2 7.7 3.8 6.7 2.2 virginica ## 3 7.7 2.6 6.9 2.3 virginica ## 4 7.7 2.8 6.7 2 virginica ## 5 7.9 3.8 6.4 2 virginica ## 6 7.7 3 6.1 2.3 virginica  Base R code equivalent iris_df[iris_df[, \"Sepal.Length\"] \u003e 7.5 \u0026 iris_df[, \"Species\"]==\"virginica\", ]  ## # A tibble: 6 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 7.6 3 6.6 2.1 virginica ## 2 7.7 3.8 6.7 2.2 virginica ## 3 7.7 2.6 6.9 2.3 virginica ## 4 7.7 2.8 6.7 2 virginica ## 5 7.9 3.8 6.4 2 virginica ## 6 7.7 3 6.1 2.3 virginica  Including boolean operators filter(iris_df, Sepal.Length \u003e 7.5 | Sepal.Length \u003c 5.5, Species==\"virginica\")  ## # A tibble: 7 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 7.6 3 6.6 2.1 virginica ## 2 4.9 2.5 4.5 1.7 virginica ## 3 7.7 3.8 6.7 2.2 virginica ## 4 7.7 2.6 6.9 2.3 virginica ## 5 7.7 2.8 6.7 2 virginica ## 6 7.9 3.8 6.4 2 virginica ## 7 7.7 3 6.1 2.3 virginica  Subset rows by position dplyr approach\nslice(iris_df, 1:2)  ## # A tibble: 2 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa  Base R code equivalent\niris_df[1:2,]  ## # A tibble: 2 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa  Subset rows by names Since tibbles do not contain row names, row wise subsetting via the [,] operator cannot be used. However, the corresponding behavior can be achieved by passing to select a row position index obtained by basic R intersect utilities such as match.\nCreate a suitable test tibble\ndf1 \u003c- bind_cols(data_frame(ids1=paste0(\"g\", 1:10)), as_data_frame(matrix(1:40, 10, 4, dimnames=list(1:10, paste0(\"CA\", 1:4))))) df1  ## # A tibble: 10 x 5 ## ids1 CA1 CA2 CA3 CA4 ## \u003cchr\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e ## 1 g1 1 11 21 31 ## 2 g2 2 12 22 32 ## 3 g3 3 13 23 33 ## 4 g4 4 14 24 34 ## 5 g5 5 15 25 35 ## 6 g6 6 16 26 36 ## 7 g7 7 17 27 37 ## 8 g8 8 18 28 38 ## 9 g9 9 19 29 39 ## 10 g10 10 20 30 40  dplyr approach\nslice(df1, match(c(\"g10\", \"g4\", \"g4\"), df1$ids1))  ## # A tibble: 3 x 5 ## ids1 CA1 CA2 CA3 CA4 ## \u003cchr\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e ## 1 g10 10 20 30 40 ## 2 g4 4 14 24 34 ## 3 g4 4 14 24 34  Base R equivalent\ndf1_old \u003c- as.data.frame(df1) rownames(df1_old) \u003c- df1_old[,1] df1_old[c(\"g10\", \"g4\", \"g4\"),]  ## ids1 CA1 CA2 CA3 CA4 ## g10 g10 10 20 30 40 ## g4 g4 4 14 24 34 ## g4.1 g4 4 14 24 34  Sorting with arrange Row-wise ordering based on specific columns\ndplyr approach\narrange(iris_df, Species, Sepal.Length, Sepal.Width)  ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 4.3 3 1.1 0.1 setosa ## 2 4.4 2.9 1.4 0.2 setosa ## 3 4.4 3 1.3 0.2 setosa ## 4 4.4 3.2 1.3 0.2 setosa ## 5 4.5 2.3 1.3 0.3 setosa ## 6 4.6 3.1 1.5 0.2 setosa ## 7 4.6 3.2 1.4 0.2 setosa ## 8 4.6 3.4 1.4 0.3 setosa ## 9 4.6 3.6 1 0.2 setosa ## 10 4.7 3.2 1.3 0.2 setosa ## # … with 140 more rows  For ordering descendingly use desc() function\narrange(iris_df, desc(Species), Sepal.Length, Sepal.Width)  ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 4.9 2.5 4.5 1.7 virginica ## 2 5.6 2.8 4.9 2 virginica ## 3 5.7 2.5 5 2 virginica ## 4 5.8 2.7 5.1 1.9 virginica ## 5 5.8 2.7 5.1 1.9 virginica ## 6 5.8 2.8 5.1 2.4 virginica ## 7 5.9 3 5.1 1.8 virginica ## 8 6 2.2 5 1.5 virginica ## 9 6 3 4.8 1.8 virginica ## 10 6.1 2.6 5.6 1.4 virginica ## # … with 140 more rows  Base R code equivalent\niris_df[order(iris_df$Species, iris_df$Sepal.Length, iris_df$Sepal.Width), ]  ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 4.3 3 1.1 0.1 setosa ## 2 4.4 2.9 1.4 0.2 setosa ## 3 4.4 3 1.3 0.2 setosa ## 4 4.4 3.2 1.3 0.2 setosa ## 5 4.5 2.3 1.3 0.3 setosa ## 6 4.6 3.1 1.5 0.2 setosa ## 7 4.6 3.2 1.4 0.2 setosa ## 8 4.6 3.4 1.4 0.3 setosa ## 9 4.6 3.6 1 0.2 setosa ## 10 4.7 3.2 1.3 0.2 setosa ## # … with 140 more rows  iris_df[order(iris_df$Species, decreasing=TRUE), ]  ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 6.3 3.3 6 2.5 virginica ## 2 5.8 2.7 5.1 1.9 virginica ## 3 7.1 3 5.9 2.1 virginica ## 4 6.3 2.9 5.6 1.8 virginica ## 5 6.5 3 5.8 2.2 virginica ## 6 7.6 3 6.6 2.1 virginica ## 7 4.9 2.5 4.5 1.7 virginica ## 8 7.3 2.9 6.3 1.8 virginica ## 9 6.7 2.5 5.8 1.8 virginica ## 10 7.2 3.6 6.1 2.5 virginica ## # … with 140 more rows  Select columns with select Select specific columns\nselect(iris_df, Species, Petal.Length, Sepal.Length)  ## # A tibble: 150 x 3 ## Species Petal.Length Sepal.Length ## \u003cchr\u003e \u003cdbl\u003e \u003cdbl\u003e ## 1 setosa 1.4 5.1 ## 2 setosa 1.4 4.9 ## 3 setosa 1.3 4.7 ## 4 setosa 1.5 4.6 ## 5 setosa 1.4 5 ## 6 setosa 1.7 5.4 ## 7 setosa 1.4 4.6 ## 8 setosa 1.5 5 ## 9 setosa 1.4 4.4 ## 10 setosa 1.5 4.9 ## # … with 140 more rows  Select range of columns by name\nselect(iris_df, Sepal.Length : Petal.Width)  ## # A tibble: 150 x 4 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e ## 1 5.1 3.5 1.4 0.2 ## 2 4.9 3 1.4 0.2 ## 3 4.7 3.2 1.3 0.2 ## 4 4.6 3.1 1.5 0.2 ## 5 5 3.6 1.4 0.2 ## 6 5.4 3.9 1.7 0.4 ## 7 4.6 3.4 1.4 0.3 ## 8 5 3.4 1.5 0.2 ## 9 4.4 2.9 1.4 0.2 ## 10 4.9 3.1 1.5 0.1 ## # … with 140 more rows  Drop specific columns (here range)\nselect(iris_df, -(Sepal.Length : Petal.Width))  ## # A tibble: 150 x 1 ## Species ## \u003cchr\u003e ## 1 setosa ## 2 setosa ## 3 setosa ## 4 setosa ## 5 setosa ## 6 setosa ## 7 setosa ## 8 setosa ## 9 setosa ## 10 setosa ## # … with 140 more rows  Renaming columns with rename dplyr approach\nrename(iris_df, new_col_name = Species)  ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width new_col_name ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## # … with 140 more rows  Base R code approach\ncolnames(iris_df)[colnames(iris_df)==\"Species\"] \u003c- \"new_col_names\"  Obtain unique rows with distinct dplyr approach\ndistinct(iris_df, Species, .keep_all=TRUE)  ## # A tibble: 3 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 5.1 3.5 1.4 0.2 setosa ## 2 7 3.2 4.7 1.4 versicolor ## 3 6.3 3.3 6 2.5 virginica  Base R code approach\niris_df[!duplicated(iris_df$Species),]  ## # A tibble: 3 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 5.1 3.5 1.4 0.2 setosa ## 2 7 3.2 4.7 1.4 versicolor ## 3 6.3 3.3 6 2.5 virginica  Add columns mutate The mutate function allows to append columns to existing ones.\nmutate(iris_df, Ratio = Sepal.Length / Sepal.Width, Sum = Sepal.Length + Sepal.Width)  ## # A tibble: 150 x 7 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species Ratio Sum ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e \u003cdbl\u003e \u003cdbl\u003e ## 1 5.1 3.5 1.4 0.2 setosa 1.46 8.6 ## 2 4.9 3 1.4 0.2 setosa 1.63 7.9 ## 3 4.7 3.2 1.3 0.2 setosa 1.47 7.9 ## 4 4.6 3.1 1.5 0.2 setosa 1.48 7.7 ## 5 5 3.6 1.4 0.2 setosa 1.39 8.6 ## 6 5.4 3.9 1.7 0.4 setosa 1.38 9.3 ## 7 4.6 3.4 1.4 0.3 setosa 1.35 8 ## 8 5 3.4 1.5 0.2 setosa 1.47 8.4 ## 9 4.4 2.9 1.4 0.2 setosa 1.52 7.3 ## 10 4.9 3.1 1.5 0.1 setosa 1.58 8 ## # … with 140 more rows  transmute The transmute function does the same as mutate but drops existing columns\ntransmute(iris_df, Ratio = Sepal.Length / Sepal.Width, Sum = Sepal.Length + Sepal.Width)  ## # A tibble: 150 x 2 ## Ratio Sum ## \u003cdbl\u003e \u003cdbl\u003e ## 1 1.46 8.6 ## 2 1.63 7.9 ## 3 1.47 7.9 ## 4 1.48 7.7 ## 5 1.39 8.6 ## 6 1.38 9.3 ## 7 1.35 8 ## 8 1.47 8.4 ## 9 1.52 7.3 ## 10 1.58 8 ## # … with 140 more rows  bind_cols The bind_cols function is the equivalent of cbind in base R. To add rows, use the corresponding bind_rows function.\nbind_cols(iris_df, iris_df)  ## # A tibble: 150 x 10 ## Sepal.Length...1 Sepal.Width...2 Petal.Length...3 Petal.Width...4 Species...5 Sepal.Length...6 ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e \u003cdbl\u003e ## 1 5.1 3.5 1.4 0.2 setosa 5.1 ## 2 4.9 3 1.4 0.2 setosa 4.9 ## 3 4.7 3.2 1.3 0.2 setosa 4.7 ## 4 4.6 3.1 1.5 0.2 setosa 4.6 ## 5 5 3.6 1.4 0.2 setosa 5 ## 6 5.4 3.9 1.7 0.4 setosa 5.4 ## 7 4.6 3.4 1.4 0.3 setosa 4.6 ## 8 5 3.4 1.5 0.2 setosa 5 ## 9 4.4 2.9 1.4 0.2 setosa 4.4 ## 10 4.9 3.1 1.5 0.1 setosa 4.9 ## # … with 140 more rows, and 4 more variables: Sepal.Width...7 \u003cdbl\u003e, Petal.Length...8 \u003cdbl\u003e, ## # Petal.Width...9 \u003cdbl\u003e, Species...10 \u003cchr\u003e  Summarize data Summary calculation on single column\nsummarize(iris_df, mean(Petal.Length))  ## # A tibble: 1 x 1 ## `mean(Petal.Length)` ## \u003cdbl\u003e ## 1 3.76  Summary calculation on many columns\nsummarize_all(iris_df[,1:4], mean)  ## # A tibble: 1 x 4 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e ## 1 5.84 3.06 3.76 1.20  Summarize by grouping column\nsummarize(group_by(iris_df, Species), mean(Petal.Length))  ## # A tibble: 3 x 2 ## Species `mean(Petal.Length)` ## \u003cchr\u003e \u003cdbl\u003e ## 1 setosa 1.46 ## 2 versicolor 4.26 ## 3 virginica 5.55  Aggregate summaries\nsummarize_all(group_by(iris_df, Species), mean)  ## # A tibble: 3 x 5 ## Species Sepal.Length Sepal.Width Petal.Length Petal.Width ## \u003cchr\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e ## 1 setosa 5.01 3.43 1.46 0.246 ## 2 versicolor 5.94 2.77 4.26 1.33 ## 3 virginica 6.59 2.97 5.55 2.03  Note: group_by does the looping for the user similar to aggregate or tapply.\nMerging tibbles The dplyr package provides several join functions for merging tibbles by a common key column similar to the merge function in base R. These *_join functions include:\n inner_join(): returns join only for rows matching among both tibbles full_join(): returns join for all (matching and non-matching) rows of two tibbles left_join(): returns join for all rows in first tibble right_join(): returns join for all rows in second tibble anti_join(): returns for first tibble only those rows that have no match in the second one  Sample tibbles to illustrate *.join functions.\ndf1 \u003c- bind_cols(data_frame(ids1=paste0(\"g\", 1:10)), as_data_frame(matrix(1:40, 10, 4, dimnames=list(1:10, paste0(\"CA\", 1:4))))) df1  ## # A tibble: 10 x 5 ## ids1 CA1 CA2 CA3 CA4 ## \u003cchr\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e ## 1 g1 1 11 21 31 ## 2 g2 2 12 22 32 ## 3 g3 3 13 23 33 ## 4 g4 4 14 24 34 ## 5 g5 5 15 25 35 ## 6 g6 6 16 26 36 ## 7 g7 7 17 27 37 ## 8 g8 8 18 28 38 ## 9 g9 9 19 29 39 ## 10 g10 10 20 30 40  df2 \u003c- bind_cols(data_frame(ids2=paste0(\"g\", c(2,5,11,12))), as_data_frame(matrix(1:16, 4, 4, dimnames=list(1:4, paste0(\"CB\", 1:4))))) df2  ## # A tibble: 4 x 5 ## ids2 CB1 CB2 CB3 CB4 ## \u003cchr\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e ## 1 g2 1 5 9 13 ## 2 g5 2 6 10 14 ## 3 g11 3 7 11 15 ## 4 g12 4 8 12 16  Inner join inner_join(df1, df2, by=c(\"ids1\"=\"ids2\"))  ## # A tibble: 2 x 9 ## ids1 CA1 CA2 CA3 CA4 CB1 CB2 CB3 CB4 ## \u003cchr\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e ## 1 g2 2 12 22 32 1 5 9 13 ## 2 g5 5 15 25 35 2 6 10 14  Left join left_join(df1, df2, by=c(\"ids1\"=\"ids2\"))  ## # A tibble: 10 x 9 ## ids1 CA1 CA2 CA3 CA4 CB1 CB2 CB3 CB4 ## \u003cchr\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e ## 1 g1 1 11 21 31 NA NA NA NA ## 2 g2 2 12 22 32 1 5 9 13 ## 3 g3 3 13 23 33 NA NA NA NA ## 4 g4 4 14 24 34 NA NA NA NA ## 5 g5 5 15 25 35 2 6 10 14 ## 6 g6 6 16 26 36 NA NA NA NA ## 7 g7 7 17 27 37 NA NA NA NA ## 8 g8 8 18 28 38 NA NA NA NA ## 9 g9 9 19 29 39 NA NA NA NA ## 10 g10 10 20 30 40 NA NA NA NA  Right join right_join(df1, df2, by=c(\"ids1\"=\"ids2\"))  ## # A tibble: 4 x 9 ## ids1 CA1 CA2 CA3 CA4 CB1 CB2 CB3 CB4 ## \u003cchr\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e ## 1 g2 2 12 22 32 1 5 9 13 ## 2 g5 5 15 25 35 2 6 10 14 ## 3 g11 NA NA NA NA 3 7 11 15 ## 4 g12 NA NA NA NA 4 8 12 16  Full join full_join(df1, df2, by=c(\"ids1\"=\"ids2\"))  ## # A tibble: 12 x 9 ## ids1 CA1 CA2 CA3 CA4 CB1 CB2 CB3 CB4 ## \u003cchr\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e ## 1 g1 1 11 21 31 NA NA NA NA ## 2 g2 2 12 22 32 1 5 9 13 ## 3 g3 3 13 23 33 NA NA NA NA ## 4 g4 4 14 24 34 NA NA NA NA ## 5 g5 5 15 25 35 2 6 10 14 ## 6 g6 6 16 26 36 NA NA NA NA ## 7 g7 7 17 27 37 NA NA NA NA ## 8 g8 8 18 28 38 NA NA NA NA ## 9 g9 9 19 29 39 NA NA NA NA ## 10 g10 10 20 30 40 NA NA NA NA ## 11 g11 NA NA NA NA 3 7 11 15 ## 12 g12 NA NA NA NA 4 8 12 16  Anti join anti_join(df1, df2, by=c(\"ids1\"=\"ids2\"))  ## # A tibble: 8 x 5 ## ids1 CA1 CA2 CA3 CA4 ## \u003cchr\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e ## 1 g1 1 11 21 31 ## 2 g3 3 13 23 33 ## 3 g4 4 14 24 34 ## 4 g6 6 16 26 36 ## 5 g7 7 17 27 37 ## 6 g8 8 18 28 38 ## 7 g9 9 19 29 39 ## 8 g10 10 20 30 40  For additional join options users want to cosult the *_join help pages.\nChaining To simplify chaining of serveral operations, dplyr provides the %\u003e% operator, where x %\u003e% f(y) turns into f(x, y). This way one can pipe together multiple operations by writing them from left-to-right or top-to-bottom. This makes for easy to type and readable code.\nExample 1 Series of data manipulations and export\nread_tsv(\"iris.txt\") %\u003e% # Import with read_tbv from readr package as_tibble() %\u003e% # Declare tibble to use select(Sepal.Length:Species) %\u003e% # Select columns filter(Species==\"setosa\") %\u003e% # Filter rows by some value arrange(Sepal.Length) %\u003e% # Sort by some column mutate(Subtract=Petal.Length - Petal.Width) # Calculate and append  ## # A tibble: 50 x 6 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species Subtract ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e \u003cdbl\u003e ## 1 4.3 3 1.1 0.1 setosa 1 ## 2 4.4 2.9 1.4 0.2 setosa 1.2 ## 3 4.4 3 1.3 0.2 setosa 1.1 ## 4 4.4 3.2 1.3 0.2 setosa 1.1 ## 5 4.5 2.3 1.3 0.3 setosa 1 ## 6 4.6 3.1 1.5 0.2 setosa 1.3 ## 7 4.6 3.4 1.4 0.3 setosa 1.10 ## 8 4.6 3.6 1 0.2 setosa 0.8 ## 9 4.6 3.2 1.4 0.2 setosa 1.2 ## 10 4.7 3.2 1.3 0.2 setosa 1.1 ## # … with 40 more rows  # write_tsv(\"iris.txt\") # Export to file, omitted here to show result  Example 2 Series of summary calculations for grouped data (group_by)\niris_df %\u003e% # Declare tibble to use group_by(Species) %\u003e% # Group by species summarize(Mean_Sepal.Length=mean(Sepal.Length), Max_Sepal.Length=max(Sepal.Length), Min_Sepal.Length=min(Sepal.Length), SD_Sepal.Length=sd(Sepal.Length), Total=n())  ## # A tibble: 3 x 6 ## Species Mean_Sepal.Length Max_Sepal.Length Min_Sepal.Length SD_Sepal.Length Total ## \u003cchr\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cint\u003e ## 1 setosa 5.01 5.8 4.3 0.352 50 ## 2 versicolor 5.94 7 4.9 0.516 50 ## 3 virginica 6.59 7.9 4.9 0.636 50  Example 3 Combining dplyr chaining with ggplot\niris_df %\u003e% group_by(Species) %\u003e% summarize_all(mean) %\u003e% reshape2::melt(id.vars=c(\"Species\"), variable.name = \"Samples\", value.name=\"Values\") %\u003e% ggplot(aes(Samples, Values, fill = Species)) + geom_bar(position=\"dodge\", stat=\"identity\")  SQLite Databases SQLite is a lightweight relational database solution. The RSQLite package provides an easy to use interface to create, manage and query SQLite databases directly from R. Basic instructions for using SQLite from the command-line are available here. A short introduction to RSQLite is available here.\nLoading data into SQLite databases The following loads two data.frames derived from the iris data set (here mydf1 and mydf2) into an SQLite database (here test.db).\nlibrary(RSQLite) unlink(\"test.db\") # Delete any existing test.db mydb \u003c- dbConnect(SQLite(), \"test.db\") # Creates database file test.db mydf1 \u003c- data.frame(ids=paste0(\"id\", seq_along(iris[,1])), iris) mydf2 \u003c- mydf1[sample(seq_along(mydf1[,1]), 10),] dbWriteTable(mydb, \"mydf1\", mydf1) dbWriteTable(mydb, \"mydf2\", mydf2)  List names of tables in database dbListTables(mydb)  ## [1] \"mydf1\" \"mydf2\"  Import table into data.frame dbGetQuery(mydb, 'SELECT * FROM mydf2')  ## ids Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 id111 6.5 3.2 5.1 2.0 virginica ## 2 id106 7.6 3.0 6.6 2.1 virginica ## 3 id117 6.5 3.0 5.5 1.8 virginica ## 4 id61 5.0 2.0 3.5 1.0 versicolor ## 5 id50 5.0 3.3 1.4 0.2 setosa ## 6 id123 7.7 2.8 6.7 2.0 virginica ## 7 id60 5.2 2.7 3.9 1.4 versicolor ## 8 id92 6.1 3.0 4.6 1.4 versicolor ## 9 id32 5.4 3.4 1.5 0.4 setosa ## 10 id84 6.0 2.7 5.1 1.6 versicolor  Query database dbGetQuery(mydb, 'SELECT * FROM mydf1 WHERE \"Sepal.Length\" \u003c 4.6')  ## ids Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 id9 4.4 2.9 1.4 0.2 setosa ## 2 id14 4.3 3.0 1.1 0.1 setosa ## 3 id39 4.4 3.0 1.3 0.2 setosa ## 4 id42 4.5 2.3 1.3 0.3 setosa ## 5 id43 4.4 3.2 1.3 0.2 setosa  Join tables The two tables can be joined on the shared ids column as follows.\ndbGetQuery(mydb, 'SELECT * FROM mydf1, mydf2 WHERE mydf1.ids = mydf2.ids')  ## ids Sepal.Length Sepal.Width Petal.Length Petal.Width Species ids Sepal.Length ## 1 id32 5.4 3.4 1.5 0.4 setosa id32 5.4 ## 2 id50 5.0 3.3 1.4 0.2 setosa id50 5.0 ## 3 id60 5.2 2.7 3.9 1.4 versicolor id60 5.2 ## 4 id61 5.0 2.0 3.5 1.0 versicolor id61 5.0 ## 5 id84 6.0 2.7 5.1 1.6 versicolor id84 6.0 ## 6 id92 6.1 3.0 4.6 1.4 versicolor id92 6.1 ## 7 id106 7.6 3.0 6.6 2.1 virginica id106 7.6 ## 8 id111 6.5 3.2 5.1 2.0 virginica id111 6.5 ## 9 id117 6.5 3.0 5.5 1.8 virginica id117 6.5 ## 10 id123 7.7 2.8 6.7 2.0 virginica id123 7.7 ## Sepal.Width Petal.Length Petal.Width Species ## 1 3.4 1.5 0.4 setosa ## 2 3.3 1.4 0.2 setosa ## 3 2.7 3.9 1.4 versicolor ## 4 2.0 3.5 1.0 versicolor ## 5 2.7 5.1 1.6 versicolor ## 6 3.0 4.6 1.4 versicolor ## 7 3.0 6.6 2.1 virginica ## 8 3.2 5.1 2.0 virginica ## 9 3.0 5.5 1.8 virginica ## 10 2.8 6.7 2.0 virginica  Graphics in R Advantages  Powerful environment for visualizing scientific data Integrated graphics and statistics infrastructure Publication quality graphics Fully programmable Highly reproducible Full LaTeX and Markdown support via knitr and R markdown Vast number of R packages with graphics utilities  Documentation for R Graphics General\n Graphics Task Page - URL R Graph Gallery - URL R Graphical Manual - URL Paul Murrell’s book R (Grid) Graphics - URL  Interactive graphics\n rggobi` (GGobi) - URL iplots - URL Open GL (rgl) - URL  Graphics Environments Viewing and saving graphics in R\n On-screen graphics postscript, pdf, svg jpeg, png, wmf, tiff, …  Four major graphic environments\n Low-level infrastructure   R Base Graphics (low- and high-level) grid: Manual  High-level infrastructure \\begin{itemize}   lattice: Manual, Intro, Book ggplot2: Manual, Intro, Book  Base Graphics: Overview Important high-level plotting functions\n plot: generic x-y plotting barplot: bar plots boxplot: box-and-whisker plot hist: histograms pie: pie charts dotchart: cleveland dot plots image, heatmap, contour, persp: functions to generate image-like plots qqnorm, qqline, qqplot: distribution comparison plots pairs, coplot: display of multivariant data  Help on graphics functions\n ?myfct ?plot ?par  Preferred Object Types  Matrices and data frames Vectors Named vectors  Scatter Plots Basic Scatter Plot Sample data set for subsequent plots\nset.seed(1410) y \u003c- matrix(runif(30), ncol=3, dimnames=list(letters[1:10], LETTERS[1:3]))  Plot data\nplot(y[,1], y[,2])  All pairs pairs(y)  With labels plot(y[,1], y[,2], pch=20, col=\"red\", main=\"Symbols and Labels\") text(y[,1]+0.03, y[,2], rownames(y))  More examples Print instead of symbols the row names\nplot(y[,1], y[,2], type=\"n\", main=\"Plot of Labels\") text(y[,1], y[,2], rownames(y))  Usage of important plotting parameters\ngrid(5, 5, lwd = 2) op \u003c- par(mar=c(8,8,8,8), bg=\"lightblue\") plot(y[,1], y[,2], type=\"p\", col=\"red\", cex.lab=1.2, cex.axis=1.2, cex.main=1.2, cex.sub=1, lwd=4, pch=20, xlab=\"x label\", ylab=\"y label\", main=\"My Main\", sub=\"My Sub\") par(op)  __Important arguments_\n mar: specifies the margin sizes around the plotting area in order: c(bottom, left, top, right) col: color of symbols pch: type of symbols, samples: example(points) lwd: size of symbols cex.*: control font sizes For details see ?par  Add regression line plot(y[,1], y[,2]) myline \u003c- lm(y[,2]~y[,1]); abline(myline, lwd=2)  summary(myline)  ## ## Call: ## lm(formula = y[, 2] ~ y[, 1]) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.40357 -0.17912 -0.04299 0.22147 0.46623 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u003e|t|) ## (Intercept) 0.5764 0.2110 2.732 0.0258 * ## y[, 1] -0.3647 0.3959 -0.921 0.3839 ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## Residual standard error: 0.3095 on 8 degrees of freedom ## Multiple R-squared: 0.09589, Adjusted R-squared: -0.01712 ## F-statistic: 0.8485 on 1 and 8 DF, p-value: 0.3839  Log scale Same plot as above, but on log scale\nplot(y[,1], y[,2], log=\"xy\")  Add a mathematical expression plot(y[,1], y[,2]); text(y[1,1], y[1,2], expression(sum(frac(1,sqrt(x^2*pi)))), cex=1.3)  Homework 3B Homework 3B: Scatter Plots\nLine Plots Single data set plot(y[,1], type=\"l\", lwd=2, col=\"blue\")  Many Data Sets Plots line graph for all columns in data frame y. The split.screen function is used in this example in a for loop to overlay several line graphs in the same plot.\nsplit.screen(c(1,1))  ## [1] 1  plot(y[,1], ylim=c(0,1), xlab=\"Measurement\", ylab=\"Intensity\", type=\"l\", lwd=2, col=1) for(i in 2:length(y[1,])) { screen(1, new=FALSE) plot(y[,i], ylim=c(0,1), type=\"l\", lwd=2, col=i, xaxt=\"n\", yaxt=\"n\", ylab=\"\", xlab=\"\", main=\"\", bty=\"n\") }  close.screen(all=TRUE)  Bar Plots Basics barplot(y[1:4,], ylim=c(0, max(y[1:4,])+0.3), beside=TRUE, legend=letters[1:4]) text(labels=round(as.vector(as.matrix(y[1:4,])),2), x=seq(1.5, 13, by=1) + sort(rep(c(0,1,2), 4)), y=as.vector(as.matrix(y[1:4,]))+0.04)  Error Bars bar \u003c- barplot(m \u003c- rowMeans(y) * 10, ylim=c(0, 10)) stdev \u003c- sd(t(y)) arrows(bar, m, bar, m + stdev, length=0.15, angle = 90)  Histograms hist(y, freq=TRUE, breaks=10)  Density Plots plot(density(y), col=\"red\")  Pie Charts pie(y[,1], col=rainbow(length(y[,1]), start=0.1, end=0.8), clockwise=TRUE) legend(\"topright\", legend=row.names(y), cex=1.3, bty=\"n\", pch=15, pt.cex=1.8, col=rainbow(length(y[,1]), start=0.1, end=0.8), ncol=1)  Color Selection Utilities Default color palette and how to change it\npalette()  ## [1] \"black\" \"#DF536B\" \"#61D04F\" \"#2297E6\" \"#28E2E5\" \"#CD0BBC\" \"#F5C710\" \"gray62\"  palette(rainbow(5, start=0.1, end=0.2)) palette()  ## [1] \"#FF9900\" \"#FFBF00\" \"#FFE600\" \"#F2FF00\" \"#CCFF00\"  palette(\"default\")  The gray function allows to select any type of gray shades by providing values from 0 to 1\ngray(seq(0.1, 1, by= 0.2))  ## [1] \"#1A1A1A\" \"#4D4D4D\" \"#808080\" \"#B3B3B3\" \"#E6E6E6\"  Color gradients with colorpanel function from gplots library`\nlibrary(gplots) colorpanel(5, \"darkblue\", \"yellow\", \"white\")  ## [1] \"#00008B\" \"#808046\" \"#FFFF00\" \"#FFFF80\" \"#FFFFFF\"  Much more on colors in R see Earl Glynn’s color chart here\nSaving Graphics to File After the pdf() command all graphs are redirected to file test.pdf. Works for all common formats similarly: jpeg, png, ps, tiff, …\npdf(\"test.pdf\") plot(1:10, 1:10) dev.off()  Generates Scalable Vector Graphics (SVG) files that can be edited in vector graphics programs, such as InkScape.\nlibrary(\"RSvgDevice\") devSVG(\"test.svg\") plot(1:10, 1:10) dev.off()  Homework 3C Homework 3C: Bar Plots\nAnalysis Routine Overview The following exercise introduces a variety of useful data analysis utilities in R.\nAnalysis Routine: Data Import   Step 1: To get started with this exercise, direct your R session to a dedicated workshop directory and download into this directory the following sample tables. Then import the files into Excel and save them as tab delimited text files.\n MolecularWeight_tair7.xls TargetP_analysis_tair7.xls    Import the tables into R\nImport molecular weight table\nmy_mw \u003c- read.delim(file=\"MolecularWeight_tair7.xls\", header=T, sep=\"\\t\") my_mw[1:2,]  Import subcelluar targeting table\nmy_target \u003c- read.delim(file=\"TargetP_analysis_tair7.xls\", header=T, sep=\"\\t\") my_target[1:2,]  Online import of molecular weight table\nmy_mw \u003c- read.delim(file=\"http://faculty.ucr.edu/~tgirke/Documents/R_BioCond/Samples/MolecularWeight_tair7.xls\", header=T, sep=\"\\t\") my_mw[1:2,]  ## Sequence.id Molecular.Weight.Da. Residues ## 1 AT1G08520.1 83285 760 ## 2 AT1G08530.1 27015 257  Online import of subcelluar targeting table\nmy_target \u003c- read.delim(file=\"http://faculty.ucr.edu/~tgirke/Documents/R_BioCond/Samples/TargetP_analysis_tair7.xls\", header=T, sep=\"\\t\") my_target[1:2,]  ## GeneName Loc cTP mTP SP other ## 1 AT1G08520.1 C 0.822 0.137 0.029 0.039 ## 2 AT1G08530.1 C 0.817 0.058 0.010 0.100  Merging Data Frames  Step 2: Assign uniform gene ID column titles  colnames(my_target)[1] \u003c- \"ID\" colnames(my_mw)[1] \u003c- \"ID\"   Step 3: Merge the two tables based on common ID field  my_mw_target \u003c- merge(my_mw, my_target, by.x=\"ID\", by.y=\"ID\", all.x=T)   Step 4: Shorten one table before the merge and then remove the non-matching rows (NAs) in the merged file  my_mw_target2a \u003c- merge(my_mw, my_target[1:40,], by.x=\"ID\", by.y=\"ID\", all.x=T) # To remove non-matching rows, use the argument setting 'all=F'. my_mw_target2 \u003c- na.omit(my_mw_target2a) # Removes rows containing \"NAs\" (non-matching rows).   Homework 3D: How can the merge function in the previous step be executed so that only the common rows among the two data frames are returned? Prove that both methods - the two step version with na.omit and your method - return identical results. Homework 3E: Replace all NAs in the data frame my_mw_target2a with zeros.  Filtering Data  Step 5: Retrieve all records with a value of greater than 100,000 in ‘MW’ column and ‘C’ value in ‘Loc’ column (targeted to chloroplast).  query \u003c- my_mw_target[my_mw_target[, 2] \u003e 100000 \u0026 my_mw_target[, 4] == \"C\", ] query[1:4, ]  ## ID Molecular.Weight.Da. Residues Loc cTP mTP SP other ## 219 AT1G02730.1 132588 1181 C 0.972 0.038 0.008 0.045 ## 243 AT1G02890.1 136825 1252 C 0.748 0.529 0.011 0.013 ## 281 AT1G03160.1 100732 912 C 0.871 0.235 0.011 0.007 ## 547 AT1G05380.1 126360 1138 C 0.740 0.099 0.016 0.358  dim(query)  ## [1] 170 8   Homework 3F: How many protein entries in the my_mw_target data frame have a MW of greater then 4,000 and less then 5,000. Subset the data frame accordingly and sort it by MW to check that your result is correct.  String Substitutions  Step 6: Use a regular expression in a substitute function to generate a separate ID column that lacks the gene model extensions. \u003c\u003clabel=Exercise 4.7, eval=TRUE, echo=TRUE, keep.source=TRUE\u003e\u003e=  my_mw_target3 \u003c- data.frame(loci=gsub(\"\\\\..*\", \"\", as.character(my_mw_target[,1]), perl = TRUE), my_mw_target) my_mw_target3[1:3,1:8]  ## loci ID Molecular.Weight.Da. Residues Loc cTP mTP SP ## 1 AT1G01010 AT1G01010.1 49426 429 _ 0.10 0.090 0.075 ## 2 AT1G01020 AT1G01020.1 28092 245 * 0.01 0.636 0.158 ## 3 AT1G01020 AT1G01020.2 21711 191 * 0.01 0.636 0.158   Homework 3G: Retrieve those rows in my_mw_target3 where the second column contains the following identifiers: c(\"AT5G52930.1\", \"AT4G18950.1\", \"AT1G15385.1\", \"AT4G36500.1\", \"AT1G67530.1\"). Use the %in% function for this query. As an alternative approach, assign the second column to the row index of the data frame and then perform the same query again using the row index. Explain the difference of the two methods.  Calculations on Data Frames  Step 7: Count the number of duplicates in the loci column with the table function and append the result to the data frame with the cbind function.  mycounts \u003c- table(my_mw_target3[,1])[my_mw_target3[,1]] my_mw_target4 \u003c- cbind(my_mw_target3, Freq=mycounts[as.character(my_mw_target3[,1])])   Step 8: Perform a vectorized devision of columns 3 and 4 (average AA weight per protein)  data.frame(my_mw_target4, avg_AA_WT=(my_mw_target4[,3] / my_mw_target4[,4]))[1:2,5:11]  ## Loc cTP mTP SP other Freq.Var1 Freq.Freq ## 1 _ 0.10 0.090 0.075 0.925 AT1G01010 1 ## 2 * 0.01 0.636 0.158 0.448 AT1G01020 2   Step 9: Calculate for each row the mean and standard deviation across several columns  mymean \u003c- apply(my_mw_target4[,6:9], 1, mean) mystdev \u003c- apply(my_mw_target4[,6:9], 1, sd, na.rm=TRUE) data.frame(my_mw_target4, mean=mymean, stdev=mystdev)[1:2,5:12]  ## Loc cTP mTP SP other Freq.Var1 Freq.Freq mean ## 1 _ 0.10 0.090 0.075 0.925 AT1G01010 1 0.2975 ## 2 * 0.01 0.636 0.158 0.448 AT1G01020 2 0.3130  Plotting Example  Step 10: Generate scatter plot columns: ‘MW’ and ‘Residues’  plot(my_mw_target4[1:500,3:4], col=\"red\")  Export Results and Run Entire Exercise as Script  Step 11: Write the data frame my_mw_target4 into a tab-delimited text file and inspect it in Excel.  write.table(my_mw_target4, file=\"my_file.xls\", quote=F, sep=\"\\t\", col.names = NA)   Homework 3H: Write all commands from this exercise into an R script named exerciseRbasics.R, or download it from here. Then execute the script with the source function like this: source(\"exerciseRbasics.R\"). This will run all commands of this exercise and generate the corresponding output files in the current working directory.  source(\"exerciseRbasics.R\")  R Markdown Overview R Markdown combines markdown (an easy to write plain text format) with embedded R code chunks. When compiling R Markdown documents, the code components can be evaluated so that both the code and its output can be included in the final document. This makes analysis reports highly reproducible by allowing to automatically regenerate them when the underlying R code or data changes. R Markdown documents (.Rmd files) can be rendered to various formats including HTML and PDF. The R code in an .Rmd document is processed by knitr, while the resulting .md file is rendered by pandoc to the final output formats (e.g. HTML or PDF). Historically, R Markdown is an extension of the older Sweave/Latex environment. Rendering of mathematical expressions and reference management is also supported by R Markdown using embedded Latex syntax and Bibtex, respectively.\nQuick Start Install R Markdown install.packages(\"rmarkdown\")  Initialize a new R Markdown (Rmd) script To minimize typing, it can be helful to start with an R Markdown template and then modify it as needed. Note the file name of an R Markdown scirpt needs to have the extension .Rmd. Template files for the following examples are available here:\n R Markdown sample script: sample.Rmd Bibtex file for handling citations and reference section: bibtex.bib  Users want to download these files, open the sample.Rmd file with their preferred R IDE (e.g. RStudio, vim or emacs), initilize an R session and then direct their R session to the location of these two files.\nMetadata section The metadata section (YAML header) in an R Markdown script defines how it will be processed and rendered. The metadata section also includes both title, author, and date information as well as options for customizing the output format. For instance, PDF and HTML output can be defined with pdf_document and html_document, respectively. The BiocStyle:: prefix will use the formatting style of the BiocStyle package from Bioconductor.\n --- title: \"My First R Markdown Document\" author: \"Author: First Last\" date: \"Last update: 20 February, 2021\" output: BiocStyle::html_document: toc: true toc_depth: 3 fig_caption: yes fontsize: 14pt bibliography: bibtex.bib ---  Render Rmd script An R Markdown script can be evaluated and rendered with the following render command or by pressing the knit button in RStudio. The output_format argument defines the format of the output (e.g. html_document). The setting output_format=\"all\" will generate all supported output formats. Alternatively, one can specify several output formats in the metadata section as shown in the above example.\nrmarkdown::render(\"sample.Rmd\", clean=TRUE, output_format=\"html_document\")  The following shows two options how to run the rendering from the command-line.\n$ Rscript -e \"rmarkdown::render('sample.Rmd', clean=TRUE)\"  Alternatively, one can use a Makefile to evaluate and render an R Markdown script. A sample Makefile for rendering the above sample.Rmd can be downloaded here. To apply it to a custom Rmd file, one needs open the Makefile in a text editor and change the value assigned to MAIN (line 13) to the base name of the corresponding .Rmd file (e.g. assign systemPipeRNAseq if the file name is systemPipeRNAseq.Rmd). To execute the Makefile, run the following command from the command-line.\n$ make -B  R code chunks R Code Chunks can be embedded in an R Markdown script by using three backticks at the beginning of a new line along with arguments enclosed in curly braces controlling the behavior of the code. The following lines contain the plain R code. A code chunk is terminated by a new line starting with three backticks. The following shows an example of such a code chunk. Note the backslashes are not part of it. They have been added to print the code chunk syntax in this document.\n ```\\{r code_chunk_name, eval=FALSE\\} x \u003c- 1:10 ```  The following lists the most important arguments to control the behavior of R code chunks:\n r: specifies language for code chunk, here R chode_chunk_name: name of code chunk; this name needs to be unique eval: if assigned TRUE the code will be evaluated warning: if assigned FALSE warnings will not be shown message: if assigned FALSE messages will not be shown cache: if assigned TRUE results will be cached to reuse in future rendering instances fig.height: allows to specify height of figures in inches fig.width: allows to specify width of figures in inches  For more details on code chunk options see here.\nLearning Markdown The basic syntax of Markdown and derivatives like kramdown is extremely easy to learn. Rather than providing another introduction on this topic, here are some useful sites for learning Markdown:\n Markdown Intro on GitHub Markdown Cheet Sheet Markdown Basics from RStudio R Markdown Cheat Sheet kramdown Syntax  Tables There are several ways to render tables. First, they can be printed within the R code chunks. Second, much nicer formatted tables can be generated with the functions kable, pander or xtable. The following example uses kable from the knitr package.\nlibrary(knitr) kable(iris[1:12,])     Sepal.Length Sepal.Width Petal.Length Petal.Width Species     5.1 3.5 1.4 0.2 setosa   4.9 3.0 1.4 0.2 setosa   4.7 3.2 1.3 0.2 setosa   4.6 3.1 1.5 0.2 setosa   5.0 3.6 1.4 0.2 setosa   5.4 3.9 1.7 0.4 setosa   4.6 3.4 1.4 0.3 setosa   5.0 3.4 1.5 0.2 setosa   4.4 2.9 1.4 0.2 setosa   4.9 3.1 1.5 0.1 setosa   5.4 3.7 1.5 0.2 setosa   4.8 3.4 1.6 0.2 setosa    A much more elegant and powerful solution is to create fully interactive tables with the DT package. This JavaScirpt based environment provides a wrapper to the DataTables library using jQuery. The resulting tables can be sorted, queried and resized by the user. For an example see here.\nlibrary(DT) datatable(iris, filter = 'top', options = list( pageLength = 100, scrollX = TRUE, scrollY = \"600px\", autoWidth = TRUE ))   {\"x\":{\"filter\":\"top\",\"filterHTML\":\"\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\",\"101\",\"102\",\"103\",\"104\",\"105\",\"106\",\"107\",\"108\",\"109\",\"110\",\"111\",\"112\",\"113\",\"114\",\"115\",\"116\",\"117\",\"118\",\"119\",\"120\",\"121\",\"122\",\"123\",\"124\",\"125\",\"126\",\"127\",\"128\",\"129\",\"130\",\"131\",\"132\",\"133\",\"134\",\"135\",\"136\",\"137\",\"138\",\"139\",\"140\",\"141\",\"142\",\"143\",\"144\",\"145\",\"146\",\"147\",\"148\",\"149\",\"150\"],[5.1,4.9,4.7,4.6,5,5.4,4.6,5,4.4,4.9,5.4,4.8,4.8,4.3,5.8,5.7,5.4,5.1,5.7,5.1,5.4,5.1,4.6,5.1,4.8,5,5,5.2,5.2,4.7,4.8,5.4,5.2,5.5,4.9,5,5.5,4.9,4.4,5.1,5,4.5,4.4,5,5.1,4.8,5.1,4.6,5.3,5,7,6.4,6.9,5.5,6.5,5.7,6.3,4.9,6.6,5.2,5,5.9,6,6.1,5.6,6.7,5.6,5.8,6.2,5.6,5.9,6.1,6.3,6.1,6.4,6.6,6.8,6.7,6,5.7,5.5,5.5,5.8,6,5.4,6,6.7,6.3,5.6,5.5,5.5,6.1,5.8,5,5.6,5.7,5.7,6.2,5.1,5.7,6.3,5.8,7.1,6.3,6.5,7.6,4.9,7.3,6.7,7.2,6.5,6.4,6.8,5.7,5.8,6.4,6.5,7.7,7.7,6,6.9,5.6,7.7,6.3,6.7,7.2,6.2,6.1,6.4,7.2,7.4,7.9,6.4,6.3,6.1,7.7,6.3,6.4,6,6.9,6.7,6.9,5.8,6.8,6.7,6.7,6.3,6.5,6.2,5.9],[3.5,3,3.2,3.1,3.6,3.9,3.4,3.4,2.9,3.1,3.7,3.4,3,3,4,4.4,3.9,3.5,3.8,3.8,3.4,3.7,3.6,3.3,3.4,3,3.4,3.5,3.4,3.2,3.1,3.4,4.1,4.2,3.1,3.2,3.5,3.6,3,3.4,3.5,2.3,3.2,3.5,3.8,3,3.8,3.2,3.7,3.3,3.2,3.2,3.1,2.3,2.8,2.8,3.3,2.4,2.9,2.7,2,3,2.2,2.9,2.9,3.1,3,2.7,2.2,2.5,3.2,2.8,2.5,2.8,2.9,3,2.8,3,2.9,2.6,2.4,2.4,2.7,2.7,3,3.4,3.1,2.3,3,2.5,2.6,3,2.6,2.3,2.7,3,2.9,2.9,2.5,2.8,3.3,2.7,3,2.9,3,3,2.5,2.9,2.5,3.6,3.2,2.7,3,2.5,2.8,3.2,3,3.8,2.6,2.2,3.2,2.8,2.8,2.7,3.3,3.2,2.8,3,2.8,3,2.8,3.8,2.8,2.8,2.6,3,3.4,3.1,3,3.1,3.1,3.1,2.7,3.2,3.3,3,2.5,3,3.4,3],[1.4,1.4,1.3,1.5,1.4,1.7,1.4,1.5,1.4,1.5,1.5,1.6,1.4,1.1,1.2,1.5,1.3,1.4,1.7,1.5,1.7,1.5,1,1.7,1.9,1.6,1.6,1.5,1.4,1.6,1.6,1.5,1.5,1.4,1.5,1.2,1.3,1.4,1.3,1.5,1.3,1.3,1.3,1.6,1.9,1.4,1.6,1.4,1.5,1.4,4.7,4.5,4.9,4,4.6,4.5,4.7,3.3,4.6,3.9,3.5,4.2,4,4.7,3.6,4.4,4.5,4.1,4.5,3.9,4.8,4,4.9,4.7,4.3,4.4,4.8,5,4.5,3.5,3.8,3.7,3.9,5.1,4.5,4.5,4.7,4.4,4.1,4,4.4,4.6,4,3.3,4.2,4.2,4.2,4.3,3,4.1,6,5.1,5.9,5.6,5.8,6.6,4.5,6.3,5.8,6.1,5.1,5.3,5.5,5,5.1,5.3,5.5,6.7,6.9,5,5.7,4.9,6.7,4.9,5.7,6,4.8,4.9,5.6,5.8,6.1,6.4,5.6,5.1,5.6,6.1,5.6,5.5,4.8,5.4,5.6,5.1,5.1,5.9,5.7,5.2,5,5.2,5.4,5.1],[0.2,0.2,0.2,0.2,0.2,0.4,0.3,0.2,0.2,0.1,0.2,0.2,0.1,0.1,0.2,0.4,0.4,0.3,0.3,0.3,0.2,0.4,0.2,0.5,0.2,0.2,0.4,0.2,0.2,0.2,0.2,0.4,0.1,0.2,0.2,0.2,0.2,0.1,0.2,0.2,0.3,0.3,0.2,0.6,0.4,0.3,0.2,0.2,0.2,0.2,1.4,1.5,1.5,1.3,1.5,1.3,1.6,1,1.3,1.4,1,1.5,1,1.4,1.3,1.4,1.5,1,1.5,1.1,1.8,1.3,1.5,1.2,1.3,1.4,1.4,1.7,1.5,1,1.1,1,1.2,1.6,1.5,1.6,1.5,1.3,1.3,1.3,1.2,1.4,1.2,1,1.3,1.2,1.3,1.3,1.1,1.3,2.5,1.9,2.1,1.8,2.2,2.1,1.7,1.8,1.8,2.5,2,1.9,2.1,2,2.4,2.3,1.8,2.2,2.3,1.5,2.3,2,2,1.8,2.1,1.8,1.8,1.8,2.1,1.6,1.9,2,2.2,1.5,1.4,2.3,2.4,1.8,1.8,2.1,2.4,2.3,1.9,2.3,2.5,2.3,1.9,2,2.3,1.8],[\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\"]],\"container\":\"\\n \\n \\n  \\n Sepal.Length\\n Sepal.Width\\n Petal.Length\\n Petal.Width\\n Species\\n \\n \\n\",\"options\":{\"pageLength\":100,\"scrollX\":true,\"scrollY\":\"600px\",\"autoWidth\":true,\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,2,3,4]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"orderClasses\":false,\"orderCellsTop\":true}},\"evals\":[],\"jsHooks\":[]} Figures Plots generated by the R code chunks in an R Markdown document can be automatically inserted in the output file. The size of the figure can be controlled with the fig.height and fig.width arguments.\nlibrary(ggplot2) dsmall \u003c- diamonds[sample(nrow(diamonds), 1000), ] ggplot(dsmall, aes(color, price/carat)) + geom_jitter(alpha = I(1 / 2), aes(color=color))  Sometimes it can be useful to explicitly write an image to a file and then insert that image into the final document by referencing its file name in the R Markdown source. For instance, this can be useful for time consuming analyses. The following code will generate a file named myplot.png. To insert the file in the final document, one can use standard Markdown or HTML syntax, e.g.: \u003cimg src=\"myplot.png\"/\u003e.\npng(\"images/myplot.png\") ggplot(dsmall, aes(color, price/carat)) + geom_jitter(alpha = I(1 / 2), aes(color=color)) dev.off()  ## png ## 2    Inline R code To evaluate R code inline, one can enclose an R expression with a single back-tick followed by r and then the actual expression. For instance, the back-ticked version of ‘r 1 + 1’ evaluates to 2 and ‘r pi’ evaluates to 3.1415927.\nMathematical equations To render mathematical equations, one can use standard Latex syntax. When expressions are enclosed with single $ signs then they will be shown inline, while enclosing them with double $$ signs will show them in display mode. For instance, the following Latex syntax d(X,Y) = \\sqrt[]{ \\sum_{i=1}^{n}{(x_{i}-y_{i})^2} } renders in display mode as follows:\n$$d(X,Y) = \\sqrt[]{ \\sum_{i=1}^{n}{(x_{i}-y_{i})^2} }$$\nCitations and bibliographies Citations and bibliographies can be autogenerated in R Markdown in a similar way as in Latex/Bibtex. Reference collections should be stored in a separate file in Bibtex or other supported formats. To cite a publication in an R Markdown script, one uses the syntax [@\u003cid1\u003e] where \u003cid1\u003e needs to be replaced with a reference identifier present in the Bibtex database listed in the metadata section of the R Markdown script (e.g. bibtex.bib). For instance, to cite Lawrence et al. (2013), one uses its reference identifier (e.g. Lawrence2013-kt) as \u003cid1\u003e (Lawrence et al. 2013). This will place the citation inline in the text and add the corresponding reference to a reference list at the end of the output document. For the latter a special section called References needs to be specified at the end of the R Markdown script. To fine control the formatting of citations and reference lists, users want to consult this the corresponding R Markdown page. Also, for general reference management and outputting references in Bibtex format Paperpile can be very helpful.\nViewing R Markdown report on HPCC cluster R Markdown reports located on UCR’s HPCC Cluster can be viewed locally in a web browser (without moving the source HTML) by creating a symbolic link from a user’s .html directory. This way any updates to the report can be viewed immediately without creating another copy of the HTML file. For instance, if user ttest has generated an R Markdown report under ~/bigdata/today/rmarkdown/sample.html, then the proper symbolic link to this file can be created as follows:\ncd ~/.html ln -s ~/bigdata/today/rmarkdown/sample.html sample.html  After this one can view the report in a web browser using this URL http://biocluster.ucr.edu/~ttest/rmarkdown/sample.html. If necessary access to the URL can be restricted with a password following the instructions here.\nA sample R Markdown report for an RNA-Seq project is given here:\n RNASeq.html{:target=\"_blank\"} RNASeq.Rmd{:target=\"_blank\"}  Shiny Web Apps What is Shiny? Shiny is an R-based environment for building interactive web applications for data analysis and exploration. Since most JavaScript code is autogenerated by the environment, basic R knowledge is sufficient for developing Shiny apps. They can be deployed on local computers or web servers including custom and cloud-based servers ( e.g. AWS, GCP, shinyapp.io service). The basic structure of a Shiny app is an app.R script containing the following components:\n  User interface\nui \u003c- fluidPage()    Server function\nserver \u003c- function(input, output) {}    Statement to run shiny app\nshinyApp(ui = ui, server = server)    Alternatively, the ui and server functions can be organized in two script files, a ui.R and a server.R script, respectively.\nDevelop and test Shiny app locally Open R and set session to parent directory (here myappdir) containing shiny script app.R, and the run it with the runApp() function. A sample app.R script for testing can be downloaded from here.\nlibrary(shiny) runApp(\"myappdir\") # To show code in app, add argument: display.mode=\"showcase\"  This will open the app in a web browser.\nDeploy on web server This can be done on local or cloud systems. An easy solution is to get an account on shinyapps.io and then deploy Shiny apps there. For details, see here.\nsetwd(\"myappdir\") library(rsconnect) deployApp()  Example Shiny app The following Shiny app is hosted on shinyapps.io and embedded into the markdown (or html) source of this page using the following iframe syntax:\n\u003ciframe src=\"https://tgirke.shinyapps.io/diamonds/\" style=\"border: none; width: 880px; height: 900px\"\u003e\u003c/iframe\u003e   Learning Shiny The Shiny section on the Rstudio site contains excellent tutorials. In addition, users may want to explore the example apps included in the shiny package. This can be done by loading the individual examples (see here) or saving the code to a user writable directory like this:\nmydir \u003c- system.file(\"examples\", package=\"shiny\") dir.create('my_shiny_test_dir') file.copy(mydir, \"my_shiny_test_dir\", recursive=TRUE) setwd(\"my_shiny_test_dir/examples\") runApp(\"01_hello\") # Runs first example app in directory dir() # Lists available Shiny examples (directories).  Session Info sessionInfo()  ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C LC_TIME=en_US.UTF-8 ## [4] LC_COLLATE=en_US.UTF-8 LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C LC_ADDRESS=C ## [10] LC_TELEPHONE=C LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] DT_0.16 knitr_1.30 gplots_3.1.1 RSQLite_2.2.1 data.table_1.13.2 ## [6] forcats_0.5.0 stringr_1.4.0 dplyr_1.0.2 purrr_0.3.4 readr_1.4.0 ## [11] tidyr_1.1.2 tibble_3.0.4 tidyverse_1.3.0 ggplot2_3.3.2 limma_3.46.0 ## [16] BiocStyle_2.18.0 ## ## loaded via a namespace (and not attached): ## [1] httr_1.4.2 viridisLite_0.3.0 bit64_4.0.5 jsonlite_1.7.1 ## [5] modelr_0.1.8 gtools_3.8.2 assertthat_0.2.1 BiocManager_1.30.10 ## [9] highr_0.8 blob_1.2.1 cellranger_1.1.0 yaml_2.2.1 ## [13] pillar_1.4.7 backports_1.2.0 glue_1.4.2 digest_0.6.27 ## [17] rvest_0.3.6 colorspace_2.0-0 htmltools_0.5.1.1 plyr_1.8.6 ## [21] pkgconfig_2.0.3 broom_0.7.2 haven_2.3.1 bookdown_0.21 ## [25] scales_1.1.1 generics_0.1.0 farver_2.0.3 ellipsis_0.3.1 ## [29] withr_2.3.0 cli_2.2.0 magrittr_2.0.1 crayon_1.3.4 ## [33] readxl_1.3.1 memoise_1.1.0 evaluate_0.14 ps_1.4.0 ## [37] fs_1.5.0 fansi_0.4.1 xml2_1.3.2 blogdown_1.1.7 ## [41] tools_4.0.4 hms_0.5.3 lifecycle_0.2.0 munsell_0.5.0 ## [45] reprex_0.3.0 compiler_4.0.4 caTools_1.18.1 rlang_0.4.8 ## [49] grid_4.0.4 rstudioapi_0.13 htmlwidgets_1.5.2 crosstalk_1.1.0.1 ## [53] bitops_1.0-6 labeling_0.4.2 rmarkdown_2.5 gtable_0.3.0 ## [57] codetools_0.2-18 DBI_1.1.0 reshape2_1.4.4 R6_2.5.0 ## [61] lubridate_1.7.9.2 bit_4.0.4 utf8_1.1.4 KernSmooth_2.23-18 ## [65] stringi_1.5.3 Rcpp_1.0.5 vctrs_0.3.5 dbplyr_2.0.0 ## [69] tidyselect_1.1.0 xfun_0.20  References Lawrence, Michael, Wolfgang Huber, Hervé Pagès, Patrick Aboyoun, Marc Carlson, Robert Gentleman, Martin T Morgan, and Vincent J Carey. 2013. “Software for Computing and Annotating Genomic Ranges.” PLoS Comput. Biol. 9 (8): e1003118. https://doi.org/10.1371/journal.pcbi.1003118.\n  ","categories":"","description":"","excerpt":"       document.addEventListener(\"DOMContentLoaded\", function() { …","ref":"/manuals/rbasics/rbasics/","tags":"","title":"Introduction to R"},{"body":"document.addEventListener(\"DOMContentLoaded\", function() { document.querySelector(\"h1\").className = \"title\"; });  document.addEventListener(\"DOMContentLoaded\", function() { var links = document.links; for (var i = 0, linksLength = links.length; i Source code downloads: [ .Rmd ] [ .R ]\n Overview What is R? R is a powerful statistical environment and programming language for the analysis and visualization of data. The associated Bioconductor and CRAN package repositories provide many additional R packages for statistical data analysis for a wide array of research areas. The R software is free and runs on all common operating systems.\nWhy Using R?  Complete statistical environment and programming language Efficient functions and data structures for data analysis Powerful graphics Access to fast growing number of analysis packages Most widely used language in bioinformatics Is standard for data mining and biostatistical analysis Technical advantages: free, open-source, available for all OSs  Books and Documentation  simpleR - Using R for Introductory Statistics (John Verzani, 2004) - URL Bioinformatics and Computational Biology Solutions Using R and Bioconductor (Gentleman et al., 2005) - URL More on this see “Finding Help” section in UCR Manual - URL  R Working Environments    R Projects and Interfaces\n Some R working environments with support for syntax highlighting and utilities to send code to the R console:\n RStudio: excellent choice for beginners (Cheat Sheet) Basic R code editors provided by Rguis gedit, Rgedit, RKWard, Eclipse, Tinn-R, Notepad++, NppToR Vim-R-Tmux: R working environment based on vim and tmux Emacs (ESS add-on package)  Example: RStudio New integrated development environment (IDE) for R. Highly functional for both beginners and advanced.\n   RStudio IDE\n Some userful shortcuts: Ctrl+Enter (send code), Ctrl+Shift+C (comment/uncomment), Ctrl+1/2 (switch window focus)\nExample: Nvim-R-Tmux Terminal-based Working Environment for R: Nvim-R-Tmux.\n   Nvim-R-Tmux IDE for R\n R Package Repositories  CRAN (\u003e14,000 packages) general data analysis - URL Bioconductor (\u003e2,000 packages) bioscience data analysis - URL Omegahat (\u003e90 packages) programming interfaces - URL RStudio packages - URL  Installation of R, RStudio and R Packages   Install R for your operating system from CRAN.\n  Install RStudio from RStudio.\n  Install CRAN Packages from R console like this:\ninstall.packages(c(\"pkg1\", \"pkg2\")) install.packages(\"pkg.zip\", repos=NULL)    Install Bioconductor packages as follows:\nif (!requireNamespace(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\") # Installs BiocManager if not available yet BiocManager::version() # Reports Bioconductor version BiocManager::install(c(\"pkg1\", \"pkg2\")) # Installs packages specified under \"pkg1\"    For more details consult the Bioc Install page and BiocInstaller package.\n  Getting Around Startup and Closing Behavior   Starting R: The R GUI versions, including RStudio, under Windows and Mac OS X can be opened by double-clicking their icons. Alternatively, one can start it by typing R in a terminal (default under Linux).\n  Startup/Closing Behavior: The R environment is controlled by hidden files in the startup directory: .RData, .Rhistory and .Rprofile (optional).\n  Closing R:\n  q()  Save workspace image? [y/n/c]:   Note: When responding with y, then the entire R workspace will be written to the .RData file which can become very large. Often it is better to select n here, because a much better working pratice is to save an analysis protocol to an R or Rmd source file. This way one can quickly regenerate all data sets and objects needed in a future session.  Navigating directories List objects in current R session\nls()  Return content of current working directory\ndir()  Return path of current working directory\ngetwd()  Change current working directory\nsetwd(\"/home/user\")  Basic Syntax Create an object with the assignment operator \u003c- or =\nobject \u003c- ...  General R command syntax\nobject \u003c- function_name(arguments) object \u003c- object[arguments]  Instead of the assignment operator one can use the assign function\nassign(\"x\", function(arguments))  Finding help\n?function_name  Load a library/package\nlibrary(\"my_library\")  List functions defined by a library\nlibrary(help=\"my_library\")  Load library manual (PDF or HTML file)\nvignette(\"my_library\")  Execute an R script from within R\nsource(\"my_script.R\")  Execute an R script from command-line (the first of the three options is preferred)\n$ Rscript my_script.R $ R CMD BATCH my_script.R $ R --slave \u003c my_script.R  Data Types Numeric data Example: 1, 2, 3, ...\nx \u003c- c(1, 2, 3) x  ## [1] 1 2 3  is.numeric(x)  ## [1] TRUE  as.character(x)  ## [1] \"1\" \"2\" \"3\"  Character data Example: \"a\", \"b\", \"c\", ...\nx \u003c- c(\"1\", \"2\", \"3\") x  ## [1] \"1\" \"2\" \"3\"  is.character(x)  ## [1] TRUE  as.numeric(x)  ## [1] 1 2 3  Complex data Example: mix of both\nc(1, \"b\", 3)  ## [1] \"1\" \"b\" \"3\"  Logical data Example: TRUE of FALSE\nx \u003c- 1:10 \u003c 5 x  ## [1] TRUE TRUE TRUE TRUE FALSE FALSE FALSE FALSE FALSE FALSE  !x  ## [1] FALSE FALSE FALSE FALSE TRUE TRUE TRUE TRUE TRUE TRUE  which(x) # Returns index for the 'TRUE' values in logical vector  ## [1] 1 2 3 4  Data Objects Object types Vectors (1D) Definition: numeric or character\nmyVec \u003c- 1:10; names(myVec) \u003c- letters[1:10] myVec \u003c- setNames(1:10, letters[1:10]) # Same as above in single step myVec[1:5]  ## a b c d e ## 1 2 3 4 5  myVec[c(2,4,6,8)]  ## b d f h ## 2 4 6 8  myVec[c(\"b\", \"d\", \"f\")]  ## b d f ## 2 4 6  Factors (1D) Definition: vectors with grouping information\nfactor(c(\"dog\", \"cat\", \"mouse\", \"dog\", \"dog\", \"cat\"))  ## [1] dog cat mouse dog dog cat ## Levels: cat dog mouse  Matrices (2D) Definition: two dimensional structures with data of same type\nmyMA \u003c- matrix(1:30, 3, 10, byrow = TRUE) class(myMA)  ## [1] \"matrix\" \"array\"  myMA[1:2,]  ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] 1 2 3 4 5 6 7 8 9 10 ## [2,] 11 12 13 14 15 16 17 18 19 20  myMA[1, , drop=FALSE]  ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] 1 2 3 4 5 6 7 8 9 10  Data Frames (2D) Definition: data.frames are two dimensional objects with data of variable types\nmyDF \u003c- data.frame(Col1=1:10, Col2=10:1) myDF[1:2, ]  ## Col1 Col2 ## 1 1 10 ## 2 2 9  Tibbles Tibbles are a more modern version of data.frames. Among many other advantages, one can see here that tibbles have a nicer printing bahavior. Much more detailed information on this object class is provided in the dplyr/tidyverse manual section.\nlibrary(tidyverse) as_tibble(iris)  ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cfct\u003e ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## # … with 140 more rows  Arrays Definition: data structure with one, two or more dimensions\nLists Definition: containers for any object type\nmyL \u003c- list(name=\"Fred\", wife=\"Mary\", no.children=3, child.ages=c(4,7,9)) myL  ## $name ## [1] \"Fred\" ## ## $wife ## [1] \"Mary\" ## ## $no.children ## [1] 3 ## ## $child.ages ## [1] 4 7 9  myL[[4]][1:2]  ## [1] 4 7  Functions Definition: piece of code\nmyfct \u003c- function(arg1, arg2, ...) { function_body }  Subsetting of data objects (1.) Subsetting by positive or negative index/position numbers\nmyVec \u003c- 1:26; names(myVec) \u003c- LETTERS myVec[1:4]  ## A B C D ## 1 2 3 4  (2.) Subsetting by same length logical vectors\nmyLog \u003c- myVec \u003e 10 myVec[myLog]  ## K L M N O P Q R S T U V W X Y Z ## 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  (3.) Subsetting by field names\nmyVec[c(\"B\", \"K\", \"M\")]  ## B K M ## 2 11 13  (4.) Subset with $ sign: references a single column or list component by its name\niris$Species[1:8]  ## [1] setosa setosa setosa setosa setosa setosa setosa setosa ## Levels: setosa versicolor virginica  Important Utilities Combining Objects The c function combines vectors and lists\nc(1, 2, 3)  ## [1] 1 2 3  x \u003c- 1:3; y \u003c- 101:103 c(x, y)  ## [1] 1 2 3 101 102 103  The cbind and rbind functions can be used to append columns and rows, respecively.\nma \u003c- cbind(x, y) ma  ## x y ## [1,] 1 101 ## [2,] 2 102 ## [3,] 3 103  rbind(ma, ma)  ## x y ## [1,] 1 101 ## [2,] 2 102 ## [3,] 3 103 ## [4,] 1 101 ## [5,] 2 102 ## [6,] 3 103  Accessing Dimensions of Objects Length and dimension information of objects\nlength(iris$Species)  ## [1] 150  dim(iris)  ## [1] 150 5  Accessing Name Slots of Objects Accessing row and column names of 2D objects\nrownames(iris)[1:8]  ## [1] \"1\" \"2\" \"3\" \"4\" \"5\" \"6\" \"7\" \"8\"  colnames(iris)  ## [1] \"Sepal.Length\" \"Sepal.Width\" \"Petal.Length\" \"Petal.Width\" \"Species\"  Return name field of vectors and lists\nnames(myVec)  ## [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\" \"T\" \"U\" \"V\" \"W\" \"X\" ## [25] \"Y\" \"Z\"  names(myL)  ## [1] \"name\" \"wife\" \"no.children\" \"child.ages\"  Sorting Objects The function sort returns a vector in ascending or descending order\nsort(10:1)  ## [1] 1 2 3 4 5 6 7 8 9 10  The function order returns a sorting index for sorting an object\nsortindex \u003c- order(iris[,1], decreasing = FALSE) sortindex[1:12]  ## [1] 14 9 39 43 42 4 7 23 48 3 30 12  iris[sortindex,][1:2,]  ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 14 4.3 3.0 1.1 0.1 setosa ## 9 4.4 2.9 1.4 0.2 setosa  sortindex \u003c- order(-iris[,1]) # Same as decreasing=TRUE  Sorting multiple columns\niris[order(iris$Sepal.Length, iris$Sepal.Width),][1:2,]  ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 14 4.3 3.0 1.1 0.1 setosa ## 9 4.4 2.9 1.4 0.2 setosa  Operators and Calculations Comparison Operators Comparison operators: ==, !=, \u003c, \u003e, \u003c=, \u003e=\n1==1  ## [1] TRUE  Logical operators: AND: \u0026, OR: |, NOT: !\nx \u003c- 1:10; y \u003c- 10:1 x \u003e y \u0026 x \u003e 5  ## [1] FALSE FALSE FALSE FALSE FALSE TRUE TRUE TRUE TRUE TRUE  Basic Calculations To look up math functions, see Function Index here\nx + y  ## [1] 11 11 11 11 11 11 11 11 11 11  sum(x)  ## [1] 55  mean(x)  ## [1] 5.5  apply(iris[1:6,1:3], 1, mean)  ## 1 2 3 4 5 6 ## 3.333333 3.100000 3.066667 3.066667 3.333333 3.666667  Reading and Writing External Data Import of tabular data Import of a tab-delimited tabular file\nmyDF \u003c- read.delim(\"myData.xls\", sep=\"\\t\")  Import of Google Sheets. The following example imports a sample Google Sheet from here. Detailed instructions for interacting from R with Google Sheets with the required googlesheets4 package are here.\nlibrary(googlesheets4) mysheet \u003c- read_sheet(\"1U-32UcwZP1k3saKeaH1mbvEAOfZRdNHNkWK2GI1rpPM\", skip=4) myDF \u003c- as.data.frame(mysheet) myDF  Import from Excel sheets works well with readxl. For details see the readxl package manual here. Note: working with tab- or comma-delimited files is more flexible and highly preferred for automated analysis workflows.\nlibrary(\"readxl\") mysheet \u003c- read_excel(targets_path, sheet=\"Sheet1\")  Additional import functions are described in the readr package section here.\nExport of tabular data write.table(myDF, file=\"myfile.xls\", sep=\"\\t\", quote=FALSE, col.names=NA)  Line-wise import myDF \u003c- readLines(\"myData.txt\")  Line-wise export writeLines(month.name, \"myData.txt\")  Export R object mylist \u003c- list(C1=iris[,1], C2=iris[,2]) # Example to export saveRDS(mylist, \"mylist.rds\")  Import R object mylist \u003c- readRDS(\"mylist.rds\")  Copy and paste into R On Windows/Linux systems\nread.delim(\"clipboard\")  On Mac OS X systems\nread.delim(pipe(\"pbpaste\"))  Copy and paste from R On Windows/Linux systems\nwrite.table(iris, \"clipboard\", sep=\"\\t\", col.names=NA, quote=F)  On Mac OS X systems\nzz \u003c- pipe('pbcopy', 'w') write.table(iris, zz, sep=\"\\t\", col.names=NA, quote=F) close(zz)  Homework 3A Homework 3A: Object Subsetting Routines and Import/Export\nUseful R Functions Unique entries Make vector entries unique with unique\nlength(iris$Sepal.Length)  ## [1] 150  length(unique(iris$Sepal.Length))  ## [1] 35  Count occurrences Count occurrences of entries with table\ntable(iris$Species)  ## ## setosa versicolor virginica ## 50 50 50  Aggregate data Compute aggregate statistics with aggregate\naggregate(iris[,1:4], by=list(iris$Species), FUN=mean, na.rm=TRUE)  ## Group.1 Sepal.Length Sepal.Width Petal.Length Petal.Width ## 1 setosa 5.006 3.428 1.462 0.246 ## 2 versicolor 5.936 2.770 4.260 1.326 ## 3 virginica 6.588 2.974 5.552 2.026  Intersect data Compute intersect between two vectors with %in%\nmonth.name %in% c(\"May\", \"July\")  ## [1] FALSE FALSE FALSE FALSE TRUE FALSE TRUE FALSE FALSE FALSE FALSE FALSE  Merge data frames Join two data frames by common field entries with merge (here row names by.x=0). To obtain only the common rows, change all=TRUE to all=FALSE. To merge on specific columns, refer to them by their position numbers or their column names.\nframe1 \u003c- iris[sample(1:length(iris[,1]), 30), ] frame1[1:2,]  ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 55 6.5 2.8 4.6 1.5 versicolor ## 49 5.3 3.7 1.5 0.2 setosa  dim(frame1)  ## [1] 30 5  my_result \u003c- merge(frame1, iris, by.x = 0, by.y = 0, all = TRUE) dim(my_result)  ## [1] 150 11  Graphics in R Advantages  Powerful environment for visualizing scientific data Integrated graphics and statistics infrastructure Publication quality graphics Fully programmable Highly reproducible Full LaTeX and Markdown support via knitr and R markdown Vast number of R packages with graphics utilities  Documentation for R Graphics General\n Graphics Task Page - URL R Graph Gallery - URL R Graphical Manual - URL Paul Murrell’s book R (Grid) Graphics - URL  Interactive graphics\n rggobi` (GGobi) - URL iplots - URL Open GL (rgl) - URL  Graphics Environments Viewing and saving graphics in R\n On-screen graphics postscript, pdf, svg jpeg, png, wmf, tiff, …  Four major graphic environments\n Low-level infrastructure   R Base Graphics (low- and high-level) grid: Manual  High-level infrastructure \\begin{itemize}   lattice: Manual, Intro, Book ggplot2: Manual, Intro, Book  Base Graphics: Overview Important high-level plotting functions\n plot: generic x-y plotting barplot: bar plots boxplot: box-and-whisker plot hist: histograms pie: pie charts dotchart: cleveland dot plots image, heatmap, contour, persp: functions to generate image-like plots qqnorm, qqline, qqplot: distribution comparison plots pairs, coplot: display of multivariant data  Help on graphics functions\n ?myfct ?plot ?par  Preferred Object Types  Matrices and data frames Vectors Named vectors  Scatter Plots Basic Scatter Plot Sample data set for subsequent plots\nset.seed(1410) y \u003c- matrix(runif(30), ncol=3, dimnames=list(letters[1:10], LETTERS[1:3]))  Plot data\nplot(y[,1], y[,2])  All pairs pairs(y)  With labels plot(y[,1], y[,2], pch=20, col=\"red\", main=\"Symbols and Labels\") text(y[,1]+0.03, y[,2], rownames(y))  More examples Print instead of symbols the row names\nplot(y[,1], y[,2], type=\"n\", main=\"Plot of Labels\") text(y[,1], y[,2], rownames(y))  Usage of important plotting parameters\ngrid(5, 5, lwd = 2) op \u003c- par(mar=c(8,8,8,8), bg=\"lightblue\") plot(y[,1], y[,2], type=\"p\", col=\"red\", cex.lab=1.2, cex.axis=1.2, cex.main=1.2, cex.sub=1, lwd=4, pch=20, xlab=\"x label\", ylab=\"y label\", main=\"My Main\", sub=\"My Sub\") par(op)  Important arguments\n mar: specifies the margin sizes around the plotting area in order: c(bottom, left, top, right) col: color of symbols pch: type of symbols, samples: example(points) lwd: size of symbols cex.*: control font sizes For details see ?par  Add regression line plot(y[,1], y[,2]) myline \u003c- lm(y[,2]~y[,1]); abline(myline, lwd=2)  summary(myline)  ## ## Call: ## lm(formula = y[, 2] ~ y[, 1]) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.40357 -0.17912 -0.04299 0.22147 0.46623 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u003e|t|) ## (Intercept) 0.5764 0.2110 2.732 0.0258 * ## y[, 1] -0.3647 0.3959 -0.921 0.3839 ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## Residual standard error: 0.3095 on 8 degrees of freedom ## Multiple R-squared: 0.09589, Adjusted R-squared: -0.01712 ## F-statistic: 0.8485 on 1 and 8 DF, p-value: 0.3839  Log scale Same plot as above, but on log scale\nplot(y[,1], y[,2], log=\"xy\")  Add a mathematical expression plot(y[,1], y[,2]); text(y[1,1], y[1,2], expression(sum(frac(1,sqrt(x^2*pi)))), cex=1.3)  Homework 3B Homework 3B: Scatter Plots\nLine Plots Single data set plot(y[,1], type=\"l\", lwd=2, col=\"blue\")  Many Data Sets Plots line graph for all columns in data frame y. The split.screen function is used in this example in a for loop to overlay several line graphs in the same plot.\nsplit.screen(c(1,1))  ## [1] 1  plot(y[,1], ylim=c(0,1), xlab=\"Measurement\", ylab=\"Intensity\", type=\"l\", lwd=2, col=1) for(i in 2:length(y[1,])) { screen(1, new=FALSE) plot(y[,i], ylim=c(0,1), type=\"l\", lwd=2, col=i, xaxt=\"n\", yaxt=\"n\", ylab=\"\", xlab=\"\", main=\"\", bty=\"n\") }  close.screen(all=TRUE)  Bar Plots Basics barplot(y[1:4,], ylim=c(0, max(y[1:4,])+0.3), beside=TRUE, legend=letters[1:4]) text(labels=round(as.vector(as.matrix(y[1:4,])),2), x=seq(1.5, 13, by=1) + sort(rep(c(0,1,2), 4)), y=as.vector(as.matrix(y[1:4,]))+0.04)  Error Bars bar \u003c- barplot(m \u003c- rowMeans(y) * 10, ylim=c(0, 10)) stdev \u003c- sd(t(y)) arrows(bar, m, bar, m + stdev, length=0.15, angle = 90)  Histograms hist(y, freq=TRUE, breaks=10)  Density Plots plot(density(y), col=\"red\")  Pie Charts pie(y[,1], col=rainbow(length(y[,1]), start=0.1, end=0.8), clockwise=TRUE) legend(\"topright\", legend=row.names(y), cex=1.3, bty=\"n\", pch=15, pt.cex=1.8, col=rainbow(length(y[,1]), start=0.1, end=0.8), ncol=1)  Color Selection Utilities Default color palette and how to change it\npalette()  ## [1] \"black\" \"#DF536B\" \"#61D04F\" \"#2297E6\" \"#28E2E5\" \"#CD0BBC\" \"#F5C710\" \"gray62\"  palette(rainbow(5, start=0.1, end=0.2)) palette()  ## [1] \"#FF9900\" \"#FFBF00\" \"#FFE600\" \"#F2FF00\" \"#CCFF00\"  palette(\"default\")  The gray function allows to select any type of gray shades by providing values from 0 to 1\ngray(seq(0.1, 1, by= 0.2))  ## [1] \"#1A1A1A\" \"#4D4D4D\" \"#808080\" \"#B3B3B3\" \"#E6E6E6\"  Color gradients with colorpanel function from gplots library`\nlibrary(gplots) colorpanel(5, \"darkblue\", \"yellow\", \"white\")  ## [1] \"#00008B\" \"#808046\" \"#FFFF00\" \"#FFFF80\" \"#FFFFFF\"  Much more on colors in R see Earl Glynn’s color chart here\nSaving Graphics to File After the pdf() command all graphs are redirected to file test.pdf. Works for all common formats similarly: jpeg, png, ps, tiff, …\npdf(\"test.pdf\") plot(1:10, 1:10) dev.off()  Generates Scalable Vector Graphics (SVG) files that can be edited in vector graphics programs, such as InkScape.\nlibrary(\"RSvgDevice\") devSVG(\"test.svg\") plot(1:10, 1:10) dev.off()  Homework 3C Homework 3C: Bar Plots\nAnalysis Routine Overview The following exercise introduces a variety of useful data analysis utilities in R.\nAnalysis Routine: Data Import   Step 1: To get started with this exercise, direct your R session to a dedicated workshop directory and download into this directory the following sample tables. Then import the files into Excel and save them as tab delimited text files.\n MolecularWeight_tair7.xls TargetP_analysis_tair7.xls    Import the tables into R\nImport molecular weight table\nmy_mw \u003c- read.delim(file=\"MolecularWeight_tair7.xls\", header=T, sep=\"\\t\") my_mw[1:2,]  Import subcelluar targeting table\nmy_target \u003c- read.delim(file=\"TargetP_analysis_tair7.xls\", header=T, sep=\"\\t\") my_target[1:2,]  Online import of molecular weight table\nmy_mw \u003c- read.delim(file=\"http://faculty.ucr.edu/~tgirke/Documents/R_BioCond/Samples/MolecularWeight_tair7.xls\", header=T, sep=\"\\t\") my_mw[1:2,]  ## Sequence.id Molecular.Weight.Da. Residues ## 1 AT1G08520.1 83285 760 ## 2 AT1G08530.1 27015 257  Online import of subcelluar targeting table\nmy_target \u003c- read.delim(file=\"http://faculty.ucr.edu/~tgirke/Documents/R_BioCond/Samples/TargetP_analysis_tair7.xls\", header=T, sep=\"\\t\") my_target[1:2,]  ## GeneName Loc cTP mTP SP other ## 1 AT1G08520.1 C 0.822 0.137 0.029 0.039 ## 2 AT1G08530.1 C 0.817 0.058 0.010 0.100  Merging Data Frames  Step 2: Assign uniform gene ID column titles  colnames(my_target)[1] \u003c- \"ID\" colnames(my_mw)[1] \u003c- \"ID\"   Step 3: Merge the two tables based on common ID field  my_mw_target \u003c- merge(my_mw, my_target, by.x=\"ID\", by.y=\"ID\", all.x=T)   Step 4: Shorten one table before the merge and then remove the non-matching rows (NAs) in the merged file  my_mw_target2a \u003c- merge(my_mw, my_target[1:40,], by.x=\"ID\", by.y=\"ID\", all.x=T) # To remove non-matching rows, use the argument setting 'all=F'. my_mw_target2 \u003c- na.omit(my_mw_target2a) # Removes rows containing \"NAs\" (non-matching rows).   Homework 3D: How can the merge function in the previous step be executed so that only the common rows among the two data frames are returned? Prove that both methods - the two step version with na.omit and your method - return identical results. Homework 3E: Replace all NAs in the data frame my_mw_target2a with zeros.  Filtering Data  Step 5: Retrieve all records with a value of greater than 100,000 in ‘MW’ column and ‘C’ value in ‘Loc’ column (targeted to chloroplast).  query \u003c- my_mw_target[my_mw_target[, 2] \u003e 100000 \u0026 my_mw_target[, 4] == \"C\", ] query[1:4, ]  ## ID Molecular.Weight.Da. Residues Loc cTP mTP SP other ## 219 AT1G02730.1 132588 1181 C 0.972 0.038 0.008 0.045 ## 243 AT1G02890.1 136825 1252 C 0.748 0.529 0.011 0.013 ## 281 AT1G03160.1 100732 912 C 0.871 0.235 0.011 0.007 ## 547 AT1G05380.1 126360 1138 C 0.740 0.099 0.016 0.358  dim(query)  ## [1] 170 8   Homework 3F: How many protein entries in the my_mw_target data frame have a MW of greater then 4,000 and less then 5,000. Subset the data frame accordingly and sort it by MW to check that your result is correct.  String Substitutions  Step 6: Use a regular expression in a substitute function to generate a separate ID column that lacks the gene model extensions. \u003c\u003clabel=Exercise 4.7, eval=TRUE, echo=TRUE, keep.source=TRUE\u003e\u003e=  my_mw_target3 \u003c- data.frame(loci=gsub(\"\\\\..*\", \"\", as.character(my_mw_target[,1]), perl = TRUE), my_mw_target) my_mw_target3[1:3,1:8]  ## loci ID Molecular.Weight.Da. Residues Loc cTP mTP SP ## 1 AT1G01010 AT1G01010.1 49426 429 _ 0.10 0.090 0.075 ## 2 AT1G01020 AT1G01020.1 28092 245 * 0.01 0.636 0.158 ## 3 AT1G01020 AT1G01020.2 21711 191 * 0.01 0.636 0.158   Homework 3G: Retrieve those rows in my_mw_target3 where the second column contains the following identifiers: c(\"AT5G52930.1\", \"AT4G18950.1\", \"AT1G15385.1\", \"AT4G36500.1\", \"AT1G67530.1\"). Use the %in% function for this query. As an alternative approach, assign the second column to the row index of the data frame and then perform the same query again using the row index. Explain the difference of the two methods.  Calculations on Data Frames  Step 7: Count the number of duplicates in the loci column with the table function and append the result to the data frame with the cbind function.  mycounts \u003c- table(my_mw_target3[,1])[my_mw_target3[,1]] my_mw_target4 \u003c- cbind(my_mw_target3, Freq=mycounts[as.character(my_mw_target3[,1])])   Step 8: Perform a vectorized devision of columns 3 and 4 (average AA weight per protein)  data.frame(my_mw_target4, avg_AA_WT=(my_mw_target4[,3] / my_mw_target4[,4]))[1:2,]  ## loci ID Molecular.Weight.Da. Residues Loc cTP mTP SP other Freq.Var1 ## 1 AT1G01010 AT1G01010.1 49426 429 _ 0.10 0.090 0.075 0.925 AT1G01010 ## 2 AT1G01020 AT1G01020.1 28092 245 * 0.01 0.636 0.158 0.448 AT1G01020 ## Freq.Freq avg_AA_WT ## 1 1 115.2121 ## 2 2 114.6612   Step 9: Calculate for each row the mean and standard deviation across several columns  mymean \u003c- apply(my_mw_target4[,6:9], 1, mean) mystdev \u003c- apply(my_mw_target4[,6:9], 1, sd, na.rm=TRUE) data.frame(my_mw_target4, mean=mymean, stdev=mystdev)[1:2,5:12]  ## Loc cTP mTP SP other Freq.Var1 Freq.Freq mean ## 1 _ 0.10 0.090 0.075 0.925 AT1G01010 1 0.2975 ## 2 * 0.01 0.636 0.158 0.448 AT1G01020 2 0.3130  Plotting Example  Step 10: Generate scatter plot columns: ‘MW’ and ‘Residues’  plot(my_mw_target4[1:500,3:4], col=\"red\")  Export Results and Run Entire Exercise as Script  Step 11: Write the data frame my_mw_target4 into a tab-delimited text file and inspect it in Excel.  write.table(my_mw_target4, file=\"my_file.xls\", quote=F, sep=\"\\t\", col.names = NA)   Homework 3H: Write all commands from this exercise into an R script named exerciseRbasics.R, or download it from here. Then execute the script with the source function like this: source(\"exerciseRbasics.R\"). This will run all commands of this exercise and generate the corresponding output files in the current working directory.  source(\"exerciseRbasics.R\")  Session Info sessionInfo()  ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C LC_TIME=en_US.UTF-8 ## [4] LC_COLLATE=en_US.UTF-8 LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C LC_ADDRESS=C ## [10] LC_TELEPHONE=C LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] knitr_1.30 gplots_3.1.1 RSQLite_2.2.1 data.table_1.13.2 forcats_0.5.0 ## [6] stringr_1.4.0 dplyr_1.0.2 purrr_0.3.4 readr_1.4.0 tidyr_1.1.2 ## [11] tibble_3.0.4 tidyverse_1.3.0 ggplot2_3.3.2 limma_3.46.0 BiocStyle_2.18.0 ## ## loaded via a namespace (and not attached): ## [1] httr_1.4.2 viridisLite_0.3.0 bit64_4.0.5 jsonlite_1.7.1 ## [5] modelr_0.1.8 gtools_3.8.2 assertthat_0.2.1 BiocManager_1.30.10 ## [9] highr_0.8 blob_1.2.1 cellranger_1.1.0 yaml_2.2.1 ## [13] pillar_1.4.7 backports_1.2.0 glue_1.4.2 digest_0.6.27 ## [17] rvest_0.3.6 colorspace_2.0-0 htmltools_0.5.1.1 plyr_1.8.6 ## [21] pkgconfig_2.0.3 broom_0.7.2 haven_2.3.1 bookdown_0.21 ## [25] scales_1.1.1 generics_0.1.0 farver_2.0.3 ellipsis_0.3.1 ## [29] withr_2.3.0 cli_2.2.0 magrittr_2.0.1 crayon_1.3.4 ## [33] readxl_1.3.1 memoise_1.1.0 evaluate_0.14 ps_1.4.0 ## [37] fs_1.5.0 fansi_0.4.1 xml2_1.3.2 blogdown_1.1.7 ## [41] tools_4.0.3 hms_0.5.3 lifecycle_0.2.0 munsell_0.5.0 ## [45] reprex_0.3.0 compiler_4.0.3 caTools_1.18.1 rlang_0.4.8 ## [49] grid_4.0.3 rstudioapi_0.13 bitops_1.0-6 labeling_0.4.2 ## [53] rmarkdown_2.5 gtable_0.3.0 codetools_0.2-16 DBI_1.1.0 ## [57] reshape2_1.4.4 R6_2.5.0 lubridate_1.7.9.2 bit_4.0.4 ## [61] utf8_1.1.4 KernSmooth_2.23-17 stringi_1.5.3 Rcpp_1.0.5 ## [65] vctrs_0.3.5 dbplyr_2.0.0 tidyselect_1.1.0 xfun_0.20  References ","categories":"","description":"","excerpt":"document.addEventListener(\"DOMContentLoaded\", function() { …","ref":"/tutorials/rbasics/rbasics/","tags":"","title":"Introduction to R"},{"body":"Internal  This page provides links to password protected resources that are only accessible to the instructor and/or students enrolled in this class.\n  Course Planning Sheet: shared privately GitHub: private repositories for course assignments (homework and course projects) GitHub Education: provides free extra benefits to students Piazza: for communication among students and instructor (please avoid email!) How to set up and maintain this site: see here  ","categories":"","description":"","excerpt":"Internal  This page provides links to password protected resources …","ref":"/about/internal/internal_resources/","tags":"","title":"Internal Resources"},{"body":"       R Markdown Overview R Markdown combines markdown (an easy to write plain text format) with embedded R code chunks. When compiling R Markdown documents, the code components can be evaluated so that both the code and its output can be included in the final document. This makes analysis reports highly reproducible by allowing to automatically regenerate them when the underlying R code or data changes. R Markdown documents (.Rmd files) can be rendered to various formats including HTML and PDF. The R code in an .Rmd document is processed by knitr, while the resulting .md file is rendered by pandoc to the final output formats (e.g. HTML or PDF). Historically, R Markdown is an extension of the older Sweave/Latex environment. Rendering of mathematical expressions and reference management is also supported by R Markdown using embedded Latex syntax and Bibtex, respectively.\nQuick Start Install R Markdown install.packages(\"rmarkdown\")  Initialize a new R Markdown (Rmd) script To minimize typing, it can be helful to start with an R Markdown template and then modify it as needed. Note the file name of an R Markdown scirpt needs to have the extension .Rmd. Template files for the following examples are available here:\n R Markdown sample script: sample.Rmd Bibtex file for handling citations and reference section: bibtex.bib  Users want to download these files, open the sample.Rmd file with their preferred R IDE (e.g. RStudio, vim or emacs), initilize an R session and then direct their R session to the location of these two files.\nMetadata section The metadata section (YAML header) in an R Markdown script defines how it will be processed and rendered. The metadata section also includes both title, author, and date information as well as options for customizing the output format. For instance, PDF and HTML output can be defined with pdf_document and html_document, respectively. The BiocStyle:: prefix will use the formatting style of the BiocStyle package from Bioconductor.\n --- title: \"My First R Markdown Document\" author: \"Author: First Last\" date: \"Last update: 18 February, 2021\" output: BiocStyle::html_document: toc: true toc_depth: 3 fig_caption: yes fontsize: 14pt bibliography: bibtex.bib ---  Render Rmd script An R Markdown script can be evaluated and rendered with the following render command or by pressing the knit button in RStudio. The output_format argument defines the format of the output (e.g. html_document). The setting output_format=\"all\" will generate all supported output formats. Alternatively, one can specify several output formats in the metadata section as shown in the above example.\nrmarkdown::render(\"sample.Rmd\", clean=TRUE, output_format=\"html_document\")  The following shows two options how to run the rendering from the command-line.\n$ Rscript -e \"rmarkdown::render('sample.Rmd', clean=TRUE)\"  Alternatively, one can use a Makefile to evaluate and render an R Markdown script. A sample Makefile for rendering the above sample.Rmd can be downloaded here. To apply it to a custom Rmd file, one needs open the Makefile in a text editor and change the value assigned to MAIN (line 13) to the base name of the corresponding .Rmd file (e.g. assign systemPipeRNAseq if the file name is systemPipeRNAseq.Rmd). To execute the Makefile, run the following command from the command-line.\n$ make -B  R code chunks R Code Chunks can be embedded in an R Markdown script by using three backticks at the beginning of a new line along with arguments enclosed in curly braces controlling the behavior of the code. The following lines contain the plain R code. A code chunk is terminated by a new line starting with three backticks. The following shows an example of such a code chunk. Note the backslashes are not part of it. They have been added to print the code chunk syntax in this document.\n ```\\{r code_chunk_name, eval=FALSE\\} x \u003c- 1:10 ```  The following lists the most important arguments to control the behavior of R code chunks:\n r: specifies language for code chunk, here R chode_chunk_name: name of code chunk; this name needs to be unique eval: if assigned TRUE the code will be evaluated warning: if assigned FALSE warnings will not be shown message: if assigned FALSE messages will not be shown cache: if assigned TRUE results will be cached to reuse in future rendering instances fig.height: allows to specify height of figures in inches fig.width: allows to specify width of figures in inches  For more details on code chunk options see here.\nLearning Markdown The basic syntax of Markdown and derivatives like kramdown is extremely easy to learn. Rather than providing another introduction on this topic, here are some useful sites for learning Markdown:\n Markdown Intro on GitHub Markdown Cheet Sheet Markdown Basics from RStudio R Markdown Cheat Sheet kramdown Syntax  Tables There are several ways to render tables. First, they can be printed within the R code chunks. Second, much nicer formatted tables can be generated with the functions kable, pander or xtable. The following example uses kable from the knitr package.\nlibrary(knitr) kable(iris[1:12,])     Sepal.Length Sepal.Width Petal.Length Petal.Width Species     5.1 3.5 1.4 0.2 setosa   4.9 3.0 1.4 0.2 setosa   4.7 3.2 1.3 0.2 setosa   4.6 3.1 1.5 0.2 setosa   5.0 3.6 1.4 0.2 setosa   5.4 3.9 1.7 0.4 setosa   4.6 3.4 1.4 0.3 setosa   5.0 3.4 1.5 0.2 setosa   4.4 2.9 1.4 0.2 setosa   4.9 3.1 1.5 0.1 setosa   5.4 3.7 1.5 0.2 setosa   4.8 3.4 1.6 0.2 setosa    A much more elegant and powerful solution is to create fully interactive tables with the DT package. This JavaScirpt based environment provides a wrapper to the DataTables library using jQuery. The resulting tables can be sorted, queried and resized by the user.\nlibrary(DT) datatable(iris, filter = 'top', options = list( pageLength = 100, scrollX = TRUE, scrollY = \"600px\", autoWidth = TRUE ))   {\"x\":{\"filter\":\"top\",\"filterHTML\":\"\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\",\"101\",\"102\",\"103\",\"104\",\"105\",\"106\",\"107\",\"108\",\"109\",\"110\",\"111\",\"112\",\"113\",\"114\",\"115\",\"116\",\"117\",\"118\",\"119\",\"120\",\"121\",\"122\",\"123\",\"124\",\"125\",\"126\",\"127\",\"128\",\"129\",\"130\",\"131\",\"132\",\"133\",\"134\",\"135\",\"136\",\"137\",\"138\",\"139\",\"140\",\"141\",\"142\",\"143\",\"144\",\"145\",\"146\",\"147\",\"148\",\"149\",\"150\"],[5.1,4.9,4.7,4.6,5,5.4,4.6,5,4.4,4.9,5.4,4.8,4.8,4.3,5.8,5.7,5.4,5.1,5.7,5.1,5.4,5.1,4.6,5.1,4.8,5,5,5.2,5.2,4.7,4.8,5.4,5.2,5.5,4.9,5,5.5,4.9,4.4,5.1,5,4.5,4.4,5,5.1,4.8,5.1,4.6,5.3,5,7,6.4,6.9,5.5,6.5,5.7,6.3,4.9,6.6,5.2,5,5.9,6,6.1,5.6,6.7,5.6,5.8,6.2,5.6,5.9,6.1,6.3,6.1,6.4,6.6,6.8,6.7,6,5.7,5.5,5.5,5.8,6,5.4,6,6.7,6.3,5.6,5.5,5.5,6.1,5.8,5,5.6,5.7,5.7,6.2,5.1,5.7,6.3,5.8,7.1,6.3,6.5,7.6,4.9,7.3,6.7,7.2,6.5,6.4,6.8,5.7,5.8,6.4,6.5,7.7,7.7,6,6.9,5.6,7.7,6.3,6.7,7.2,6.2,6.1,6.4,7.2,7.4,7.9,6.4,6.3,6.1,7.7,6.3,6.4,6,6.9,6.7,6.9,5.8,6.8,6.7,6.7,6.3,6.5,6.2,5.9],[3.5,3,3.2,3.1,3.6,3.9,3.4,3.4,2.9,3.1,3.7,3.4,3,3,4,4.4,3.9,3.5,3.8,3.8,3.4,3.7,3.6,3.3,3.4,3,3.4,3.5,3.4,3.2,3.1,3.4,4.1,4.2,3.1,3.2,3.5,3.6,3,3.4,3.5,2.3,3.2,3.5,3.8,3,3.8,3.2,3.7,3.3,3.2,3.2,3.1,2.3,2.8,2.8,3.3,2.4,2.9,2.7,2,3,2.2,2.9,2.9,3.1,3,2.7,2.2,2.5,3.2,2.8,2.5,2.8,2.9,3,2.8,3,2.9,2.6,2.4,2.4,2.7,2.7,3,3.4,3.1,2.3,3,2.5,2.6,3,2.6,2.3,2.7,3,2.9,2.9,2.5,2.8,3.3,2.7,3,2.9,3,3,2.5,2.9,2.5,3.6,3.2,2.7,3,2.5,2.8,3.2,3,3.8,2.6,2.2,3.2,2.8,2.8,2.7,3.3,3.2,2.8,3,2.8,3,2.8,3.8,2.8,2.8,2.6,3,3.4,3.1,3,3.1,3.1,3.1,2.7,3.2,3.3,3,2.5,3,3.4,3],[1.4,1.4,1.3,1.5,1.4,1.7,1.4,1.5,1.4,1.5,1.5,1.6,1.4,1.1,1.2,1.5,1.3,1.4,1.7,1.5,1.7,1.5,1,1.7,1.9,1.6,1.6,1.5,1.4,1.6,1.6,1.5,1.5,1.4,1.5,1.2,1.3,1.4,1.3,1.5,1.3,1.3,1.3,1.6,1.9,1.4,1.6,1.4,1.5,1.4,4.7,4.5,4.9,4,4.6,4.5,4.7,3.3,4.6,3.9,3.5,4.2,4,4.7,3.6,4.4,4.5,4.1,4.5,3.9,4.8,4,4.9,4.7,4.3,4.4,4.8,5,4.5,3.5,3.8,3.7,3.9,5.1,4.5,4.5,4.7,4.4,4.1,4,4.4,4.6,4,3.3,4.2,4.2,4.2,4.3,3,4.1,6,5.1,5.9,5.6,5.8,6.6,4.5,6.3,5.8,6.1,5.1,5.3,5.5,5,5.1,5.3,5.5,6.7,6.9,5,5.7,4.9,6.7,4.9,5.7,6,4.8,4.9,5.6,5.8,6.1,6.4,5.6,5.1,5.6,6.1,5.6,5.5,4.8,5.4,5.6,5.1,5.1,5.9,5.7,5.2,5,5.2,5.4,5.1],[0.2,0.2,0.2,0.2,0.2,0.4,0.3,0.2,0.2,0.1,0.2,0.2,0.1,0.1,0.2,0.4,0.4,0.3,0.3,0.3,0.2,0.4,0.2,0.5,0.2,0.2,0.4,0.2,0.2,0.2,0.2,0.4,0.1,0.2,0.2,0.2,0.2,0.1,0.2,0.2,0.3,0.3,0.2,0.6,0.4,0.3,0.2,0.2,0.2,0.2,1.4,1.5,1.5,1.3,1.5,1.3,1.6,1,1.3,1.4,1,1.5,1,1.4,1.3,1.4,1.5,1,1.5,1.1,1.8,1.3,1.5,1.2,1.3,1.4,1.4,1.7,1.5,1,1.1,1,1.2,1.6,1.5,1.6,1.5,1.3,1.3,1.3,1.2,1.4,1.2,1,1.3,1.2,1.3,1.3,1.1,1.3,2.5,1.9,2.1,1.8,2.2,2.1,1.7,1.8,1.8,2.5,2,1.9,2.1,2,2.4,2.3,1.8,2.2,2.3,1.5,2.3,2,2,1.8,2.1,1.8,1.8,1.8,2.1,1.6,1.9,2,2.2,1.5,1.4,2.3,2.4,1.8,1.8,2.1,2.4,2.3,1.9,2.3,2.5,2.3,1.9,2,2.3,1.8],[\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\"]],\"container\":\"\\n \\n \\n  \\n Sepal.Length\\n Sepal.Width\\n Petal.Length\\n Petal.Width\\n Species\\n \\n \\n\",\"options\":{\"pageLength\":100,\"scrollX\":true,\"scrollY\":\"600px\",\"autoWidth\":true,\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,2,3,4]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"orderClasses\":false,\"orderCellsTop\":true}},\"evals\":[],\"jsHooks\":[]} Figures Plots generated by the R code chunks in an R Markdown document can be automatically inserted in the output file. The size of the figure can be controlled with the fig.height and fig.width arguments.\nlibrary(ggplot2) dsmall \u003c- diamonds[sample(nrow(diamonds), 1000), ] ggplot(dsmall, aes(color, price/carat)) + geom_jitter(alpha = I(1 / 2), aes(color=color))  Sometimes it can be useful to explicitly write an image to a file and then insert that image into the final document by referencing its file name in the R Markdown source. For instance, this can be useful for time consuming analyses. The following code will generate a file named myplot.png. To insert the file in the final document, one can use standard Markdown or HTML syntax, e.g.: \u003cimg src=\"myplot.png\"/\u003e.\npng(\"myplot.png\") ggplot(dsmall, aes(color, price/carat)) + geom_jitter(alpha = I(1 / 2), aes(color=color)) dev.off()  ## png ## 2    Inline R code To evaluate R code inline, one can enclose an R expression with a single back-tick followed by r and then the actual expression. For instance, the back-ticked version of ‘r 1 + 1’ evaluates to 2 and ‘r pi’ evaluates to 3.1415927.\nMathematical equations To render mathematical equations, one can use standard Latex syntax. When expressions are enclosed with single $ signs then they will be shown inline, while enclosing them with double $$ signs will show them in display mode. For instance, the following Latex syntax d(X,Y) = \\sqrt[]{ \\sum_{i=1}^{n}{(x_{i}-y_{i})^2} } renders in display mode as follows:\n$$d(X,Y) = \\sqrt[]{ \\sum_{i=1}^{n}{(x_{i}-y_{i})^2} }$$\nCitations and bibliographies Citations and bibliographies can be autogenerated in R Markdown in a similar way as in Latex/Bibtex. Reference collections should be stored in a separate file in Bibtex or other supported formats. To cite a publication in an R Markdown script, one uses the syntax [@\u003cid1\u003e] where \u003cid1\u003e needs to be replaced with a reference identifier present in the Bibtex database listed in the metadata section of the R Markdown script (e.g. bibtex.bib). For instance, to cite Lawrence et al. (2013), one uses its reference identifier (e.g. Lawrence2013-kt) as \u003cid1\u003e (Lawrence et al. 2013). This will place the citation inline in the text and add the corresponding reference to a reference list at the end of the output document. For the latter a special section called References needs to be specified at the end of the R Markdown script. To fine control the formatting of citations and reference lists, users want to consult this the corresponding R Markdown page. Also, for general reference management and outputting references in Bibtex format Paperpile can be very helpful.\nViewing R Markdown report on HPCC cluster R Markdown reports located on UCR’s HPCC Cluster can be viewed locally in a web browser (without moving the source HTML) by creating a symbolic link from a user’s .html directory. This way any updates to the report will show up immediately without creating another copy of the HTML file. For instance, if user ttest has generated an R Markdown report under ~/bigdata/today/rmarkdown/sample.html, then the symbolic link can be created as follows:\ncd ~/.html ln -s ~/bigdata/today/rmarkdown/sample.html sample.html  After this one can view the report in a web browser using this URL http://biocluster.ucr.edu/~ttest/rmarkdown/sample.html. If necessary access to the URL can be restricted with a password following the instructions here.\nSession Info sessionInfo()  ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 ## [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] ggplot2_3.3.2 DT_0.16 knitr_1.30 ## ## loaded via a namespace (and not attached): ## [1] compiler_4.0.4 pillar_1.4.7 highr_0.8 tools_4.0.4 ## [5] digest_0.6.27 viridisLite_0.3.0 jsonlite_1.7.1 evaluate_0.14 ## [9] lifecycle_0.2.0 tibble_3.0.4 gtable_0.3.0 pkgconfig_2.0.3 ## [13] rlang_0.4.8 crosstalk_1.1.0.1 yaml_2.2.1 blogdown_1.1.7 ## [17] xfun_0.20 withr_2.3.0 stringr_1.4.0 dplyr_1.0.2 ## [21] generics_0.1.0 htmlwidgets_1.5.2 vctrs_0.3.5 grid_4.0.4 ## [25] tidyselect_1.1.0 glue_1.4.2 R6_2.5.0 rmarkdown_2.5 ## [29] bookdown_0.21 farver_2.0.3 purrr_0.3.4 magrittr_2.0.1 ## [33] scales_1.1.1 htmltools_0.5.1.1 ellipsis_0.3.1 colorspace_2.0-0 ## [37] labeling_0.4.2 stringi_1.5.3 munsell_0.5.0 crayon_1.3.4  References Lawrence, Michael, Wolfgang Huber, Hervé Pagès, Patrick Aboyoun, Marc Carlson, Robert Gentleman, Martin T Morgan, and Vincent J Carey. 2013. “Software for Computing and Annotating Genomic Ranges.” PLoS Comput. Biol. 9 (8): e1003118. https://doi.org/10.1371/journal.pcbi.1003118.\n  ","categories":"","description":"","excerpt":"       R Markdown Overview R Markdown combines markdown (an easy to …","ref":"/manuals/rbasics/sample/","tags":"","title":"Sample R Markdown"},{"body":"       R Markdown Overview R Markdown combines markdown (an easy to write plain text format) with embedded R code chunks. When compiling R Markdown documents, the code components can be evaluated so that both the code and its output can be included in the final document. This makes analysis reports highly reproducible by allowing to automatically regenerate them when the underlying R code or data changes. R Markdown documents (.Rmd files) can be rendered to various formats including HTML and PDF. The R code in an .Rmd document is processed by knitr, while the resulting .md file is rendered by pandoc to the final output formats (e.g. HTML or PDF). Historically, R Markdown is an extension of the older Sweave/Latex environment. Rendering of mathematical expressions and reference management is also supported by R Markdown using embedded Latex syntax and Bibtex, respectively.\nQuick Start Install R Markdown install.packages(\"rmarkdown\")  Initialize a new R Markdown (Rmd) script To minimize typing, it can be helful to start with an R Markdown template and then modify it as needed. Note the file name of an R Markdown scirpt needs to have the extension .Rmd. Template files for the following examples are available here:\n R Markdown sample script: sample.Rmd Bibtex file for handling citations and reference section: bibtex.bib  Users want to download these files, open the sample.Rmd file with their preferred R IDE (e.g. RStudio, vim or emacs), initilize an R session and then direct their R session to the location of these two files.\nMetadata section The metadata section (YAML header) in an R Markdown script defines how it will be processed and rendered. The metadata section also includes both title, author, and date information as well as options for customizing the output format. For instance, PDF and HTML output can be defined with pdf_document and html_document, respectively. The BiocStyle:: prefix will use the formatting style of the BiocStyle package from Bioconductor.\n --- title: \"My First R Markdown Document\" author: \"Author: First Last\" date: \"Last update: 18 February, 2021\" output: BiocStyle::html_document: toc: true toc_depth: 3 fig_caption: yes fontsize: 14pt bibliography: bibtex.bib ---  Render Rmd script An R Markdown script can be evaluated and rendered with the following render command or by pressing the knit button in RStudio. The output_format argument defines the format of the output (e.g. html_document). The setting output_format=\"all\" will generate all supported output formats. Alternatively, one can specify several output formats in the metadata section as shown in the above example.\nrmarkdown::render(\"sample.Rmd\", clean=TRUE, output_format=\"html_document\")  The following shows two options how to run the rendering from the command-line.\n$ Rscript -e \"rmarkdown::render('sample.Rmd', clean=TRUE)\"  Alternatively, one can use a Makefile to evaluate and render an R Markdown script. A sample Makefile for rendering the above sample.Rmd can be downloaded here. To apply it to a custom Rmd file, one needs open the Makefile in a text editor and change the value assigned to MAIN (line 13) to the base name of the corresponding .Rmd file (e.g. assign systemPipeRNAseq if the file name is systemPipeRNAseq.Rmd). To execute the Makefile, run the following command from the command-line.\n$ make -B  R code chunks R Code Chunks can be embedded in an R Markdown script by using three backticks at the beginning of a new line along with arguments enclosed in curly braces controlling the behavior of the code. The following lines contain the plain R code. A code chunk is terminated by a new line starting with three backticks. The following shows an example of such a code chunk. Note the backslashes are not part of it. They have been added to print the code chunk syntax in this document.\n ```\\{r code_chunk_name, eval=FALSE\\} x \u003c- 1:10 ```  The following lists the most important arguments to control the behavior of R code chunks:\n r: specifies language for code chunk, here R chode_chunk_name: name of code chunk; this name needs to be unique eval: if assigned TRUE the code will be evaluated warning: if assigned FALSE warnings will not be shown message: if assigned FALSE messages will not be shown cache: if assigned TRUE results will be cached to reuse in future rendering instances fig.height: allows to specify height of figures in inches fig.width: allows to specify width of figures in inches  For more details on code chunk options see here.\nLearning Markdown The basic syntax of Markdown and derivatives like kramdown is extremely easy to learn. Rather than providing another introduction on this topic, here are some useful sites for learning Markdown:\n Markdown Intro on GitHub Markdown Cheet Sheet Markdown Basics from RStudio R Markdown Cheat Sheet kramdown Syntax  Tables There are several ways to render tables. First, they can be printed within the R code chunks. Second, much nicer formatted tables can be generated with the functions kable, pander or xtable. The following example uses kable from the knitr package.\nlibrary(knitr) kable(iris[1:12,])     Sepal.Length Sepal.Width Petal.Length Petal.Width Species     5.1 3.5 1.4 0.2 setosa   4.9 3.0 1.4 0.2 setosa   4.7 3.2 1.3 0.2 setosa   4.6 3.1 1.5 0.2 setosa   5.0 3.6 1.4 0.2 setosa   5.4 3.9 1.7 0.4 setosa   4.6 3.4 1.4 0.3 setosa   5.0 3.4 1.5 0.2 setosa   4.4 2.9 1.4 0.2 setosa   4.9 3.1 1.5 0.1 setosa   5.4 3.7 1.5 0.2 setosa   4.8 3.4 1.6 0.2 setosa    A much more elegant and powerful solution is to create fully interactive tables with the DT package. This JavaScirpt based environment provides a wrapper to the DataTables library using jQuery. The resulting tables can be sorted, queried and resized by the user.\nlibrary(DT) datatable(iris, filter = 'top', options = list( pageLength = 100, scrollX = TRUE, scrollY = \"600px\", autoWidth = TRUE ))   {\"x\":{\"filter\":\"top\",\"filterHTML\":\"\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\",\"101\",\"102\",\"103\",\"104\",\"105\",\"106\",\"107\",\"108\",\"109\",\"110\",\"111\",\"112\",\"113\",\"114\",\"115\",\"116\",\"117\",\"118\",\"119\",\"120\",\"121\",\"122\",\"123\",\"124\",\"125\",\"126\",\"127\",\"128\",\"129\",\"130\",\"131\",\"132\",\"133\",\"134\",\"135\",\"136\",\"137\",\"138\",\"139\",\"140\",\"141\",\"142\",\"143\",\"144\",\"145\",\"146\",\"147\",\"148\",\"149\",\"150\"],[5.1,4.9,4.7,4.6,5,5.4,4.6,5,4.4,4.9,5.4,4.8,4.8,4.3,5.8,5.7,5.4,5.1,5.7,5.1,5.4,5.1,4.6,5.1,4.8,5,5,5.2,5.2,4.7,4.8,5.4,5.2,5.5,4.9,5,5.5,4.9,4.4,5.1,5,4.5,4.4,5,5.1,4.8,5.1,4.6,5.3,5,7,6.4,6.9,5.5,6.5,5.7,6.3,4.9,6.6,5.2,5,5.9,6,6.1,5.6,6.7,5.6,5.8,6.2,5.6,5.9,6.1,6.3,6.1,6.4,6.6,6.8,6.7,6,5.7,5.5,5.5,5.8,6,5.4,6,6.7,6.3,5.6,5.5,5.5,6.1,5.8,5,5.6,5.7,5.7,6.2,5.1,5.7,6.3,5.8,7.1,6.3,6.5,7.6,4.9,7.3,6.7,7.2,6.5,6.4,6.8,5.7,5.8,6.4,6.5,7.7,7.7,6,6.9,5.6,7.7,6.3,6.7,7.2,6.2,6.1,6.4,7.2,7.4,7.9,6.4,6.3,6.1,7.7,6.3,6.4,6,6.9,6.7,6.9,5.8,6.8,6.7,6.7,6.3,6.5,6.2,5.9],[3.5,3,3.2,3.1,3.6,3.9,3.4,3.4,2.9,3.1,3.7,3.4,3,3,4,4.4,3.9,3.5,3.8,3.8,3.4,3.7,3.6,3.3,3.4,3,3.4,3.5,3.4,3.2,3.1,3.4,4.1,4.2,3.1,3.2,3.5,3.6,3,3.4,3.5,2.3,3.2,3.5,3.8,3,3.8,3.2,3.7,3.3,3.2,3.2,3.1,2.3,2.8,2.8,3.3,2.4,2.9,2.7,2,3,2.2,2.9,2.9,3.1,3,2.7,2.2,2.5,3.2,2.8,2.5,2.8,2.9,3,2.8,3,2.9,2.6,2.4,2.4,2.7,2.7,3,3.4,3.1,2.3,3,2.5,2.6,3,2.6,2.3,2.7,3,2.9,2.9,2.5,2.8,3.3,2.7,3,2.9,3,3,2.5,2.9,2.5,3.6,3.2,2.7,3,2.5,2.8,3.2,3,3.8,2.6,2.2,3.2,2.8,2.8,2.7,3.3,3.2,2.8,3,2.8,3,2.8,3.8,2.8,2.8,2.6,3,3.4,3.1,3,3.1,3.1,3.1,2.7,3.2,3.3,3,2.5,3,3.4,3],[1.4,1.4,1.3,1.5,1.4,1.7,1.4,1.5,1.4,1.5,1.5,1.6,1.4,1.1,1.2,1.5,1.3,1.4,1.7,1.5,1.7,1.5,1,1.7,1.9,1.6,1.6,1.5,1.4,1.6,1.6,1.5,1.5,1.4,1.5,1.2,1.3,1.4,1.3,1.5,1.3,1.3,1.3,1.6,1.9,1.4,1.6,1.4,1.5,1.4,4.7,4.5,4.9,4,4.6,4.5,4.7,3.3,4.6,3.9,3.5,4.2,4,4.7,3.6,4.4,4.5,4.1,4.5,3.9,4.8,4,4.9,4.7,4.3,4.4,4.8,5,4.5,3.5,3.8,3.7,3.9,5.1,4.5,4.5,4.7,4.4,4.1,4,4.4,4.6,4,3.3,4.2,4.2,4.2,4.3,3,4.1,6,5.1,5.9,5.6,5.8,6.6,4.5,6.3,5.8,6.1,5.1,5.3,5.5,5,5.1,5.3,5.5,6.7,6.9,5,5.7,4.9,6.7,4.9,5.7,6,4.8,4.9,5.6,5.8,6.1,6.4,5.6,5.1,5.6,6.1,5.6,5.5,4.8,5.4,5.6,5.1,5.1,5.9,5.7,5.2,5,5.2,5.4,5.1],[0.2,0.2,0.2,0.2,0.2,0.4,0.3,0.2,0.2,0.1,0.2,0.2,0.1,0.1,0.2,0.4,0.4,0.3,0.3,0.3,0.2,0.4,0.2,0.5,0.2,0.2,0.4,0.2,0.2,0.2,0.2,0.4,0.1,0.2,0.2,0.2,0.2,0.1,0.2,0.2,0.3,0.3,0.2,0.6,0.4,0.3,0.2,0.2,0.2,0.2,1.4,1.5,1.5,1.3,1.5,1.3,1.6,1,1.3,1.4,1,1.5,1,1.4,1.3,1.4,1.5,1,1.5,1.1,1.8,1.3,1.5,1.2,1.3,1.4,1.4,1.7,1.5,1,1.1,1,1.2,1.6,1.5,1.6,1.5,1.3,1.3,1.3,1.2,1.4,1.2,1,1.3,1.2,1.3,1.3,1.1,1.3,2.5,1.9,2.1,1.8,2.2,2.1,1.7,1.8,1.8,2.5,2,1.9,2.1,2,2.4,2.3,1.8,2.2,2.3,1.5,2.3,2,2,1.8,2.1,1.8,1.8,1.8,2.1,1.6,1.9,2,2.2,1.5,1.4,2.3,2.4,1.8,1.8,2.1,2.4,2.3,1.9,2.3,2.5,2.3,1.9,2,2.3,1.8],[\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\"]],\"container\":\"\\n \\n \\n  \\n Sepal.Length\\n Sepal.Width\\n Petal.Length\\n Petal.Width\\n Species\\n \\n \\n\",\"options\":{\"pageLength\":100,\"scrollX\":true,\"scrollY\":\"600px\",\"autoWidth\":true,\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,2,3,4]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"orderClasses\":false,\"orderCellsTop\":true}},\"evals\":[],\"jsHooks\":[]} Figures Plots generated by the R code chunks in an R Markdown document can be automatically inserted in the output file. The size of the figure can be controlled with the fig.height and fig.width arguments.\nlibrary(ggplot2) dsmall \u003c- diamonds[sample(nrow(diamonds), 1000), ] ggplot(dsmall, aes(color, price/carat)) + geom_jitter(alpha = I(1 / 2), aes(color=color))  Sometimes it can be useful to explicitly write an image to a file and then insert that image into the final document by referencing its file name in the R Markdown source. For instance, this can be useful for time consuming analyses. The following code will generate a file named myplot.png. To insert the file in the final document, one can use standard Markdown or HTML syntax, e.g.: \u003cimg src=\"myplot.png\"/\u003e.\npng(\"myplot.png\") ggplot(dsmall, aes(color, price/carat)) + geom_jitter(alpha = I(1 / 2), aes(color=color)) dev.off()  ## png ## 2    Inline R code To evaluate R code inline, one can enclose an R expression with a single back-tick followed by r and then the actual expression. For instance, the back-ticked version of ‘r 1 + 1’ evaluates to 2 and ‘r pi’ evaluates to 3.1415927.\nMathematical equations To render mathematical equations, one can use standard Latex syntax. When expressions are enclosed with single $ signs then they will be shown inline, while enclosing them with double $$ signs will show them in display mode. For instance, the following Latex syntax d(X,Y) = \\sqrt[]{ \\sum_{i=1}^{n}{(x_{i}-y_{i})^2} } renders in display mode as follows:\n$$d(X,Y) = \\sqrt[]{ \\sum_{i=1}^{n}{(x_{i}-y_{i})^2} }$$\nCitations and bibliographies Citations and bibliographies can be autogenerated in R Markdown in a similar way as in Latex/Bibtex. Reference collections should be stored in a separate file in Bibtex or other supported formats. To cite a publication in an R Markdown script, one uses the syntax [@\u003cid1\u003e] where \u003cid1\u003e needs to be replaced with a reference identifier present in the Bibtex database listed in the metadata section of the R Markdown script (e.g. bibtex.bib). For instance, to cite Lawrence et al. (2013), one uses its reference identifier (e.g. Lawrence2013-kt) as \u003cid1\u003e (Lawrence et al. 2013). This will place the citation inline in the text and add the corresponding reference to a reference list at the end of the output document. For the latter a special section called References needs to be specified at the end of the R Markdown script. To fine control the formatting of citations and reference lists, users want to consult this the corresponding R Markdown page. Also, for general reference management and outputting references in Bibtex format Paperpile can be very helpful.\nViewing R Markdown report on HPCC cluster R Markdown reports located on UCR’s HPCC Cluster can be viewed locally in a web browser (without moving the source HTML) by creating a symbolic link from a user’s .html directory. This way any updates to the report will show up immediately without creating another copy of the HTML file. For instance, if user ttest has generated an R Markdown report under ~/bigdata/today/rmarkdown/sample.html, then the symbolic link can be created as follows:\ncd ~/.html ln -s ~/bigdata/today/rmarkdown/sample.html sample.html  After this one can view the report in a web browser using this URL http://biocluster.ucr.edu/~ttest/rmarkdown/sample.html. If necessary access to the URL can be restricted with a password following the instructions here.\nSession Info sessionInfo()  ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 ## [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] ggplot2_3.3.2 DT_0.16 knitr_1.30 ## ## loaded via a namespace (and not attached): ## [1] compiler_4.0.4 pillar_1.4.7 highr_0.8 tools_4.0.4 ## [5] digest_0.6.27 viridisLite_0.3.0 jsonlite_1.7.1 evaluate_0.14 ## [9] lifecycle_0.2.0 tibble_3.0.4 gtable_0.3.0 pkgconfig_2.0.3 ## [13] rlang_0.4.8 crosstalk_1.1.0.1 yaml_2.2.1 blogdown_1.1.7 ## [17] xfun_0.20 withr_2.3.0 stringr_1.4.0 dplyr_1.0.2 ## [21] generics_0.1.0 htmlwidgets_1.5.2 vctrs_0.3.5 grid_4.0.4 ## [25] tidyselect_1.1.0 glue_1.4.2 R6_2.5.0 rmarkdown_2.5 ## [29] bookdown_0.21 farver_2.0.3 purrr_0.3.4 magrittr_2.0.1 ## [33] scales_1.1.1 htmltools_0.5.1.1 ellipsis_0.3.1 colorspace_2.0-0 ## [37] labeling_0.4.2 stringi_1.5.3 munsell_0.5.0 crayon_1.3.4  References Lawrence, Michael, Wolfgang Huber, Hervé Pagès, Patrick Aboyoun, Marc Carlson, Robert Gentleman, Martin T Morgan, and Vincent J Carey. 2013. “Software for Computing and Annotating Genomic Ranges.” PLoS Comput. Biol. 9 (8): e1003118. https://doi.org/10.1371/journal.pcbi.1003118.\n  ","categories":"","description":"","excerpt":"       R Markdown Overview R Markdown combines markdown (an easy to …","ref":"/tutorials/rbasics/sample/","tags":"","title":"Sample R Markdown"},{"body":"   This page provides instructions how to create new deployment instances of this teaching site, and how to configure and customize it. It uses the Docsy theme of the Hugo framework for building content driven websites.\n Quick start  Click on the Use this Template button. Choose a Repository Name Click on the Create repository from template button.  Usage locally  Go to your new repository that created from our template https://github.com/\u003cusername\u003e/\u003crepository_name\u003e Click on the Code button. Copy the URL https://github.com/\u003cusername\u003e/\u003crepository_name\u003e.git Open terminal  git clone --recurse-submodules --depth 1 https://github.com/\u003cusername\u003e/\u003crepository_name\u003e.git cd \u003crepository_name\u003e   Run the website locally  hugo server   Run the website locally with blogdown  blogdown::serve_site()  Prerequisites and Installation Install blogdown and Hugo blogdown installed.packages(\"rstudio/blogdown\") # If anything wrong try develop version remotes::install_github(\"rstudio/blogdown\")  Hugo You need a recent extended version (we recommend version 0.79.0 or later) of Hugo to do local builds and previews of sites that use Docsy.\nIt is recommended to install Hugo from R for working with blogdown\nblogdown::install_hugo(extended = TRUE)  or from commandline\nwget https://github.com/gohugoio/hugo/releases/download/v0.79.0/hugo_extended_0.79.0_Linux-64bit.deb sudo dpkg -i hugo_extended_0.79.0_Linux-64bit.deb hugo version  For Windows and macOS please see instructions here.\nInstall PostCSS To build or update your site’s CSS resources, you also need PostCSS to create the final assets. If you need to install it, you must have a recent version of NodeJS installed on your machine so you can use npm, the Node package manager. By default npm installs tools under the directory where you run npm install:\nsudo npm install -D autoprefixer sudo npm install -D postcss-cli # Starting in version 8 of postcss-cli, you must also separately install postcss: sudo npm install -D postcss # go to your website directory cd \u003crepository_name\u003e npm audit fix  Run the website locally with blogdown  Open R in console or Rstudio  This repo contains a .Rprofile file that will automatically serve the site for you R starting directory is this newly cloned repository. Otherwise, change working directory to the repository and run:\nblogdown::serve_site()  You should see a website is opened in your local browser or Rstudio viewer.\nRun the website locally on the terminal cd YOUR_NEW_REPO_PATH hugo server  ","categories":"","description":"","excerpt":"   This page provides instructions how to create new deployment …","ref":"/about/internal/install/","tags":"","title":"Deployment and Maintenance of this Site"},{"body":"document.addEventListener(\"DOMContentLoaded\", function() { document.querySelector(\"h1\").className = \"title\"; });  document.addEventListener(\"DOMContentLoaded\", function() { var links = document.links; for (var i = 0, linksLength = links.length; i Overview One of the main attractions of using the R (http://cran.at.r-project.org) environment is the ease with which users can write their own programs and custom functions. The R programming syntax is extremely easy to learn, even for users with no previous programming experience. Once the basic R programming control structures are understood, users can use the R language as a powerful environment to perform complex custom analyses of almost any type of data (Gentleman 2008).\nWhy Programming in R?  Powerful statistical environment and programming language Facilitates reproducible research Efficient data structures make programming very easy Ease of implementing custom functions Powerful graphics Access to fast growing number of analysis packages Most widely used language in bioinformatics Is standard for data mining and biostatistical analysis Technical advantages: free, open-source, available for all OSs  R Basics The previous Rbasics tutorial provides a general introduction to the usage of the R environment and its basic command syntax. More details can be found in the R \u0026 BioConductor manual here.\nCode Editors for R Several excellent code editors are available that provide functionalities like R syntax highlighting, auto code indenting and utilities to send code/functions to the R console.\n RStudio: GUI-based IDE for R Vim-R-Tmux: R working environment based on vim and tmux Emacs (ESS add-on package) gedit and Rgedit RKWard Eclipse Tinn-R Notepad++ (NppToR)   Programming in R using RStudio     Programming in R using Vim or Emacs    Finding Help Reference list on R programming (selection)\n Advanced R, by Hadley Wickham R Programming for Bioinformatics, by Robert Gentleman S Programming, by W. N. Venables and B. D. Ripley Programming with Data, by John M. Chambers R Help \u0026 R Coding Conventions, Henrik Bengtsson, Lund University Programming in R (Vincent Zoonekynd) Peter’s R Programming Pages, University of Warwick Rtips, Paul Johnsson, University of Kansas R for Programmers, Norm Matloff, UC Davis High-Performance R, Dirk Eddelbuettel tutorial presented at useR-2008 C/C++ level programming for R, Gopi Goswami  Control Structures Important Operators Comparison operators  == (equal) != (not equal) \u003e (greater than) \u003e= (greater than or equal) \u003c (less than) \u003c= (less than or equal)  Logical operators  \u0026 (and) | (or) ! (not)  Conditional Executions: if Statements An if statement operates on length-one logical vectors.\nSyntax\nif(TRUE) { statements_1 } else { statements_2 }  Example\nif(1==0) { print(1) } else { print(2) }  ## [1] 2  Conditional Executions: ifelse Statements The ifelse statement operates on vectors.\nSyntax\nifelse(test, true_value, false_value)  Example\nx \u003c- 1:10 ifelse(x\u003c5, x, 0)  ## [1] 1 2 3 4 0 0 0 0 0 0  Loops for loop for loops iterate over elements of a looping vector.\nSyntax\nfor(variable in sequence) { statements }  Example\nmydf \u003c- iris myve \u003c- NULL for(i in seq(along=mydf[,1])) { myve \u003c- c(myve, mean(as.numeric(mydf[i,1:3]))) } myve[1:8]  ## [1] 3.333333 3.100000 3.066667 3.066667 3.333333 3.666667 3.133333 3.300000  Note: Inject into objecs is much faster than append approach with c, cbind, etc.\nExample\nmyve \u003c- numeric(length(mydf[,1])) for(i in seq(along=myve)) { myve[i] \u003c- mean(as.numeric(mydf[i,1:3])) } myve[1:8]  ## [1] 3.333333 3.100000 3.066667 3.066667 3.333333 3.666667 3.133333 3.300000  Conditional Stop of Loops The stop function can be used to break out of a loop (or a function) when a condition becomes TRUE. In addition, an error message will be printed.\nExample\nx \u003c- 1:10 z \u003c- NULL for(i in seq(along=x)) { if(x[i] \u003c 5) { z \u003c- c(z, x[i]-1) } else { stop(\"values need to be \u003c 5\") } }  while loop Iterates as long as a condition is true.\nSyntax\nwhile(condition) { statements }  Example\nz \u003c- 0 while(z\u003c5) { z \u003c- z + 2 print(z) }  ## [1] 2 ## [1] 4 ## [1] 6  The apply Function Family apply Syntax\napply(X, MARGIN, FUN, ARGs)  Arguments\n X: array, matrix or data.frame MARGIN: 1 for rows, 2 for columns FUN: one or more functions ARGs: possible arguments for functions  Example\napply(iris[1:8,1:3], 1, mean)  ## 1 2 3 4 5 6 7 8 ## 3.333333 3.100000 3.066667 3.066667 3.333333 3.666667 3.133333 3.300000  tapply Applies a function to vector components that are defined by a factor.\nSyntax\ntapply(vector, factor, FUN)  Example\niris[1:2,]  ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa  tapply(iris$Sepal.Length, iris$Species, mean)  ## setosa versicolor virginica ## 5.006 5.936 6.588  sapply, lapply and vapply All three apply a function to vector or list. The lapply function always returns a list, while sapply returns vector or matrix objects when possible. If not then a list is returned. The vapply function returns a vector or array of type matching the FUN.VALUE. Compared to sappy, vapply is a safer choice with respect to controlling specific output types to avoid exception handling problems.\nExamples\nl \u003c- list(a = 1:10, beta = exp(-3:3), logic = c(TRUE,FALSE,FALSE,TRUE)) lapply(l, mean)  ## $a ## [1] 5.5 ## ## $beta ## [1] 4.535125 ## ## $logic ## [1] 0.5  sapply(l, mean)  ## a beta logic ## 5.500000 4.535125 0.500000  vapply(l, mean, FUN.VALUE=numeric(1))  ## a beta logic ## 5.500000 4.535125 0.500000  Often used in combination with a function definition:\nlapply(names(l), function(x) mean(l[[x]])) sapply(names(l), function(x) mean(l[[x]])) vapply(names(l), function(x) mean(l[[x]]), FUN.VALUE=numeric(1))  Functions Function Overview A very useful feature of the R environment is the possibility to expand existing functions and to easily write custom functions. In fact, most of the R software can be viewed as a series of R functions.\nSyntax to define function\nmyfct \u003c- function(arg1, arg2, ...) { function_body }  Syntax to call functions\nmyfct(arg1=..., arg2=...)  The value returned by a function is the value of the function body, which is usually an unassigned final expression, e.g.: return()\nFunction Syntax Rules General\n Functions are defined by  The assignment with the keyword function The declaration of arguments/variables (arg1, arg2, ...) The definition of operations (function_body) that perform computations on the provided arguments. A function name needs to be assigned to call the function.    Naming\n Function names can be almost anything. However, the usage of names of existing functions should be avoided.  Arguments\n It is often useful to provide default values for arguments (e.g.: arg1=1:10). This way they don’t need to be provided in a function call. The argument list can also be left empty (myfct \u003c- function() { fct_body }) if a function is expected to return always the same value(s). The argument ... can be used to allow one function to pass on argument settings to another.  Body\n The actual expressions (commands/operations) are defined in the function body which should be enclosed by braces. The individual commands are separated by semicolons or new lines (preferred).  Usage\n Functions are called by their name followed by parentheses containing possible argument names. Empty parenthesis after the function name will result in an error message when a function requires certain arguments to be provided by the user. The function name alone will print the definition of a function.  Scope\n Variables created inside a function exist only for the life time of a function. Thus, they are not accessible outside of the function. To force variables in functions to exist globally, one can use the double assignment operator: \u003c\u003c-  Examples Define sample function\nmyfct \u003c- function(x1, x2=5) { z1 \u003c- x1 / x1 z2 \u003c- x2 * x2 myvec \u003c- c(z1, z2) return(myvec) }  Function usage\nApply function to values 2 and 5\nmyfct(x1=2, x2=5)  ## [1] 1 25  Run without argument names\nmyfct(2, 5)  ## [1] 1 25  Makes use of default value 5\nmyfct(x1=2)  ## [1] 1 25  Print function definition (often unintended)\nmyfct  ## function(x1, x2=5) { ## z1 \u003c- x1 / x1 ## z2 \u003c- x2 * x2 ## myvec \u003c- c(z1, z2) ## return(myvec) ## } ## \u003cbytecode: 0x575bef4fbd40\u003e  Useful Utilities Debugging Utilities Several debugging utilities are available for R. They include:\n traceback browser options(error=recover) options(error=NULL) debug  The Debugging in R page provides an overview of the available resources.\nRegular Expressions R’s regular expression utilities work similar as in other languages. To learn how to use them in R, one can consult the main help page on this topic with ?regexp.\nString matching with grep The grep function can be used for finding patterns in strings, here letter A in vector month.name.\nmonth.name[grep(\"A\", month.name)]  ## [1] \"April\" \"August\"  String substitution with gsub Example for using regular expressions to substitute a pattern by another one using a back reference. Remember: single escapes \\ need to be double escaped \\\\ in R.\ngsub('(i.*a)', 'xxx_\\\\1', \"virginica\", perl = TRUE)  ## [1] \"vxxx_irginica\"  Interpreting a Character String as Expression Some useful examples\nGenerates vector of object names in session\nmylist \u003c- ls() mylist[1]  ## [1] \"i\"  Executes 1st entry as expression\nget(mylist[1])  ## [1] 150  Alternative approach\neval(parse(text=mylist[1]))  ## [1] 150  Replacement, Split and Paste Functions for Strings Selected examples\nSubstitution with back reference which inserts in this example _ character\nx \u003c- gsub(\"(a)\",\"\\\\1_\", month.name[1], perl=T) x  ## [1] \"Ja_nua_ry\"  Split string on inserted character from above\nstrsplit(x,\"_\")  ## [[1]] ## [1] \"Ja\" \"nua\" \"ry\"  Reverse a character string by splitting first all characters into vector fields\npaste(rev(unlist(strsplit(x, NULL))), collapse=\"\")  ## [1] \"yr_aun_aJ\"  Time, Date and Sleep Selected examples\nReturn CPU (and other) times that an expression used (here ls)\nsystem.time(ls())  ## user system elapsed ## 0 0 0  Return the current system date and time\ndate()  ## [1] \"Thu Feb 18 14:46:40 2021\"  Pause execution of R expressions for a given number of seconds (e.g. in loop)\nSys.sleep(1)  Example Import of Specific File Lines with Regular Expression The following example demonstrates the retrieval of specific lines from an external file with a regular expression. First, an external file is created with the cat function, all lines of this file are imported into a vector with readLines, the specific elements (lines) are then retieved with the grep function, and the resulting lines are split into vector fields with strsplit.\ncat(month.name, file=\"zzz.txt\", sep=\"\\n\") x \u003c- readLines(\"zzz.txt\") x[1:6]  ## [1] \"January\" \"February\" \"March\" \"April\" \"May\" \"June\"  x \u003c- x[c(grep(\"^J\", as.character(x), perl = TRUE))] t(as.data.frame(strsplit(x, \"u\")))  ## [,1] [,2] ## c..Jan....ary.. \"Jan\" \"ary\" ## c..J....ne.. \"J\" \"ne\" ## c..J....ly.. \"J\" \"ly\"  Calling External Software External command-line software can be called with system. The following example calls blastall from R\nsystem(\"blastall -p blastp -i seq.fasta -d uniprot -o seq.blastp\")  ## Warning in system(\"blastall -p blastp -i seq.fasta -d uniprot -o seq.blastp\"): error in running ## command  Running R Scripts Possibilities for Executing R Scripts R console source(\"my_script.R\")  Command-line Rscript my_script.R # or just ./myscript.R after making it executable R CMD BATCH my_script.R # Alternative way 1 R --slave \u003c my_script.R # Alternative way 2  Passing arguments from command-line to R Create an R script named test.R with the following content:\nmyarg \u003c- commandArgs() print(iris[1:myarg[6], ])  Then run it from the command-line like this:\nRscript test.R 10  In the given example the number 10 is passed on from the command-line as an argument to the R script which is used to return to STDOUT the first 10 rows of the iris sample data. If several arguments are provided, they will be interpreted as one string and need to be split in R with the strsplit function. A more detailed example can be found here.\nBuilding R Packages Short Overview of Package Building Process R packages can be built with the package.skeleton function. The given example will create a directory named mypackage containing the skeleton of the package for all functions, methods and classes defined in the R script(s) passed on to the code_files argument. The basic structure of the package directory is described here. The package directory will also contain a file named Read-and-delete-me with instructions for completing the package:\npackage.skeleton(name=\"mypackage\", code_files=c(\"script1.R\", \"script2.R\"))  Once a package skeleton is available one can build the package from the command-line (Linux/OS X). This will create a tarball of the package with its version number encoded in the file name. Subequently, the package tarball needs to be checked for errors with:\nR CMD build mypackage R CMD check mypackage_1.0.tar.gz  Install package from source\ninstall.packages(\"mypackage_1.0.tar.gz\", repos=NULL)  For more details see here\nProgramming Exercises Exercise 1 for loop Task 1.1: Compute the mean of each row in myMA by applying the mean function in a for loop.\nmyMA \u003c- matrix(rnorm(500), 100, 5, dimnames=list(1:100, paste(\"C\", 1:5, sep=\"\"))) myve_for \u003c- NULL for(i in seq(along=myMA[,1])) { myve_for \u003c- c(myve_for, mean(as.numeric(myMA[i, ]))) } myResult \u003c- cbind(myMA, mean_for=myve_for) myResult[1:4, ]  ## C1 C2 C3 C4 C5 mean_for ## 1 -1.5890569 -0.00759616 -0.7651252 -0.1334947 1.75902044 -0.1472505 ## 2 -0.5760445 -0.07502956 1.8156748 -0.6022573 0.04071099 0.1206109 ## 3 0.1452555 -0.85005686 0.8514295 -0.4692688 -0.95188121 -0.2549044 ## 4 0.9678927 -0.48747853 0.5058947 0.5961237 -0.84373458 0.1477396  while loop Task 1.2: Compute the mean of each row in myMA by applying the mean function in a while loop.\nz \u003c- 1 myve_while \u003c- NULL while(z \u003c= length(myMA[,1])) { myve_while \u003c- c(myve_while, mean(as.numeric(myMA[z, ]))) z \u003c- z + 1 } myResult \u003c- cbind(myMA, mean_for=myve_for, mean_while=myve_while) myResult[1:4, -c(1,2)]  ## C3 C4 C5 mean_for mean_while ## 1 -0.7651252 -0.1334947 1.75902044 -0.1472505 -0.1472505 ## 2 1.8156748 -0.6022573 0.04071099 0.1206109 0.1206109 ## 3 0.8514295 -0.4692688 -0.95188121 -0.2549044 -0.2549044 ## 4 0.5058947 0.5961237 -0.84373458 0.1477396 0.1477396  Task 1.3: Confirm that the results from both mean calculations are identical\nall(myResult[,6] == myResult[,7])  ## [1] TRUE  apply loop Task 1.4: Compute the mean of each row in myMA by applying the mean function in an apply loop\nmyve_apply \u003c- apply(myMA, 1, mean) myResult \u003c- cbind(myMA, mean_for=myve_for, mean_while=myve_while, mean_apply=myve_apply) myResult[1:4, -c(1,2)]  ## C3 C4 C5 mean_for mean_while mean_apply ## 1 -0.7651252 -0.1334947 1.75902044 -0.1472505 -0.1472505 -0.1472505 ## 2 1.8156748 -0.6022573 0.04071099 0.1206109 0.1206109 0.1206109 ## 3 0.8514295 -0.4692688 -0.95188121 -0.2549044 -0.2549044 -0.2549044 ## 4 0.5058947 0.5961237 -0.84373458 0.1477396 0.1477396 0.1477396  Avoiding loops Task 1.5: When operating on large data sets it is much faster to use the rowMeans function\nmymean \u003c- rowMeans(myMA) myResult \u003c- cbind(myMA, mean_for=myve_for, mean_while=myve_while, mean_apply=myve_apply, mean_int=mymean) myResult[1:4, -c(1,2,3)]  ## C4 C5 mean_for mean_while mean_apply mean_int ## 1 -0.1334947 1.75902044 -0.1472505 -0.1472505 -0.1472505 -0.1472505 ## 2 -0.6022573 0.04071099 0.1206109 0.1206109 0.1206109 0.1206109 ## 3 -0.4692688 -0.95188121 -0.2549044 -0.2549044 -0.2549044 -0.2549044 ## 4 0.5961237 -0.84373458 0.1477396 0.1477396 0.1477396 0.1477396  Exercise 2 Custom functions Task 2.1: Use the following code as basis to implement a function that allows the user to compute the mean for any combination of columns in a matrix or data frame. The first argument of this function should specify the input data set, the second the mathematical function to be passed on (e.g. mean, sd, max) and the third one should allow the selection of the columns by providing a grouping vector.\nmyMA \u003c- matrix(rnorm(100000), 10000, 10, dimnames=list(1:10000, paste(\"C\", 1:10, sep=\"\"))) myMA[1:2,]  ## C1 C2 C3 C4 C5 C6 C7 C8 C9 ## 1 -0.1430870 1.6518732 -0.4030777 1.3449119 -1.275383 0.8054689 0.7659832 0.2528063 0.2783535 ## 2 -0.6469048 0.5299854 -0.4038505 0.4141411 -1.097646 1.9669993 -2.5523817 1.6555577 -1.4068711 ## C10 ## 1 -0.03573911 ## 2 -0.58036942  myList \u003c- tapply(colnames(myMA), c(1,1,1,2,2,2,3,3,4,4), list) names(myList) \u003c- sapply(myList, paste, collapse=\"_\") myMAmean \u003c- sapply(myList, function(x) apply(myMA[,x], 1, mean)) myMAmean[1:4,]  ## C1_C2_C3 C4_C5_C6 C7_C8 C9_C10 ## 1 0.3685695 0.29166595 0.5093947 0.121307169 ## 2 -0.1735900 0.42783144 -0.4484120 -0.993620282 ## 3 -0.5667075 -0.04833491 0.6504228 0.006118701 ## 4 0.7495088 -0.44156279 0.5179593 0.082354279  Exercise 3 Nested loops to generate similarity matrices Task 3.1: Create a sample list populated with character vectors of different lengths\nsetlist \u003c- lapply(11:30, function(x) sample(letters, x, replace=TRUE)) names(setlist) \u003c- paste(\"S\", seq(along=setlist), sep=\"\") setlist[1:6]  ## $S1 ## [1] \"s\" \"a\" \"m\" \"n\" \"w\" \"s\" \"m\" \"t\" \"n\" \"y\" \"c\" ## ## $S2 ## [1] \"x\" \"r\" \"p\" \"v\" \"a\" \"n\" \"d\" \"b\" \"o\" \"d\" \"g\" \"d\" ## ## $S3 ## [1] \"e\" \"p\" \"k\" \"q\" \"x\" \"p\" \"u\" \"s\" \"z\" \"t\" \"j\" \"r\" \"a\" ## ## $S4 ## [1] \"c\" \"f\" \"e\" \"j\" \"k\" \"j\" \"c\" \"q\" \"b\" \"j\" \"o\" \"x\" \"n\" \"x\" ## ## $S5 ## [1] \"q\" \"d\" \"a\" \"f\" \"j\" \"m\" \"m\" \"o\" \"c\" \"k\" \"c\" \"q\" \"s\" \"u\" \"s\" ## ## $S6 ## [1] \"v\" \"i\" \"f\" \"z\" \"d\" \"m\" \"w\" \"f\" \"u\" \"b\" \"l\" \"c\" \"g\" \"f\" \"c\" \"u\"  Task 3.2: Compute the length for all pairwise intersects of the vectors stored in setlist. The intersects can be determined with the %in% function like this: sum(setlist[[1]] %in% setlist[[2]])\nsetlist \u003c- sapply(setlist, unique) olMA \u003c- sapply(names(setlist), function(x) sapply(names(setlist), function(y) sum(setlist[[x]] %in% setlist[[y]]))) olMA[1:12,]  ## S1 S2 S3 S4 S5 S6 S7 S8 S9 S10 S11 S12 S13 S14 S15 S16 S17 S18 S19 S20 ## S1 8 2 3 2 4 3 3 4 6 3 3 5 5 8 4 8 6 5 8 5 ## S2 2 10 4 4 3 4 3 4 4 8 4 7 6 6 6 8 6 6 6 7 ## S3 3 4 12 5 6 2 5 6 6 7 7 7 7 6 6 9 12 8 9 8 ## S4 2 4 5 10 6 3 2 4 4 8 2 7 6 8 6 7 8 6 6 6 ## S5 4 3 6 6 11 5 3 6 7 8 5 6 5 8 6 10 9 7 9 7 ## S6 3 4 2 3 5 12 6 8 5 7 4 6 6 8 10 8 7 10 9 8 ## S7 3 3 5 2 3 6 11 5 7 5 4 5 6 5 8 8 6 7 7 8 ## S8 4 4 6 4 6 8 5 13 5 8 5 7 9 10 9 10 8 11 12 7 ## S9 6 4 6 4 7 5 7 5 13 8 5 8 8 7 8 11 9 6 8 11 ## S10 3 8 7 8 8 7 5 8 8 16 8 10 11 10 10 12 11 9 9 10 ## S11 3 4 7 2 5 4 4 5 5 8 11 6 6 6 7 7 10 7 9 9 ## S12 5 7 7 7 6 6 5 7 8 10 6 15 10 11 12 11 11 9 11 11  Task 3.3 Plot the resulting intersect matrix as heat map. The image or the heatmap.2 function from the gplots library can be used for this.\nimage(olMA)  Exercise 4 Build your own R package Task 4.1: Save one or more of your functions to a file called script.R and build the package with the package.skeleton function.\npackage.skeleton(name=\"mypackage\", code_files=c(\"script1.R\"))  Task 4.2: Build tarball of the package\nsystem(\"R CMD build mypackage\")  Task 4.3: Install and use package\ninstall.packages(\"mypackage_1.0.tar.gz\", repos=NULL, type=\"source\") library(mypackage) ?myMAcomp # Opens help for function defined by mypackage  Homework 5 Reverse and complement of DNA Task 1: Write a RevComp function that returns the reverse and complement of a DNA sequence string. Include an argument that will allow to return only the reversed sequence, the complemented sequence or the reversed and complemented sequence. The following R functions will be useful for the implementation:\nx \u003c- c(\"ATGCATTGGACGTTAG\") x  ## [1] \"ATGCATTGGACGTTAG\"  x \u003c- substring(x, 1:nchar(x), 1:nchar(x)) x  ## [1] \"A\" \"T\" \"G\" \"C\" \"A\" \"T\" \"T\" \"G\" \"G\" \"A\" \"C\" \"G\" \"T\" \"T\" \"A\" \"G\"  x \u003c- rev(x) x  ## [1] \"G\" \"A\" \"T\" \"T\" \"G\" \"C\" \"A\" \"G\" \"G\" \"T\" \"T\" \"A\" \"C\" \"G\" \"T\" \"A\"  x \u003c- paste(x, collapse=\"\") x  ## [1] \"GATTGCAGGTTACGTA\"  chartr(\"ATGC\", \"TACG\", x)  ## [1] \"CTAACGTCCAATGCAT\"  Task 2: Write a function that applies the RevComp function to many sequences stored in a vector.\nTranslate DNA into Protein Task 3: Write a function that will translate one or many DNA sequences in all three reading frames into proteins. The following commands will simplify this task:\nAAdf \u003c- read.table(file=\"http://faculty.ucr.edu/~tgirke/Documents/R_BioCond/My_R_Scripts/AA.txt\", header=TRUE, sep=\"\\t\") AAdf[1:4,]  ## Codon AA_1 AA_3 AA_Full AntiCodon ## 1 TCA S Ser Serine TGA ## 2 TCG S Ser Serine CGA ## 3 TCC S Ser Serine GGA ## 4 TCT S Ser Serine AGA  AAv \u003c- as.character(AAdf[,2]) names(AAv) \u003c- AAdf[,1] AAv  ## TCA TCG TCC TCT TTT TTC TTA TTG TAT TAC TAA TAG TGT TGC TGA TGG CTA CTG CTC CTT CCA CCG CCC CCT CAT ## \"S\" \"S\" \"S\" \"S\" \"F\" \"F\" \"L\" \"L\" \"Y\" \"Y\" \"*\" \"*\" \"C\" \"C\" \"*\" \"W\" \"L\" \"L\" \"L\" \"L\" \"P\" \"P\" \"P\" \"P\" \"H\" ## CAC CAA CAG CGA CGG CGC CGT ATT ATC ATA ATG ACA ACG ACC ACT AAT AAC AAA AAG AGT AGC AGA AGG GTA GTG ## \"H\" \"Q\" \"Q\" \"R\" \"R\" \"R\" \"R\" \"I\" \"I\" \"I\" \"M\" \"T\" \"T\" \"T\" \"T\" \"N\" \"N\" \"K\" \"K\" \"S\" \"S\" \"R\" \"R\" \"V\" \"V\" ## GTC GTT GCA GCG GCC GCT GAT GAC GAA GAG GGA GGG GGC GGT ## \"V\" \"V\" \"A\" \"A\" \"A\" \"A\" \"D\" \"D\" \"E\" \"E\" \"G\" \"G\" \"G\" \"G\"  y \u003c- gsub(\"(...)\", \"\\\\1_\", x) y \u003c- unlist(strsplit(y, \"_\")) y \u003c- y[grep(\"^...$\", y)] AAv[y]  ## GAT TGC AGG TTA CGT ## \"D\" \"C\" \"R\" \"L\" \"R\"  Homework submission Submit the 3 functions in one well structured and annotated R script to the instructor. The script should include instructions on how to use the functions.\nDue date This homework is due on Thu, April 26th at 6:00 PM.\nHomework Solutions See here\nSession Info sessionInfo()  ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C LC_TIME=en_US.UTF-8 ## [4] LC_COLLATE=en_US.UTF-8 LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C LC_ADDRESS=C ## [10] LC_TELEPHONE=C LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] ggplot2_3.3.2 limma_3.46.0 BiocStyle_2.18.0 ## ## loaded via a namespace (and not attached): ## [1] knitr_1.30 magrittr_2.0.1 tidyselect_1.1.0 munsell_0.5.0 ## [5] colorspace_2.0-0 R6_2.5.0 rlang_0.4.8 dplyr_1.0.2 ## [9] stringr_1.4.0 tools_4.0.4 grid_4.0.4 gtable_0.3.0 ## [13] xfun_0.20 withr_2.3.0 ellipsis_0.3.1 htmltools_0.5.1.1 ## [17] yaml_2.2.1 digest_0.6.27 tibble_3.0.4 lifecycle_0.2.0 ## [21] crayon_1.3.4 bookdown_0.21 purrr_0.3.4 BiocManager_1.30.10 ## [25] codetools_0.2-18 vctrs_0.3.5 glue_1.4.2 evaluate_0.14 ## [29] rmarkdown_2.5 blogdown_1.1.7 stringi_1.5.3 pillar_1.4.7 ## [33] compiler_4.0.4 generics_0.1.0 scales_1.1.1 pkgconfig_2.0.3  References Gentleman, Robert. 2008. R Programming for Bioinformatics (Chapman \u0026 Hall/CRC Computer Science \u0026 Data Analysis). 1 edition. Chapman; Hall/CRC. http://www.amazon.com/Programming-Bioinformatics-Chapman-Computer-Analysis/dp/1420063677.\n  ","categories":"","description":"","excerpt":"document.addEventListener(\"DOMContentLoaded\", function() { …","ref":"/manuals/rprogramming/rprogramming/","tags":"","title":"Programming in R"},{"body":"Overview  R provides a large number of packages for parallel evaluations on multi-core, multi-socket and multi-node systems. The latter are usually referred to as computer clusters. MPI is also supported For an overview of parallelization packages available for R see here One of the most comprehensive parallel computing environments for R is batchtools. Older versions of this package were released under the name BatchJobs (Bischl et al. 2015). batchtools supports both multi-core and multi-node computations with and without schedulers. By making use of cluster template files, most schedulers and queueing systems are supported (e.g. Torque, Sun Grid Engine, Slurm).  Reminder: Traditional Job Submission for R This topic is covered in more detail in other tutorials. The following only provides a very brief overview of this submission method.\n1. Create Slurm submission script, here called script_name.sh with:\n#!/bin/bash -l #SBATCH --nodes=1 #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --mem-per-cpu=1G #SBATCH --time=1-00:15:00 # 1 day and 15 minutes #SBATCH --mail-user=useremail@address.com #SBATCH --mail-type=ALL #SBATCH --job-name=\"some_test\" #SBATCH -p short # Choose queue/partition from: intel, batch, highmem, gpu, short Rscript my_script.R  2. Submit R script (my_script.R) called by above Slurm script with:\nsbatch script_name.sh  Parallel Evaluations on Clusters with batchtools  The following introduces the usage of batchtools for a computer cluster using SLURM as scheduler (workload manager). SLURM is the scheduler used by the HPCC. Similar instructions are provided in HPCC’s manual section covering batchtools here To simplify the evaluation of the R code on the following slides, the corresponding text version is available for download from here.  Hands-on Demo of batchtools Set up working directory for SLURM First login to your cluster account, open R and execute the following lines. This will create a test directory (here mytestdir), redirect R into this directory and then download the required files:\n slurm.tmpl .batchtools.conf.R  dir.create(\"mytestdir\") setwd(\"mytestdir\") download.file(\"https://bit.ly/3gZJBsy\", \"slurm.tmpl\") download.file(\"https://bit.ly/3nvSNHA\", \".batchtools.conf.R\")  Load package and define some custom function The following code defines a test function (here myFct) that will be run on the cluster for demonstration purposes.\nThe test function (myFct) subsets the iris data frame by rows, and appends the host name and R version of each node where the function was executed. The R version to be used on each node can be specified in the slurm.tmpl file (under module load).\nlibrary('RenvModule') module('load','slurm') # Loads slurm among other modules library(batchtools) myFct \u003c- function(x) { Sys.sleep(10) # to see job in queue, pause for 10 sec result \u003c- cbind(iris[x, 1:4,], Node=system(\"hostname\", intern=TRUE), Rversion=paste(R.Version()[6:7], collapse=\".\")) }  Submit jobs from R to cluster The following creates a batchtools registry, defines the number of jobs and resource requests, and then submits the jobs to the cluster via SLURM.\nreg \u003c- makeRegistry(file.dir=\"myregdir\", conf.file=\".batchtools.conf.R\") Njobs \u003c- 1:4 # Define number of jobs (here 4) ids \u003c- batchMap(fun=myFct, x=Njobs) done \u003c- submitJobs(ids, reg=reg, resources=list(partition=\"short\", walltime=120, ntasks=1, ncpus=1, memory=1024)) waitForJobs() # Wait until jobs are completed  Summarize job status After the jobs are completed one can inspect their status as follows.\ngetStatus() # Summarize job status showLog(Njobs[1]) # killJobs(Njobs) # # Possible from within R or outside with scancel  Access/assemble results The results are stored as .rds files in the registry directory (here myregdir). One can access them manually via readRDS or use various convenience utilities provided by the batchtools package.\nreadRDS(\"myregdir/results/1.rds\") # reads from rds file first result chunk loadResult(1) lapply(Njobs, loadResult) reduceResults(rbind) # Assemble result chunks in single data.frame do.call(\"rbind\", lapply(Njobs, loadResult))  Remove registry directory from file system By default existing registries will not be overwritten. If required one can explicitly clean and delete them with the following functions.\nclearRegistry() # Clear registry in R session removeRegistry(wait=0, reg=reg) # Delete registry directory # unlink(\"myregdir\", recursive=TRUE) # Same as previous line  Load registry into R Loading a registry can be useful when accessing the results at a later state or after moving them to a local system.\nfrom_file \u003c- loadRegistry(\"myregdir\", conf.file=\".batchtools.conf.R\") reduceResults(rbind)  Conclusions Advantages of batchtools  many parallelization methods multiple cores, and across both multiple CPU sockets and nodes most schedulers supported takes full advantage of a cluster robust job management by organizing results in registry file-based database simplifies submission, monitoring and restart of jobs well supported and maintained package  Session Info sessionInfo()  ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 ## [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## loaded via a namespace (and not attached): ## [1] compiler_4.0.4 magrittr_2.0.1 bookdown_0.21 tools_4.0.4 ## [5] htmltools_0.5.1.1 yaml_2.2.1 stringi_1.5.3 rmarkdown_2.5 ## [9] blogdown_1.1.7 knitr_1.30 stringr_1.4.0 digest_0.6.27 ## [13] xfun_0.20 rlang_0.4.8 evaluate_0.14  References Bischl, Bernd, Michel Lang, Olaf Mersmann, Jörg Rahnenführer, and Claus Weihs. 2015. “BatchJobs and BatchExperiments: Abstraction Mechanisms for Using R in Batch Environments.” Journal of Statistical Software. http://www.jstatsoft.org/v64/i11/.\n  ","categories":"","description":"","excerpt":"Overview  R provides a large number of packages for parallel …","ref":"/manuals/rparallel/rparallel/","tags":"","title":"Parallel Evaluations in R"},{"body":"document.addEventListener(\"DOMContentLoaded\", function() { document.querySelector(\"h1\").className = \"title\"; });  document.addEventListener(\"DOMContentLoaded\", function() { var links = document.links; for (var i = 0, linksLength = links.length; i Overview Sequence Analysis in R and Bioconductor R Base\n Some basic string handling utilities. Wide spectrum of numeric data analysis tools.  Bioconductor\nBioconductor packages provide much more sophisticated string handling utilities for sequence analysis (Lawrence et al. 2013; Huber et al. 2015).\n Biostrings: general sequence analysis environment ShortRead: pipeline for short read data IRanges: low-level infrastructure for range data GenomicRanges: high-level infrastructure for range data GenomicFeatures: managing transcript centric annotations GenomicAlignments: handling short genomic alignments Rsamtools: interface to samtools, bcftools and tabix BSgenome: genome annotation data biomaRt: interface to BioMart annotations rtracklayer: Annotation imports, interface to online genome browsers HelloRanges: Bedtools semantics in Bioc’s Ranges infrastructure  Package Requirements Several Bioconductor packages are required for this tutorial. To install them, execute the following lines in the R console. Please also make sure that you have a recent R version installed on your system. R versions 3.3.x or higher are recommended.\nsource(\"https://bioconductor.org/biocLite.R\") if (!requireNamespace(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\") BiocManager::install(c(\"Biostrings\", \"GenomicRanges\", \"rtracklayer\", \"systemPipeR\", \"seqLogo\", \"ShortRead\"))  Strings in R Base Basic String Matching and Parsing String matching Generate sample sequence data set\nmyseq \u003c- c(\"ATGCAGACATAGTG\", \"ATGAACATAGATCC\", \"GTACAGATCAC\")  String searching with regular expression support\nmyseq[grep(\"ATG\", myseq)]  ## [1] \"ATGCAGACATAGTG\" \"ATGAACATAGATCC\"  Searches myseq for first match of pattern “AT”\npos1 \u003c- regexpr(\"AT\", myseq) as.numeric(pos1); attributes(pos1)$match.length # Returns position information of matches  ## [1] 1 1 7 ## [1] 2 2 2  Searches myseq for all matches of pattern “AT”\npos2 \u003c- gregexpr(\"AT\", myseq) as.numeric(pos2[[1]]); attributes(pos2[[1]])$match.length # Returns positions of matches in first sequence  ## [1] 1 9 ## [1] 2 2  String substitution with regular expression support\ngsub(\"^ATG\", \"atg\", myseq)  ## [1] \"atgCAGACATAGTG\" \"atgAACATAGATCC\" \"GTACAGATCAC\"  Positional parsing nchar(myseq) # Computes length of strings  ## [1] 14 14 11  substring(myseq[1], c(1,3), c(2,5)) # Positional parsing of several fragments from one string  ## [1] \"AT\" \"GCA\"  substring(myseq, c(1,4,7), c(2,6,10)) # Positional parsing of many strings  ## [1] \"AT\" \"AAC\" \"ATCA\"  Random Sequence Generation Random DNA sequences of any length rand \u003c- sapply(1:100, function(x) paste(sample(c(\"A\",\"T\",\"G\",\"C\"), sample(10:20), replace=T), collapse=\"\")) rand[1:3]  ## [1] \"GGTCTATTTGCTGG\" \"CCTTCGCGGTAA\" \"AGAACTGATGCCAGAG\"  Count identical sequences table(c(rand[1:4], rand[1]))  ## ## AGAACTGATGCCAGAG CCTTCGCGGTAA GGTCTATTTGCTGG GTTTCTCCCTCAAATACTG ## 1 1 2 1  Extract reads from reference Note: this requires Biostrings package.\nlibrary(Biostrings) ref \u003c- DNAString(paste(sample(c(\"A\",\"T\",\"G\",\"C\"), 100000, replace=T), collapse=\"\")) randstart \u003c- sample(1:(length(ref)-15), 1000) randreads \u003c- Views(ref, randstart, width=15) rand_set \u003c- DNAStringSet(randreads) unlist(rand_set)  ## 15000-letter DNAString object ## seq: TACGTACTTCAGAAGTATATCATGATAGGGATGCCCTGTACGTCCA...CCTAGCGGAGCCTACTAACGCCGGAATTCGAAGACTGAATACGTAC  Sequences in Bioconductor Important Data Objects of Biostrings XString for single sequence  DNAString: for DNA RNAString: for RNA AAString: for amino acid BString: for any string  XStringSet for many sequences  `DNAStringSet``: for DNA RNAStringSet: for RNA AAStringSet: for amino acid BStringSet: for any string  QualityScaleXStringSet for sequences with quality data  QualityScaledDNAStringSet: for DNA QualityScaledRNAStringSet: for RNA QualityScaledAAStringSet: for amino acid QualityScaledBStringSet: for any string  Sequence Import and Export Download the following sequences to your current working directory and then import them into R: ftp://ftp.ncbi.nlm.nih.gov/genomes/archive/old_genbank/Bacteria/Halobacterium_sp_uid217/AE004437.ffn\ndir.create(\"data\", showWarnings = FALSE) # system(\"wget ftp://ftp.ncbi.nlm.nih.gov/genomes/archive/old_genbank/Bacteria/Halobacterium_sp_uid217/AE004437.ffn\") download.file(\"ftp://ftp.ncbi.nlm.nih.gov/genomes/archive/old_genbank/Bacteria/Halobacterium_sp_uid217/AE004437.ffn\", \"data/AE004437.ffn\")  Import FASTA file with readDNAStringSet\nmyseq \u003c- readDNAStringSet(\"data/AE004437.ffn\") myseq[1:3]  ## DNAStringSet object of length 3: ## width seq names ## [1] 1206 ATGACTCGGCGGTCTCGTGTCGGTGCCGGCCTC...GTCGTCGTTGTTCGACGCTGGCGGAACCCATGA gi|12057215|gb|AE... ## [2] 666 ATGAGCATCATCGAACTCGAAGGCGTGGTCAAA...GTCAACCTCGTCGATGGGGTGTTACACACGTGA gi|12057215|gb|AE... ## [3] 1110 ATGGCGTGGCGGAACCTCGGGCGGAACCGCGTG...AACGATCCGCCCGTCGAGGCGCTCGGCGAATGA gi|12057215|gb|AE...  Subset sequences with regular expression on sequence name field\nsub \u003c- myseq[grep(\"99.*\", names(myseq))] length(sub)  ## [1] 170  Export subsetted sequences to FASTA file\nwriteXStringSet(sub, file=\"./data/AE004437sub.ffn\", width=80)  Now inspect exported sequence file AE004437sub.ffn in a text editor\nWorking with XString Containers The XString stores the different types of biosequences in dedicated containers\nlibrary(Biostrings) d \u003c- DNAString(\"GCATAT-TAC\") d  ## 10-letter DNAString object ## seq: GCATAT-TAC  d[1:4]  ## 4-letter DNAString object ## seq: GCAT  RNA sequences\nr \u003c- RNAString(\"GCAUAU-UAC\") r \u003c- RNAString(d) # Converts d to RNAString object r  ## 10-letter RNAString object ## seq: GCAUAU-UAC  Protein sequences\np \u003c- AAString(\"HCWYHH\") p  ## 6-letter AAString object ## seq: HCWYHH  Any type of character strings\nb \u003c- BString(\"I store any set of characters. Other XString objects store only the IUPAC characters.\") b  ## 85-letter BString object ## seq: I store any set of characters. Other XString objects store only the IUPAC characters.  Working with XStringSet Containers XStringSet containers allow to store many biosequences in one object\ndset \u003c- DNAStringSet(c(\"GCATATTAC\", \"AATCGATCC\", \"GCATATTAC\")) names(dset) \u003c- c(\"seq1\", \"seq2\", \"seq3\") # Assigns names dset[1:2]  ## DNAStringSet object of length 2: ## width seq names ## [1] 9 GCATATTAC seq1 ## [2] 9 AATCGATCC seq2  Important utilities for XStringSet containers\nwidth(dset) # Returns the length of each sequences  ## [1] 9 9 9  d \u003c- dset[[1]] # The [[ subsetting operator returns a single entry as XString object dset2 \u003c- c(dset, dset) # Appends/concatenates two XStringSet objects dsetchar \u003c- as.character(dset) # Converts XStringSet to named vector dsetone \u003c- unlist(dset) # Collapses many sequences to a single one stored in a DNAString container  Sequence subsetting by positions:\nDNAStringSet(dset, start=c(1,2,3), end=c(4,8,5))  ## DNAStringSet object of length 3: ## width seq names ## [1] 4 GCAT seq1 ## [2] 7 ATCGATC seq2 ## [3] 3 ATA seq3  Multiple Alignment Class The XMultipleAlignment class stores the different types of multiple sequence alignments:\norigMAlign \u003c- readDNAMultipleAlignment(filepath = system.file(\"extdata\", \"msx2_mRNA.aln\", package = \"Biostrings\"), format = \"clustal\") origMAlign  ## DNAMultipleAlignment with 8 rows and 2343 columns ## aln names ## [1] -----TCCCGTCTCCGCAGCAAAAAAGTTTGAGTCG...TTGTCCAAACTCACAATTAAAAAAAAAAAAAAAAA gi|84452153|ref|N... ## [2] ------------------------------------...----------------------------------- gi|208431713|ref|... ## [3] ------------------------------------...----------------------------------- gi|118601823|ref|... ## [4] ----------------------AAAAGTTGGAGTCT...----------------------------------- gi|114326503|ref|... ## [5] ------------------------------------...----------------------------------- gi|119220589|ref|... ## [6] ------------------------------------...----------------------------------- gi|148540149|ref|... ## [7] --------------CGGCTCCGCAGCGCCTCACTCG...----------------------------------- gi|45383056|ref|N... ## [8] GGGGGAGACTTCAGAAGTTGTTGTCCTCTCCGCTGA...----------------------------------- gi|213515133|ref|...  Basic Sequence Manipulations Reverse and Complement randset \u003c- DNAStringSet(rand) complement(randset[1:2])  ## DNAStringSet object of length 2: ## width seq ## [1] 14 CCAGATAAACGACC ## [2] 12 GGAAGCGCCATT  reverse(randset[1:2])  ## DNAStringSet object of length 2: ## width seq ## [1] 14 GGTCGTTTATCTGG ## [2] 12 AATGGCGCTTCC  reverseComplement(randset[1:2])  ## DNAStringSet object of length 2: ## width seq ## [1] 14 CCAGCAAATAGACC ## [2] 12 TTACCGCGAAGG  Translate DNA into Protein translate(randset[1:2])  ## Warning in .Call2(\"DNAStringSet_translate\", x, skip_code, dna_codes[codon_alphabet], : in 'x[[1]]': ## last 2 bases were ignored ## AAStringSet object of length 2: ## width seq ## [1] 4 GLFA ## [2] 4 PSR*  Pattern Matching Pattern matching with mismatches Find pattern matches in reference\nmyseq1 \u003c- readDNAStringSet(\"./data/AE004437.ffn\") mypos \u003c- matchPattern(\"ATGGTG\", myseq1[[1]], max.mismatch=1)  Count only the corresponding matches\ncountPattern(\"ATGGCT\", myseq1[[1]], max.mismatch=1)  ## [1] 3  Count matches in many sequences\nvcountPattern(\"ATGGCT\", myseq1, max.mismatch=1)[1:20]  ## [1] 3 0 5 4 1 2 2 1 4 3 0 0 1 2 0 1 4 0 0 1  Results shown in DNAStringSet object\ntmp \u003c- c(DNAStringSet(\"ATGGTG\"), DNAStringSet(mypos))  Return a consensus matrix for query and hits\nconsensusMatrix(tmp)[1:4,]  ## [,1] [,2] [,3] [,4] [,5] [,6] ## A 3 0 0 0 0 0 ## C 1 1 0 0 0 0 ## G 0 0 4 4 1 4 ## T 0 3 0 0 3 0  Find all pattern matches in reference\nmyvpos \u003c- vmatchPattern(\"ATGGCT\", myseq1, max.mismatch=1) myvpos # The results are stored as MIndex object.  ## MIndex object of length 2058 ## $`gi|12057215|gb|AE004437.1|:248-1453 Halobacterium sp. NRC-1, complete genome` ## IRanges object with 3 ranges and 0 metadata columns: ## start end width ## \u003cinteger\u003e \u003cinteger\u003e \u003cinteger\u003e ## [1] 1 6 6 ## [2] 383 388 6 ## [3] 928 933 6 ## ## $`gi|12057215|gb|AE004437.1|:1450-2115 Halobacterium sp. NRC-1, complete genome` ## IRanges object with 0 ranges and 0 metadata columns: ## start end width ## \u003cinteger\u003e \u003cinteger\u003e \u003cinteger\u003e ## ## $`gi|12057215|gb|AE004437.1|:2145-3254 Halobacterium sp. NRC-1, complete genome` ## IRanges object with 5 ranges and 0 metadata columns: ## start end width ## \u003cinteger\u003e \u003cinteger\u003e \u003cinteger\u003e ## [1] 1 6 6 ## [2] 94 99 6 ## [3] 221 226 6 ## [4] 535 540 6 ## [5] 601 606 6 ## ## ... ## \u003c2055 more elements\u003e  Views(myseq1[[1]], start(myvpos[[1]]), end(myvpos[[1]])) # Retrieves the result for single entry  ## Views on a 1206-letter DNAString subject ## subject: ATGACTCGGCGGTCTCGTGTCGGTGCCGGCCTCGCAGCCATTGT...TTGCGATCGTCGTCGTCGTTGTTCGACGCTGGCGGAACCCATGA ## views: ## start end width ## [1] 1 6 6 [ATGACT] ## [2] 383 388 6 [ATGGCA] ## [3] 928 933 6 [ATGACT]  Return all matches\nsapply(seq(along=myseq1), function(x) as.character(Views(myseq1[[x]], start(myvpos[[x]]), end(myvpos[[x]]))))[1:4]  Pattern matching with regular expression support myseq \u003c- DNAStringSet(c(\"ATGCAGACATAGTG\", \"ATGAACATAGATCC\", \"GTACAGATCAC\")) myseq[grep(\"^ATG\", myseq, perl=TRUE)] # String searching with regular expression support  ## DNAStringSet object of length 2: ## width seq ## [1] 14 ATGCAGACATAGTG ## [2] 14 ATGAACATAGATCC  pos1 \u003c- regexpr(\"AT\", myseq) # Searches 'myseq' for first match of pattern \"AT\" as.numeric(pos1); attributes(pos1)$match.length # Returns position information of matches  ## [1] 1 1 7 ## [1] 2 2 2  pos2 \u003c- gregexpr(\"AT\", myseq) # Searches 'myseq' for all matches of pattern \"AT\" as.numeric(pos2[[1]]); attributes(pos2[[1]])$match.length # Match positions in first sequence  ## [1] 1 9 ## [1] 2 2  DNAStringSet(gsub(\"^ATG\", \"NNN\", myseq)) # String substitution with regular expression support  ## DNAStringSet object of length 3: ## width seq ## [1] 14 NNNCAGACATAGTG ## [2] 14 NNNAACATAGATCC ## [3] 11 GTACAGATCAC  PWM Viewing and Searching Plot with seqLogo library(seqLogo)  ## Loading required package: grid  pwm \u003c- PWM(DNAStringSet(c(\"GCT\", \"GGT\", \"GCA\"))) pwm  ## [,1] [,2] [,3] ## A 0.0000000 0.0000000 0.2312611 ## C 0.0000000 0.3157205 0.0000000 ## G 0.3685591 0.2312611 0.0000000 ## T 0.0000000 0.0000000 0.3157205  seqLogo(t(t(pwm) * 1/colSums(pwm)))  Plot with ggseqlogo The ggseqlogo package (manual) provides many customization options for plotting sequence logos. It also supports various alphabets including sequence logos for amino acid sequences.\nlibrary(ggplot2); library(ggseqlogo) pwm \u003c- PWM(DNAStringSet(c(\"GCT\", \"GGT\", \"GCA\"))) ggseqlogo(pwm)  Search sequence for PWM matches with score better than min.score\nchr \u003c- DNAString(\"AAAGCTAAAGGTAAAGCAAAA\") matchPWM(pwm, chr, min.score=0.9)  ## Views on a 21-letter DNAString subject ## subject: AAAGCTAAAGGTAAAGCAAAA ## views: ## start end width ## [1] 4 6 3 [GCT] ## [2] 10 12 3 [GGT] ## [3] 16 18 3 [GCA]  NGS Sequences Sequence and Quality Data: FASTQ Format Four lines per sequence:\n ID Sequence ID Base call qualities (Phred scores) as ASCII characters  The following gives an example of 3 Illumina reads in a FASTQ file. The numbers at the beginning of each line are not part of the FASTQ format. They have been added solely for illustration purposes.\n1. @SRR038845.3 HWI-EAS038:6:1:0:1938 length=36 2. CAACGAGTTCACACCTTGGCCGACAGGCCCGGGTAA 3. +SRR038845.3 HWI-EAS038:6:1:0:1938 length=36 4. BA@7\u003eB=\u003e:\u003e\u003e7@7@\u003e\u003e9=BAA?;\u003e52;\u003e:9=8.=A 1. @SRR038845.41 HWI-EAS038:6:1:0:1474 length=36 2. CCAATGATTTTTTTCCGTGTTTCAGAATACGGTTAA 3. +SRR038845.41 HWI-EAS038:6:1:0:1474 length=36 4. BCCBA@BB@BBBBAB@B9B@=BABA@A:@693:@B= 1. @SRR038845.53 HWI-EAS038:6:1:1:360 length=36 2. GTTCAAAAAGAACTAAATTGTGTCAATAGAAAACTC 3. +SRR038845.53 HWI-EAS038:6:1:1:360 length=36 4. BBCBBBBBB@@BAB?BBBBCBC\u003eBBBAA8\u003eBBBAA@  Sequence and Quality Data: QualityScaleXStringSet Phred quality scores are integers from 0-50 that are stored as ASCII characters after adding 33. The basic R functions rawToChar and charToRaw can be used to interconvert among their representations.\nPhred score interconversion\nphred \u003c- 1:9 phreda \u003c- paste(sapply(as.raw((phred)+33), rawToChar), collapse=\"\") phreda  ## [1] \"\\\"#$%\u0026'()*\"  as.integer(charToRaw(phreda))-33  ## [1] 1 2 3 4 5 6 7 8 9  Construct QualityScaledDNAStringSet from scratch\ndset \u003c- DNAStringSet(sapply(1:100, function(x) paste(sample(c(\"A\",\"T\",\"G\",\"C\"), 20, replace=T), collapse=\"\"))) # Creates random sample sequence. myqlist \u003c- lapply(1:100, function(x) sample(1:40, 20, replace=T)) # Creates random Phred score list. myqual \u003c- sapply(myqlist, function(x) toString(PhredQuality(x))) # Converts integer scores into ASCII characters. myqual \u003c- PhredQuality(myqual) # Converts to a PhredQuality object. dsetq1 \u003c- QualityScaledDNAStringSet(dset, myqual) # Combines DNAStringSet and quality data in QualityScaledDNAStringSet object. dsetq1[1:2]  ## A QualityScaledDNAStringSet instance containing: ## ## DNAStringSet object of length 2: ## width seq ## [1] 20 GGACTGCAATCACTAATCCC ## [2] 20 TCTGATGAACAAACTGGTTT ## ## PhredQuality object of length 2: ## width seq ## [1] 20 (@5.;ECA0$.3\u003c$'7?H3D ## [2] 20 5\u003c(;1C@*BI:92\u0026;#2F\u003eI  Processing FASTQ Files with ShortRead The following expains the basic usage of ShortReadQ objects. To make the sample code work, download and unzip this file to your current working directory. The following code performs the download for you.\nlibrary(ShortRead) download.file(\"http://cluster.hpcc.ucr.edu/~tgirke/HTML_Presentations/Manuals/Workshop_Dec_6_10_2012/Rsequences/data.zip\", \"data.zip\") unzip(\"data.zip\")  Important utilities for accessing FASTQ files\nfastq \u003c- list.files(\"data\", \"*.fastq$\"); fastq \u003c- paste(\"data/\", fastq, sep=\"\") names(fastq) \u003c- paste(\"flowcell6_lane\", 1:length(fastq), sep=\"_\") (fq \u003c- readFastq(fastq[1])) # Imports first FASTQ file  ## class: ShortReadQ ## length: 1000 reads; width: 36 cycles  countLines(dirPath=\"./data\", pattern=\".fastq$\")/4 # Counts numbers of reads in FASTQ files  ## SRR038845.fastq SRR038846.fastq SRR038848.fastq SRR038850.fastq ## 1000 1000 1000 1000  id(fq)[1] # Returns ID field  ## BStringSet object of length 1: ## width seq ## [1] 43 SRR038845.3 HWI-EAS038:6:1:0:1938 length=36  sread(fq)[1] # Returns sequence  ## DNAStringSet object of length 1: ## width seq ## [1] 36 CAACGAGTTCACACCTTGGCCGACAGGCCCGGGTAA  quality(fq)[1] # Returns Phred scores  ## class: FastqQuality ## quality: ## BStringSet object of length 1: ## width seq ## [1] 36 BA@7\u003eB=\u003e:\u003e\u003e7@7@\u003e\u003e9=BAA?;\u003e52;\u003e:9=8.=A  as(quality(fq), \"matrix\")[1:4,1:12] # Coerces Phred scores to numeric matrix  ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] ## [1,] 33 32 31 22 29 33 28 29 25 29 29 22 ## [2,] 33 34 34 33 32 31 33 33 31 33 33 33 ## [3,] 33 33 34 33 33 33 33 33 33 31 31 33 ## [4,] 33 33 33 33 31 33 28 31 28 32 33 33  ShortReadQ(sread=sread(fq), quality=quality(fq), id=id(fq)) # Constructs a ShortReadQ from components  ## class: ShortReadQ ## length: 1000 reads; width: 36 cycles  FASTQ Quality Reports Using systemPipeR The following seeFastq and seeFastqPlot functions generate and plot a series of useful quality statistics for a set of FASTQ files.\nlibrary(systemPipeR) fqlist \u003c- seeFastq(fastq=fastq, batchsize=800, klength=8) # For real data set batchsize to at least 10^5 seeFastqPlot(fqlist)  Handles many samples in one PDF file. For more details see here\nUsing ShortRead The ShortRead package contains several FASTQ quality reporting functions.\nsp \u003c- SolexaPath(system.file('extdata', package='ShortRead')) fl \u003c- file.path(analysisPath(sp), \"s_1_sequence.txt\") fls \u003c- c(fl, fl) coll \u003c- QACollate(QAFastqSource(fls), QAReadQuality(), QAAdapterContamination(), QANucleotideUse(), QAQualityUse(), QASequenceUse(), QAFrequentSequence(n=10), QANucleotideByCycle(), QAQualityByCycle()) x \u003c- qa2(coll, verbose=TRUE) res \u003c- report(x) if(interactive()) browseURL(res)  Filtering and Trimming FASTQ Files with ShortRead Adaptor trimming fqtrim \u003c- trimLRPatterns(Rpattern=\"GCCCGGGTAA\", subject=fq) sread(fq)[1:2] # Before trimming  ## DNAStringSet object of length 2: ## width seq ## [1] 36 CAACGAGTTCACACCTTGGCCGACAGGCCCGGGTAA ## [2] 36 CCAATGATTTTTTTCCGTGTTTCAGAATACGGTTAA  sread(fqtrim)[1:2] # After trimming  ## DNAStringSet object of length 2: ## width seq ## [1] 26 CAACGAGTTCACACCTTGGCCGACAG ## [2] 36 CCAATGATTTTTTTCCGTGTTTCAGAATACGGTTAA  Read counting and duplicate removal tables(fq)$distribution # Counts read occurences  ## nOccurrences nReads ## 1 1 948 ## 2 2 26  sum(srduplicated(fq)) # Identifies duplicated reads  ## [1] 26  fq[!srduplicated(fq)]  ## class: ShortReadQ ## length: 974 reads; width: 36 cycles  Trimming low quality tails cutoff \u003c- 30 cutoff \u003c- rawToChar(as.raw(cutoff+33)) sread(trimTails(fq, k=2, a=cutoff, successive=FALSE))[1:2]  ## DNAStringSet object of length 2: ## width seq ## [1] 4 CAAC ## [2] 20 CCAATGATTTTTTTCCGTGT  Removal of reads with Phred scores below a threshold value cutoff \u003c- 30 qcount \u003c- rowSums(as(quality(fq), \"matrix\") \u003c= 20) fq[qcount == 0] # Number of reads where all Phred scores \u003e= 20  ## class: ShortReadQ ## length: 349 reads; width: 36 cycles  Removal of reads with x Ns and/or low complexity segments filter1 \u003c- nFilter(threshold=1) # Keeps only reads without Ns filter2 \u003c- polynFilter(threshold=20, nuc=c(\"A\",\"T\",\"G\",\"C\")) # Removes reads with \u003e=20 of one nucleotide filter \u003c- compose(filter1, filter2) fq[filter(fq)]  ## class: ShortReadQ ## length: 989 reads; width: 36 cycles  Memory Efficient FASTQ Processing Streaming through FASTQ files with FastqStreamer and random sampling reads with FastqSampler\nfq \u003c- yield(FastqStreamer(fastq[1], 50)) # Imports first 50 reads fq \u003c- yield(FastqSampler(fastq[1], 50)) # Random samples 50 reads  Streaming through a FASTQ file while applying filtering/trimming functions and writing the results to a new file here SRR038845.fastq_sub in data directory.\nf \u003c- FastqStreamer(fastq[1], 50) while(length(fq \u003c- yield(f))) { fqsub \u003c- fq[grepl(\"^TT\", sread(fq))] writeFastq(fqsub, paste(fastq[1], \"sub\", sep=\"_\"), mode=\"a\", compress=FALSE) } close(f)  Range Operations Important Data Objects for Range Operations  IRanges: stores range data only (IRanges library) GRanges: stores ranges and annotations (GenomicRanges library) GRangesList: list version of GRanges container (GenomicRanges library)  Range Data Are Stored in IRanges and GRanges Containers Construct GRanges Object library(GenomicRanges); library(rtracklayer) gr \u003c- GRanges(seqnames = Rle(c(\"chr1\", \"chr2\", \"chr1\", \"chr3\"), c(1, 3, 2, 4)), ranges = IRanges(1:10, end = 7:16, names = head(letters, 10)), strand = Rle(strand(c(\"-\", \"+\", \"*\", \"+\", \"-\")), c(1, 2, 2, 3, 2)), score = 1:10, GC = seq(1, 0, length = 10)) # Example of creating a GRanges object with its constructor function.  Import GFF into GRanges Object gff \u003c- import.gff(\"http://cluster.hpcc.ucr.edu/~tgirke/Documents/R_BioCond/Samples/gff3.gff\") # Imports a simplified GFF3 genome annotation file. seqlengths(gff) \u003c- end(ranges(gff[which(values(gff)[,\"type\"]==\"chromosome\"),])) names(gff) \u003c- 1:length(gff) # Assigns names to corresponding slot gff[1:4,]  ## GRanges object with 4 ranges and 10 metadata columns: ## seqnames ranges strand | source type score phase ID ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e \u003cfactor\u003e \u003cnumeric\u003e \u003cinteger\u003e \u003ccharacter\u003e ## 1 Chr1 1-30427671 + | TAIR10 chromosome NA \u003cNA\u003e Chr1 ## 2 Chr1 3631-5899 + | TAIR10 gene NA \u003cNA\u003e AT1G01010 ## 3 Chr1 3631-5899 + | TAIR10 mRNA NA \u003cNA\u003e AT1G01010.1 ## 4 Chr1 3760-5630 + | TAIR10 protein NA \u003cNA\u003e AT1G01010.1-Protein ## Name Note Parent Index Derives_from ## \u003ccharacter\u003e \u003cCharacterList\u003e \u003cCharacterList\u003e \u003ccharacter\u003e \u003ccharacter\u003e ## 1 Chr1 \u003cNA\u003e \u003cNA\u003e ## 2 AT1G01010 protein_coding_gene \u003cNA\u003e \u003cNA\u003e ## 3 AT1G01010.1 AT1G01010 1 \u003cNA\u003e ## 4 AT1G01010.1 \u003cNA\u003e AT1G01010.1 ## ------- ## seqinfo: 7 sequences from an unspecified genome  Coerce GRanges object to data.frame as.data.frame(gff)[1:4, 1:7]  ## seqnames start end width strand source type ## 1 Chr1 1 30427671 30427671 + TAIR10 chromosome ## 2 Chr1 3631 5899 2269 + TAIR10 gene ## 3 Chr1 3631 5899 2269 + TAIR10 mRNA ## 4 Chr1 3760 5630 1871 + TAIR10 protein  Utilities for Range Containers Accessor and subsetting methods for GRanges objects Subsetting and replacement\ngff[1:4]  ## GRanges object with 4 ranges and 10 metadata columns: ## seqnames ranges strand | source type score phase ID ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e \u003cfactor\u003e \u003cnumeric\u003e \u003cinteger\u003e \u003ccharacter\u003e ## 1 Chr1 1-30427671 + | TAIR10 chromosome NA \u003cNA\u003e Chr1 ## 2 Chr1 3631-5899 + | TAIR10 gene NA \u003cNA\u003e AT1G01010 ## 3 Chr1 3631-5899 + | TAIR10 mRNA NA \u003cNA\u003e AT1G01010.1 ## 4 Chr1 3760-5630 + | TAIR10 protein NA \u003cNA\u003e AT1G01010.1-Protein ## Name Note Parent Index Derives_from ## \u003ccharacter\u003e \u003cCharacterList\u003e \u003cCharacterList\u003e \u003ccharacter\u003e \u003ccharacter\u003e ## 1 Chr1 \u003cNA\u003e \u003cNA\u003e ## 2 AT1G01010 protein_coding_gene \u003cNA\u003e \u003cNA\u003e ## 3 AT1G01010.1 AT1G01010 1 \u003cNA\u003e ## 4 AT1G01010.1 \u003cNA\u003e AT1G01010.1 ## ------- ## seqinfo: 7 sequences from an unspecified genome  gff[1:4, c(\"type\", \"ID\")]  ## GRanges object with 4 ranges and 2 metadata columns: ## seqnames ranges strand | type ID ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e \u003ccharacter\u003e ## 1 Chr1 1-30427671 + | chromosome Chr1 ## 2 Chr1 3631-5899 + | gene AT1G01010 ## 3 Chr1 3631-5899 + | mRNA AT1G01010.1 ## 4 Chr1 3760-5630 + | protein AT1G01010.1-Protein ## ------- ## seqinfo: 7 sequences from an unspecified genome  gff[2] \u003c- gff[3]  GRanges objects can be concatenated with the c function\nc(gff[1:2], gff[401:402])  ## GRanges object with 4 ranges and 10 metadata columns: ## seqnames ranges strand | source type score phase ID ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e \u003cfactor\u003e \u003cnumeric\u003e \u003cinteger\u003e \u003ccharacter\u003e ## 1 Chr1 1-30427671 + | TAIR10 chromosome NA \u003cNA\u003e Chr1 ## 2 Chr1 3631-5899 + | TAIR10 mRNA NA \u003cNA\u003e AT1G01010.1 ## 401 Chr5 5516-5769 - | TAIR10 protein NA \u003cNA\u003e AT5G01015.2-Protein ## 402 Chr5 5770-5801 - | TAIR10 five_prime_UTR NA \u003cNA\u003e \u003cNA\u003e ## Name Note Parent Index Derives_from ## \u003ccharacter\u003e \u003cCharacterList\u003e \u003cCharacterList\u003e \u003ccharacter\u003e \u003ccharacter\u003e ## 1 Chr1 \u003cNA\u003e \u003cNA\u003e ## 2 AT1G01010.1 AT1G01010 1 \u003cNA\u003e ## 401 AT5G01015.2 \u003cNA\u003e AT5G01015.2 ## 402 \u003cNA\u003e AT5G01015.2 \u003cNA\u003e \u003cNA\u003e ## ------- ## seqinfo: 7 sequences from an unspecified genome  Acessor functions\nseqnames(gff)  ## factor-Rle of length 449 with 7 runs ## Lengths: 72 22 38 118 172 13 14 ## Values : Chr1 Chr2 Chr3 Chr4 Chr5 ChrC ChrM ## Levels(7): Chr1 Chr2 Chr3 Chr4 Chr5 ChrC ChrM  ranges(gff)  ## IRanges object with 449 ranges and 0 metadata columns: ## start end width ## \u003cinteger\u003e \u003cinteger\u003e \u003cinteger\u003e ## 1 1 30427671 30427671 ## 2 3631 5899 2269 ## 3 3631 5899 2269 ## 4 3760 5630 1871 ## 5 3631 3913 283 ## ... ... ... ... ## 445 11918 12241 324 ## 446 11918 12241 324 ## 447 11918 12241 324 ## 448 11918 12241 324 ## 449 11918 12241 324  strand(gff)  ## factor-Rle of length 449 with 13 runs ## Lengths: 18 54 28 21 12 117 1 171 1 12 1 8 5 ## Values : + - + - + - + - + - + - + ## Levels(3): + - *  seqlengths(gff)  ## Chr1 Chr2 Chr3 Chr4 Chr5 ChrC ChrM ## 30427671 19698289 23459830 18585056 26975502 154478 366924  start(gff[1:4])  ## [1] 1 3631 3631 3760  end(gff[1:4])  ## [1] 30427671 5899 5899 5630  width(gff[1:4])  ## [1] 30427671 2269 2269 1871  Accessing metadata component\nvalues(gff) # or elementMetadata(gff)  ## DataFrame with 449 rows and 10 columns ## source type score phase ID Name Note ## \u003cfactor\u003e \u003cfactor\u003e \u003cnumeric\u003e \u003cinteger\u003e \u003ccharacter\u003e \u003ccharacter\u003e \u003cCharacterList\u003e ## 1 TAIR10 chromosome NA NA Chr1 Chr1 ## 2 TAIR10 mRNA NA NA AT1G01010.1 AT1G01010.1 ## 3 TAIR10 mRNA NA NA AT1G01010.1 AT1G01010.1 ## 4 TAIR10 protein NA NA AT1G01010.1-Protein AT1G01010.1 ## 5 TAIR10 exon NA NA NA NA ## ... ... ... ... ... ... ... ... ## 445 TAIR10 gene NA NA ATMG00030 ATMG00030 protein_coding_gene ## 446 TAIR10 mRNA NA NA ATMG00030.1 ATMG00030.1 ## 447 TAIR10 protein NA NA ATMG00030.1-Protein ATMG00030.1 ## 448 TAIR10 exon NA NA NA NA ## 449 TAIR10 CDS NA 0 NA NA ## Parent Index Derives_from ## \u003cCharacterList\u003e \u003ccharacter\u003e \u003ccharacter\u003e ## 1 NA NA ## 2 AT1G01010 1 NA ## 3 AT1G01010 1 NA ## 4 NA AT1G01010.1 ## 5 AT1G01010.1 NA NA ## ... ... ... ... ## 445 NA NA ## 446 ATMG00030 1 NA ## 447 NA ATMG00030.1 ## 448 ATMG00030.1 NA NA ## 449 ATMG00030.1,ATMG00030.1-Protein NA NA  values(gff)[, \"type\"][1:20]  ## [1] chromosome mRNA mRNA protein exon five_prime_UTR ## [7] CDS exon CDS exon CDS exon ## [13] CDS exon CDS exon CDS three_prime_UTR ## [19] gene mRNA ## Levels: chromosome gene mRNA protein exon five_prime_UTR CDS three_prime_UTR rRNA tRNA  gff[values(gff)[ ,\"type\"] == \"gene\"]  ## GRanges object with 21 ranges and 10 metadata columns: ## seqnames ranges strand | source type score phase ID Name ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e \u003cfactor\u003e \u003cnumeric\u003e \u003cinteger\u003e \u003ccharacter\u003e \u003ccharacter\u003e ## 19 Chr1 5928-8737 - | TAIR10 gene NA \u003cNA\u003e AT1G01020 AT1G01020 ## 64 Chr1 11649-13714 - | TAIR10 gene NA \u003cNA\u003e AT1G01030 AT1G01030 ## 74 Chr2 1025-2810 + | TAIR10 gene NA \u003cNA\u003e AT2G01008 AT2G01008 ## 84 Chr2 3706-5513 + | TAIR10 gene NA \u003cNA\u003e AT2G01010 AT2G01010 ## 87 Chr2 5782-5945 + | TAIR10 gene NA \u003cNA\u003e AT2G01020 AT2G01020 ## ... ... ... ... . ... ... ... ... ... ... ## 427 ChrC 383-1444 - | TAIR10 gene NA \u003cNA\u003e ATCG00020 ATCG00020 ## 432 ChrC 1717-4347 - | TAIR10 gene NA \u003cNA\u003e ATCG00030 ATCG00030 ## 437 ChrM 273-734 - | TAIR10 gene NA \u003cNA\u003e ATMG00010 ATMG00010 ## 442 ChrM 8848-11415 - | TAIR10 gene NA \u003cNA\u003e ATMG00020 ATMG00020 ## 445 ChrM 11918-12241 + | TAIR10 gene NA \u003cNA\u003e ATMG00030 ATMG00030 ## Note Parent Index Derives_from ## \u003cCharacterList\u003e \u003cCharacterList\u003e \u003ccharacter\u003e \u003ccharacter\u003e ## 19 protein_coding_gene \u003cNA\u003e \u003cNA\u003e ## 64 protein_coding_gene \u003cNA\u003e \u003cNA\u003e ## 74 protein_coding_gene \u003cNA\u003e \u003cNA\u003e ## 84 rRNA \u003cNA\u003e \u003cNA\u003e ## 87 rRNA \u003cNA\u003e \u003cNA\u003e ## ... ... ... ... ... ## 427 protein_coding_gene \u003cNA\u003e \u003cNA\u003e ## 432 tRNA \u003cNA\u003e \u003cNA\u003e ## 437 protein_coding_gene \u003cNA\u003e \u003cNA\u003e ## 442 rRNA \u003cNA\u003e \u003cNA\u003e ## 445 protein_coding_gene \u003cNA\u003e \u003cNA\u003e ## ------- ## seqinfo: 7 sequences from an unspecified genome  Useful utilities for GRanges objects Remove chromosome ranges\ngff \u003c- gff[values(gff)$type != \"chromosome\"]  Erase the strand information\nstrand(gff) \u003c- \"*\"  Collapses overlapping ranges to continuous ranges.\nreduce(gff)  ## GRanges object with 22 ranges and 0 metadata columns: ## seqnames ranges strand ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e ## [1] Chr1 3631-5899 * ## [2] Chr1 5928-8737 * ## [3] Chr1 11649-13714 * ## [4] Chr2 1025-2810 * ## [5] Chr2 3706-5513 * ## ... ... ... ... ## [18] ChrC 383-1444 * ## [19] ChrC 1717-4347 * ## [20] ChrM 273-734 * ## [21] ChrM 8848-11415 * ## [22] ChrM 11918-12241 * ## ------- ## seqinfo: 7 sequences from an unspecified genome  Return uncovered regions\ngaps(gff)  ## GRanges object with 43 ranges and 0 metadata columns: ## seqnames ranges strand ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e ## [1] Chr1 1-30427671 + ## [2] Chr1 1-30427671 - ## [3] Chr1 1-3630 * ## [4] Chr1 5900-5927 * ## [5] Chr1 8738-11648 * ## ... ... ... ... ## [39] ChrM 1-366924 - ## [40] ChrM 1-272 * ## [41] ChrM 735-8847 * ## [42] ChrM 11416-11917 * ## [43] ChrM 12242-366924 * ## ------- ## seqinfo: 7 sequences from an unspecified genome  More intuitive way to get uncovered regions\nsetdiff(as(seqinfo(gff), \"GRanges\"), gff)  ## GRanges object with 29 ranges and 0 metadata columns: ## seqnames ranges strand ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e ## [1] Chr1 1-3630 * ## [2] Chr1 5900-5927 * ## [3] Chr1 8738-11648 * ## [4] Chr1 13715-30427671 * ## [5] Chr2 1-1024 * ## ... ... ... ... ## [25] ChrC 4348-154478 * ## [26] ChrM 1-272 * ## [27] ChrM 735-8847 * ## [28] ChrM 11416-11917 * ## [29] ChrM 12242-366924 * ## ------- ## seqinfo: 7 sequences from an unspecified genome  Return disjoint ranges\ndisjoin(gff)  ## GRanges object with 211 ranges and 0 metadata columns: ## seqnames ranges strand ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e ## [1] Chr1 3631-3759 * ## [2] Chr1 3760-3913 * ## [3] Chr1 3914-3995 * ## [4] Chr1 3996-4276 * ## [5] Chr1 4277-4485 * ## ... ... ... ... ## [207] ChrC 1752-4310 * ## [208] ChrC 4311-4347 * ## [209] ChrM 273-734 * ## [210] ChrM 8848-11415 * ## [211] ChrM 11918-12241 * ## ------- ## seqinfo: 7 sequences from an unspecified genome  Returns coverage of ranges\ncoverage(gff)  ## RleList of length 7 ## $Chr1 ## integer-Rle of length 30427671 with 45 runs ## Lengths: 3630 129 154 82 281 ... 233 161 380 30413957 ## Values : 0 4 5 3 5 ... 4 2 4 0 ## ## $Chr2 ## integer-Rle of length 19698289 with 14 runs ## Lengths: 1024 248 185 53 362 ... 164 625 102 19691617 ## Values : 0 5 3 5 3 ... 3 0 5 0 ## ## $Chr3 ## integer-Rle of length 23459830 with 29 runs ## Lengths: 1652 145 139 111 95 ... 155 148 156 23453781 ## Values : 0 4 5 3 5 ... 3 5 4 0 ## ## $Chr4 ## integer-Rle of length 18585056 with 72 runs ## Lengths: 1179 357 1358 128 872 ... 212 114 74 18571697 ## Values : 0 5 0 5 3 ... 3 5 4 0 ## ## $Chr5 ## integer-Rle of length 26975502 with 64 runs ## Lengths: 1222 28 28 109 72 ... 76 55 174 26967058 ## Values : 0 4 7 13 16 ... 3 5 4 0 ## ## ... ## \u003c2 more elements\u003e  Return the index pairings for overlapping ranges\nfindOverlaps(gff, gff[1:4])  ## Hits object with 55 hits and 0 metadata columns: ## queryHits subjectHits ## \u003cinteger\u003e \u003cinteger\u003e ## [1] 1 1 ## [2] 1 2 ## [3] 1 4 ## [4] 1 3 ## [5] 2 1 ## ... ... ... ## [51] 16 1 ## [52] 16 2 ## [53] 16 3 ## [54] 17 1 ## [55] 17 2 ## ------- ## queryLength: 442 / subjectLength: 4  Counts overlapping ranges\ncountOverlaps(gff, gff[1:4])[1:40]  ## 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 ## 4 4 4 4 3 4 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 35 36 37 38 39 40 41 ## 0 0 0 0 0 0 0  Return only overlapping ranges\nsubsetByOverlaps(gff, gff[1:4])  ## GRanges object with 17 ranges and 10 metadata columns: ## seqnames ranges strand | source type score phase ID ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e \u003cfactor\u003e \u003cnumeric\u003e \u003cinteger\u003e \u003ccharacter\u003e ## 2 Chr1 3631-5899 * | TAIR10 mRNA NA \u003cNA\u003e AT1G01010.1 ## 3 Chr1 3631-5899 * | TAIR10 mRNA NA \u003cNA\u003e AT1G01010.1 ## 4 Chr1 3760-5630 * | TAIR10 protein NA \u003cNA\u003e AT1G01010.1-Protein ## 5 Chr1 3631-3913 * | TAIR10 exon NA \u003cNA\u003e \u003cNA\u003e ## 6 Chr1 3631-3759 * | TAIR10 five_prime_UTR NA \u003cNA\u003e \u003cNA\u003e ## .. ... ... ... . ... ... ... ... ... ## 14 Chr1 5174-5326 * | TAIR10 exon NA \u003cNA\u003e \u003cNA\u003e ## 15 Chr1 5174-5326 * | TAIR10 CDS NA 0 \u003cNA\u003e ## 16 Chr1 5439-5899 * | TAIR10 exon NA \u003cNA\u003e \u003cNA\u003e ## 17 Chr1 5439-5630 * | TAIR10 CDS NA 0 \u003cNA\u003e ## 18 Chr1 5631-5899 * | TAIR10 three_prime_UTR NA \u003cNA\u003e \u003cNA\u003e ## Name Note Parent Index Derives_from ## \u003ccharacter\u003e \u003cCharacterList\u003e \u003cCharacterList\u003e \u003ccharacter\u003e \u003ccharacter\u003e ## 2 AT1G01010.1 AT1G01010 1 \u003cNA\u003e ## 3 AT1G01010.1 AT1G01010 1 \u003cNA\u003e ## 4 AT1G01010.1 \u003cNA\u003e AT1G01010.1 ## 5 \u003cNA\u003e AT1G01010.1 \u003cNA\u003e \u003cNA\u003e ## 6 \u003cNA\u003e AT1G01010.1 \u003cNA\u003e \u003cNA\u003e ## .. ... ... ... ... ... ## 14 \u003cNA\u003e AT1G01010.1 \u003cNA\u003e \u003cNA\u003e ## 15 \u003cNA\u003e AT1G01010.1,AT1G01010.1-Protein \u003cNA\u003e \u003cNA\u003e ## 16 \u003cNA\u003e AT1G01010.1 \u003cNA\u003e \u003cNA\u003e ## 17 \u003cNA\u003e AT1G01010.1,AT1G01010.1-Protein \u003cNA\u003e \u003cNA\u003e ## 18 \u003cNA\u003e AT1G01010.1 \u003cNA\u003e \u003cNA\u003e ## ------- ## seqinfo: 7 sequences from an unspecified genome  GRangesList Objects sp \u003c- split(gff, seq(along=gff)) # Stores every range in separate component of a GRangesList object split(gff, seqnames(gff)) # Stores ranges of each chromosome in separate component.  ## GRangesList object of length 7: ## $Chr1 ## GRanges object with 71 ranges and 10 metadata columns: ## seqnames ranges strand | source type score phase ID ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e \u003cfactor\u003e \u003cnumeric\u003e \u003cinteger\u003e \u003ccharacter\u003e ## 2 Chr1 3631-5899 * | TAIR10 mRNA NA \u003cNA\u003e AT1G01010.1 ## 3 Chr1 3631-5899 * | TAIR10 mRNA NA \u003cNA\u003e AT1G01010.1 ## 4 Chr1 3760-5630 * | TAIR10 protein NA \u003cNA\u003e AT1G01010.1-Protein ## 5 Chr1 3631-3913 * | TAIR10 exon NA \u003cNA\u003e \u003cNA\u003e ## 6 Chr1 3631-3759 * | TAIR10 five_prime_UTR NA \u003cNA\u003e \u003cNA\u003e ## .. ... ... ... . ... ... ... ... ... ## 68 Chr1 13335-13714 * | TAIR10 exon NA \u003cNA\u003e \u003cNA\u003e ## 69 Chr1 12941-13173 * | TAIR10 five_prime_UTR NA \u003cNA\u003e \u003cNA\u003e ## 70 Chr1 11864-12940 * | TAIR10 CDS NA 0 \u003cNA\u003e ## 71 Chr1 11649-11863 * | TAIR10 three_prime_UTR NA \u003cNA\u003e \u003cNA\u003e ## 72 Chr1 11649-13173 * | TAIR10 exon NA \u003cNA\u003e \u003cNA\u003e ## Name Note Parent Index Derives_from ## \u003ccharacter\u003e \u003cCharacterList\u003e \u003cCharacterList\u003e \u003ccharacter\u003e \u003ccharacter\u003e ## 2 AT1G01010.1 AT1G01010 1 \u003cNA\u003e ## 3 AT1G01010.1 AT1G01010 1 \u003cNA\u003e ## 4 AT1G01010.1 \u003cNA\u003e AT1G01010.1 ## 5 \u003cNA\u003e AT1G01010.1 \u003cNA\u003e \u003cNA\u003e ## 6 \u003cNA\u003e AT1G01010.1 \u003cNA\u003e \u003cNA\u003e ## .. ... ... ... ... ... ## 68 \u003cNA\u003e AT1G01030.1 \u003cNA\u003e \u003cNA\u003e ## 69 \u003cNA\u003e AT1G01030.1 \u003cNA\u003e \u003cNA\u003e ## 70 \u003cNA\u003e AT1G01030.1,AT1G01030.1-Protein \u003cNA\u003e \u003cNA\u003e ## 71 \u003cNA\u003e AT1G01030.1 \u003cNA\u003e \u003cNA\u003e ## 72 \u003cNA\u003e AT1G01030.1 \u003cNA\u003e \u003cNA\u003e ## ------- ## seqinfo: 7 sequences from an unspecified genome ## ## ... ## \u003c6 more elements\u003e  unlist(sp) # Returns data as GRanges object  ## GRanges object with 442 ranges and 10 metadata columns: ## seqnames ranges strand | source type score phase ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e \u003cfactor\u003e \u003cnumeric\u003e \u003cinteger\u003e ## 1.2 Chr1 3631-5899 * | TAIR10 mRNA NA \u003cNA\u003e ## 2.3 Chr1 3631-5899 * | TAIR10 mRNA NA \u003cNA\u003e ## 3.4 Chr1 3760-5630 * | TAIR10 protein NA \u003cNA\u003e ## 4.5 Chr1 3631-3913 * | TAIR10 exon NA \u003cNA\u003e ## 5.6 Chr1 3631-3759 * | TAIR10 five_prime_UTR NA \u003cNA\u003e ## ... ... ... ... . ... ... ... ... ## 438.445 ChrM 11918-12241 * | TAIR10 gene NA \u003cNA\u003e ## 439.446 ChrM 11918-12241 * | TAIR10 mRNA NA \u003cNA\u003e ## 440.447 ChrM 11918-12241 * | TAIR10 protein NA \u003cNA\u003e ## 441.448 ChrM 11918-12241 * | TAIR10 exon NA \u003cNA\u003e ## 442.449 ChrM 11918-12241 * | TAIR10 CDS NA 0 ## ID Name Note Parent ## \u003ccharacter\u003e \u003ccharacter\u003e \u003cCharacterList\u003e \u003cCharacterList\u003e ## 1.2 AT1G01010.1 AT1G01010.1 AT1G01010 ## 2.3 AT1G01010.1 AT1G01010.1 AT1G01010 ## 3.4 AT1G01010.1-Protein AT1G01010.1 ## 4.5 \u003cNA\u003e \u003cNA\u003e AT1G01010.1 ## 5.6 \u003cNA\u003e \u003cNA\u003e AT1G01010.1 ## ... ... ... ... ... ## 438.445 ATMG00030 ATMG00030 protein_coding_gene ## 439.446 ATMG00030.1 ATMG00030.1 ATMG00030 ## 440.447 ATMG00030.1-Protein ATMG00030.1 ## 441.448 \u003cNA\u003e \u003cNA\u003e ATMG00030.1 ## 442.449 \u003cNA\u003e \u003cNA\u003e ATMG00030.1,ATMG00030.1-Protein ## Index Derives_from ## \u003ccharacter\u003e \u003ccharacter\u003e ## 1.2 1 \u003cNA\u003e ## 2.3 1 \u003cNA\u003e ## 3.4 \u003cNA\u003e AT1G01010.1 ## 4.5 \u003cNA\u003e \u003cNA\u003e ## 5.6 \u003cNA\u003e \u003cNA\u003e ## ... ... ... ## 438.445 \u003cNA\u003e \u003cNA\u003e ## 439.446 1 \u003cNA\u003e ## 440.447 \u003cNA\u003e ATMG00030.1 ## 441.448 \u003cNA\u003e \u003cNA\u003e ## 442.449 \u003cNA\u003e \u003cNA\u003e ## ------- ## seqinfo: 7 sequences from an unspecified genome  sp[1:4, \"type\"] # Subsetting of GRangesList objects is similar to GRanges objects.  ## GRangesList object of length 4: ## $`1` ## GRanges object with 1 range and 1 metadata column: ## seqnames ranges strand | type ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e ## 2 Chr1 3631-5899 * | mRNA ## ------- ## seqinfo: 7 sequences from an unspecified genome ## ## $`2` ## GRanges object with 1 range and 1 metadata column: ## seqnames ranges strand | type ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e ## 3 Chr1 3631-5899 * | mRNA ## ------- ## seqinfo: 7 sequences from an unspecified genome ## ## $`3` ## GRanges object with 1 range and 1 metadata column: ## seqnames ranges strand | type ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e ## 4 Chr1 3760-5630 * | protein ## ------- ## seqinfo: 7 sequences from an unspecified genome ## ## $`4` ## GRanges object with 1 range and 1 metadata column: ## seqnames ranges strand | type ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e ## 5 Chr1 3631-3913 * | exon ## ------- ## seqinfo: 7 sequences from an unspecified genome  lapply(sp[1:4], length) # Looping over GRangesList objects similar to lists  ## $`1` ## [1] 1 ## ## $`2` ## [1] 1 ## ## $`3` ## [1] 1 ## ## $`4` ## [1] 1  Transcript Ranges Storing annotation ranges in TranscriptDb databases makes many operations more robust and convenient.\nlibrary(GenomicFeatures) download.file(\"http://cluster.hpcc.ucr.edu/~tgirke/Documents/R_BioCond/Samples/gff3.gff\", \"data/gff3.gff\") txdb \u003c- makeTxDbFromGFF(file=\"data/gff3.gff\", format=\"gff\", dataSource=\"TAIR\", organism=\"Arabidopsis thaliana\")  ## Warning in .extract_exons_from_GRanges(cds_IDX, gr, mcols0, tx_IDX, feature = \"cds\", : 163 CDS couldn't be linked to a transcript so were dropped (showing only the first 6): ## seqid start end strand ID Name Parent Parent_type ## 1 Chr1 3760 3913 + \u003cNA\u003e \u003cNA\u003e AT1G01010.1-Protein \u003cNA\u003e ## 2 Chr1 3996 4276 + \u003cNA\u003e \u003cNA\u003e AT1G01010.1-Protein \u003cNA\u003e ## 3 Chr1 4486 4605 + \u003cNA\u003e \u003cNA\u003e AT1G01010.1-Protein \u003cNA\u003e ## 4 Chr1 4706 5095 + \u003cNA\u003e \u003cNA\u003e AT1G01010.1-Protein \u003cNA\u003e ## 5 Chr1 5174 5326 + \u003cNA\u003e \u003cNA\u003e AT1G01010.1-Protein \u003cNA\u003e ## 6 Chr1 5439 5630 + \u003cNA\u003e \u003cNA\u003e AT1G01010.1-Protein \u003cNA\u003e  saveDb(txdb, file=\"./data/TAIR10.sqlite\")  ## TxDb object: ## # Db type: TxDb ## # Supporting package: GenomicFeatures ## # Data source: TAIR ## # Organism: Arabidopsis thaliana ## # Taxonomy ID: 3702 ## # miRBase build ID: NA ## # Genome: NA ## # Nb of transcripts: 28 ## # Db created by: GenomicFeatures package from Bioconductor ## # Creation time: 2021-02-18 14:48:05 -0800 (Thu, 18 Feb 2021) ## # GenomicFeatures version at creation time: 1.42.1 ## # RSQLite version at creation time: 2.2.1 ## # DBSCHEMAVERSION: 1.2  txdb \u003c- loadDb(\"./data/TAIR10.sqlite\") transcripts(txdb)  ## GRanges object with 28 ranges and 2 metadata columns: ## seqnames ranges strand | tx_id tx_name ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cinteger\u003e \u003ccharacter\u003e ## [1] Chr1 3631-5899 + | 1 AT1G01010.1 ## [2] Chr1 5928-8737 - | 2 AT1G01020.1 ## [3] Chr1 6790-8737 - | 3 AT1G01020.2 ## [4] Chr1 11649-13714 - | 4 AT1G01030.1 ## [5] Chr2 1025-2810 + | 5 AT2G01008.1 ## ... ... ... ... . ... ... ## [24] ChrC 383-1444 - | 24 ATCG00020.1 ## [25] ChrC 1717-4347 - | 25 ATCG00030.1 ## [26] ChrM 11918-12241 + | 26 ATMG00030.1 ## [27] ChrM 273-734 - | 27 ATMG00010.1 ## [28] ChrM 8848-11415 - | 28 ATMG00020.1 ## ------- ## seqinfo: 7 sequences (2 circular) from an unspecified genome; no seqlengths  transcriptsBy(txdb, by = \"gene\")  ## GRangesList object of length 22: ## $AT1G01010 ## GRanges object with 1 range and 2 metadata columns: ## seqnames ranges strand | tx_id tx_name ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cinteger\u003e \u003ccharacter\u003e ## [1] Chr1 3631-5899 + | 1 AT1G01010.1 ## ------- ## seqinfo: 7 sequences (2 circular) from an unspecified genome; no seqlengths ## ## $AT1G01020 ## GRanges object with 2 ranges and 2 metadata columns: ## seqnames ranges strand | tx_id tx_name ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cinteger\u003e \u003ccharacter\u003e ## [1] Chr1 5928-8737 - | 2 AT1G01020.1 ## [2] Chr1 6790-8737 - | 3 AT1G01020.2 ## ------- ## seqinfo: 7 sequences (2 circular) from an unspecified genome; no seqlengths ## ## $AT1G01030 ## GRanges object with 1 range and 2 metadata columns: ## seqnames ranges strand | tx_id tx_name ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cinteger\u003e \u003ccharacter\u003e ## [1] Chr1 11649-13714 - | 4 AT1G01030.1 ## ------- ## seqinfo: 7 sequences (2 circular) from an unspecified genome; no seqlengths ## ## ... ## \u003c19 more elements\u003e  exonsBy(txdb, by = \"gene\")  ## GRangesList object of length 22: ## $AT1G01010 ## GRanges object with 6 ranges and 2 metadata columns: ## seqnames ranges strand | exon_id exon_name ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cinteger\u003e \u003ccharacter\u003e ## [1] Chr1 3631-3913 + | 1 \u003cNA\u003e ## [2] Chr1 3996-4276 + | 2 \u003cNA\u003e ## [3] Chr1 4486-4605 + | 3 \u003cNA\u003e ## [4] Chr1 4706-5095 + | 4 \u003cNA\u003e ## [5] Chr1 5174-5326 + | 5 \u003cNA\u003e ## [6] Chr1 5439-5899 + | 6 \u003cNA\u003e ## ------- ## seqinfo: 7 sequences (2 circular) from an unspecified genome; no seqlengths ## ## $AT1G01020 ## GRanges object with 12 ranges and 2 metadata columns: ## seqnames ranges strand | exon_id exon_name ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cinteger\u003e \u003ccharacter\u003e ## [1] Chr1 5928-6263 - | 7 \u003cNA\u003e ## [2] Chr1 6437-7069 - | 8 \u003cNA\u003e ## [3] Chr1 6790-7069 - | 9 \u003cNA\u003e ## [4] Chr1 7157-7232 - | 10 \u003cNA\u003e ## [5] Chr1 7157-7450 - | 11 \u003cNA\u003e ## ... ... ... ... . ... ... ## [8] Chr1 7762-7835 - | 14 \u003cNA\u003e ## [9] Chr1 7942-7987 - | 15 \u003cNA\u003e ## [10] Chr1 8236-8325 - | 16 \u003cNA\u003e ## [11] Chr1 8417-8464 - | 17 \u003cNA\u003e ## [12] Chr1 8571-8737 - | 18 \u003cNA\u003e ## ------- ## seqinfo: 7 sequences (2 circular) from an unspecified genome; no seqlengths ## ## $AT1G01030 ## GRanges object with 2 ranges and 2 metadata columns: ## seqnames ranges strand | exon_id exon_name ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cinteger\u003e \u003ccharacter\u003e ## [1] Chr1 11649-13173 - | 19 \u003cNA\u003e ## [2] Chr1 13335-13714 - | 20 \u003cNA\u003e ## ------- ## seqinfo: 7 sequences (2 circular) from an unspecified genome; no seqlengths ## ## ... ## \u003c19 more elements\u003e  txdb from BioMart Alternative sources for creating txdb databases are BioMart, Bioc annotation packages, UCSC, etc. The following shows how to create a txdb from BioMart.\nlibrary(GenomicFeatures); library(\"biomaRt\") txdb \u003c- makeTxDbFromBiomart(biomart = \"plants_mart\", dataset = \"athaliana_eg_gene\", host=\"plants.ensembl.org\")  The following steps are useful to find out what is availble in BioMart.\nlistMarts() # Lists BioMart databases listMarts(host=\"plants.ensembl.org\") mymart \u003c- useMart(\"plants_mart\", host=\"plants.ensembl.org\") # Select one, here plants_mart_25 listDatasets(mymart) # List datasets available in the selected BioMart database mymart \u003c- useMart(\"plants_mart\", dataset=\"athaliana_eg_gene\", host=\"plants.ensembl.org\") listAttributes(mymart) # List available features getBM(attributes=c(\"ensembl_gene_id\", \"description\"), mart=mymart)[1:4,]  Efficient Sequence Parsing getSeq The following parses all annotation ranges provided by a GRanges object (e.g. gff) from a genome sequence stored in a local file.\ngff \u003c- gff[values(gff)$type != \"chromosome\"] # Remove chromosome ranges rand \u003c- DNAStringSet(sapply(unique(as.character(seqnames(gff))), function(x) paste(sample(c(\"A\",\"T\",\"G\",\"C\"), 200000, replace=T), collapse=\"\"))) writeXStringSet(DNAStringSet(rand), \"./data/test\") getSeq(FaFile(\"./data/test\"), gff)  ## DNAStringSet object of length 442: ## width seq names ## [1] 2269 CTTGGCTAGGCTGCCACATTCGTAACCCAGAT...GATACTGCCTCGACTTCCGGCATCTGATCATC Chr1 ## [2] 2269 CTTGGCTAGGCTGCCACATTCGTAACCCAGAT...GATACTGCCTCGACTTCCGGCATCTGATCATC Chr1 ## [3] 1871 TTGTGGGATAAAAATGCTATCAATGAGTGTGA...CATGAAGCAACAACCTAGCCGGTTAACCACCC Chr1 ## [4] 283 CTTGGCTAGGCTGCCACATTCGTAACCCAGAT...ATGCCCATACGGTTGGTTGTGGATTCCGCTAG Chr1 ## [5] 129 CTTGGCTAGGCTGCCACATTCGTAACCCAGAT...AGCCACGTATGGGCCGTCGTGGGCGGTCCATC Chr1 ## ... ... ... ## [438] 324 TCCGGTGACGCCCGCTAACACGGCGGGGGGTG...AATCACAAATGGTATGCGTCGTGTCAACTGCA ChrM ## [439] 324 TCCGGTGACGCCCGCTAACACGGCGGGGGGTG...AATCACAAATGGTATGCGTCGTGTCAACTGCA ChrM ## [440] 324 TCCGGTGACGCCCGCTAACACGGCGGGGGGTG...AATCACAAATGGTATGCGTCGTGTCAACTGCA ChrM ## [441] 324 TCCGGTGACGCCCGCTAACACGGCGGGGGGTG...AATCACAAATGGTATGCGTCGTGTCAACTGCA ChrM ## [442] 324 TCCGGTGACGCCCGCTAACACGGCGGGGGGTG...AATCACAAATGGTATGCGTCGTGTCAACTGCA ChrM  extractTranscriptSeqs Sequences composed of several ranges, such as transcripts (or CDSs) with several exons, can be parsed with extractTranscriptSeqs. Note: the following expects the genome sequence in a file called mygenome.fasta and a valid txdb defining the ranges for that genome.\nlibrary(GenomicFeatures); library(Biostrings); library(Rsamtools) indexFa(\"mygenome.fasta\") # Creates index for genome fasta txseq \u003c- extractTranscriptSeqs(FaFile(\"mygenome.fasta\"), txdb, use.names=TRUE)  Homework 6 HW6a - Demultiplexing Write a demultiplexing function that accepts any number of barcodes and splits a FASTQ file into as many subfiles as there are barcodes. At the same time the function should remove low quality tails from the reads. The following function accomplishes the first step. Expand this function so that it performs the second step as well.\ndemultiplex \u003c- function(x, barcode, nreads) { f \u003c- FastqStreamer(x, nreads) while(length(fq \u003c- yield(f))) { for(i in barcode) { pattern \u003c- paste(\"^\", i, sep=\"\") fqsub \u003c- fq[grepl(pattern, sread(fq))] if(length(fqsub) \u003e 0) { writeFastq(fqsub, paste(x, i, sep=\"_\"), mode=\"a\", compress=FALSE) } } } close(f) } demultiplex(x=fastq[1], barcode=c(\"TT\", \"AA\", \"GG\"), nreads=50)  HW6b - Sequence Parsing  Download GFF from Halobacterium sp here Download genome sequence from Halobacterium sp here Task 1 Extract gene ranges, parse their sequences from genome and translate them into proteins Task 2 Reduce overlapping genes and parse their sequences from genome Task 3 Generate intergenic ranges and parse their sequences from genome  Useful commands\ndownload.file(\"ftp://ftp.ncbi.nlm.nih.gov/genomes/archive/old_genbank/Bacteria/Halobacterium_sp_uid217/AE004437.gff\", \"data/AE004437.gff\") download.file(\"ftp://ftp.ncbi.nlm.nih.gov/genomes/archive/old_genbank/Bacteria/Halobacterium_sp_uid217/AE004437.fna\", \"data/AE004437.fna\") chr \u003c- readDNAStringSet(\"data/AE004437.fna\") gff \u003c- import(\"data/AE004437.gff\") gffgene \u003c- gff[values(gff)[,\"type\"]==\"gene\"] gene \u003c- DNAStringSet(Views(chr[[1]], IRanges(start(gffgene), end(gffgene)))) names(gene) \u003c- values(gffgene)[,\"locus_tag\"] pos \u003c- values(gffgene[strand(gffgene) == \"+\"])[,\"locus_tag\"] p1 \u003c- translate(gene[names(gene) %in% pos]) names(p1) \u003c- names(gene[names(gene) %in% pos]) neg \u003c- values(gffgene[strand(gffgene) == \"-\"])[,\"locus_tag\"] p2 \u003c- translate(reverseComplement(gene[names(gene) %in% neg])) names(p2) \u003c- names(gene[names(gene) %in% neg]) writeXStringSet(c(p1, p2), \"./data/mypep.fasta\")  Homework submission Submit the homework results in one well structured and annotated R script to the instructor. The script should include instructions on how to use the functions.\nDue date This homework is due on …\nHomework Solutions See here\nSession Info sessionInfo()  ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C LC_TIME=en_US.UTF-8 ## [4] LC_COLLATE=en_US.UTF-8 LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C LC_ADDRESS=C ## [10] LC_TELEPHONE=C LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] grid stats4 parallel stats graphics grDevices utils datasets methods ## [10] base ## ## other attached packages: ## [1] GenomicFeatures_1.42.1 AnnotationDbi_1.52.0 rtracklayer_1.50.0 ## [4] systemPipeR_1.24.2 ShortRead_1.48.0 GenomicAlignments_1.26.0 ## [7] SummarizedExperiment_1.20.0 Biobase_2.50.0 MatrixGenerics_1.2.0 ## [10] matrixStats_0.57.0 Rsamtools_2.6.0 GenomicRanges_1.42.0 ## [13] GenomeInfoDb_1.26.1 BiocParallel_1.24.1 ggseqlogo_0.1 ## [16] seqLogo_1.56.0 Biostrings_2.58.0 XVector_0.30.0 ## [19] IRanges_2.24.0 S4Vectors_0.28.0 BiocGenerics_0.36.0 ## [22] ggplot2_3.3.2 limma_3.46.0 BiocStyle_2.18.0 ## ## loaded via a namespace (and not attached): ## [1] colorspace_2.0-0 rjson_0.2.20 hwriter_1.3.2 ## [4] ellipsis_0.3.1 farver_2.0.3 bit64_4.0.5 ## [7] xml2_1.3.2 codetools_0.2-18 splines_4.0.4 ## [10] knitr_1.30 jsonlite_1.7.1 annotate_1.68.0 ## [13] GO.db_3.12.1 dbplyr_2.0.0 png_0.1-7 ## [16] pheatmap_1.0.12 graph_1.68.0 BiocManager_1.30.10 ## [19] compiler_4.0.4 httr_1.4.2 GOstats_2.56.0 ## [22] backports_1.2.0 assertthat_0.2.1 Matrix_1.3-2 ## [25] htmltools_0.5.1.1 prettyunits_1.1.1 tools_4.0.4 ## [28] gtable_0.3.0 glue_1.4.2 GenomeInfoDbData_1.2.4 ## [31] Category_2.56.0 dplyr_1.0.2 rsvg_2.1 ## [34] batchtools_0.9.14 rappdirs_0.3.1 V8_3.4.0 ## [37] Rcpp_1.0.5 vctrs_0.3.5 blogdown_1.1.7 ## [40] xfun_0.20 stringr_1.4.0 lifecycle_0.2.0 ## [43] XML_3.99-0.5 edgeR_3.32.0 zlibbioc_1.36.0 ## [46] scales_1.1.1 BSgenome_1.58.0 VariantAnnotation_1.36.0 ## [49] hms_0.5.3 RBGL_1.66.0 RColorBrewer_1.1-2 ## [52] yaml_2.2.1 curl_4.3 memoise_1.1.0 ## [55] biomaRt_2.46.0 latticeExtra_0.6-29 stringi_1.5.3 ## [58] RSQLite_2.2.1 genefilter_1.72.0 checkmate_2.0.0 ## [61] DOT_0.1 rlang_0.4.8 pkgconfig_2.0.3 ## [64] bitops_1.0-6 evaluate_0.14 lattice_0.20-41 ## [67] purrr_0.3.4 labeling_0.4.2 bit_4.0.4 ## [70] tidyselect_1.1.0 GSEABase_1.52.0 AnnotationForge_1.32.0 ## [73] magrittr_2.0.1 bookdown_0.21 R6_2.5.0 ## [76] generics_0.1.0 base64url_1.4 DelayedArray_0.16.0 ## [79] DBI_1.1.0 pillar_1.4.7 withr_2.3.0 ## [82] survival_3.2-7 RCurl_1.98-1.2 tibble_3.0.4 ## [85] crayon_1.3.4 BiocFileCache_1.14.0 rmarkdown_2.5 ## [88] jpeg_0.1-8.1 progress_1.2.2 locfit_1.5-9.4 ## [91] data.table_1.13.2 blob_1.2.1 Rgraphviz_2.34.0 ## [94] digest_0.6.27 xtable_1.8-4 brew_1.0-6 ## [97] openssl_1.4.3 munsell_0.5.0 viridisLite_0.3.0 ## [100] askpass_1.1  References Huber, Wolfgang, Vincent J Carey, Robert Gentleman, Simon Anders, Marc Carlson, Benilton S Carvalho, Hector Corrada Bravo, et al. 2015. “Orchestrating High-Throughput Genomic Analysis with Bioconductor.” Nat. Methods 12 (2): 115–21. https://doi.org/10.1038/nmeth.3252.\n Lawrence, Michael, Wolfgang Huber, Hervé Pagès, Patrick Aboyoun, Marc Carlson, Robert Gentleman, Martin T Morgan, and Vincent J Carey. 2013. “Software for Computing and Annotating Genomic Ranges.” PLoS Comput. Biol. 9 (8): e1003118. https://doi.org/10.1371/journal.pcbi.1003118.\n  ","categories":"","description":"","excerpt":"document.addEventListener(\"DOMContentLoaded\", function() { …","ref":"/manuals/rsequences/rsequences/","tags":"","title":"NGS Analysis Basics"},{"body":"document.addEventListener(\"DOMContentLoaded\", function() { document.querySelector(\"h1\").className = \"title\"; });  document.addEventListener(\"DOMContentLoaded\", function() { var links = document.links; for (var i = 0, linksLength = links.length; i Overview Graphics in R  Powerful environment for visualizing scientific data Integrated graphics and statistics infrastructure Publication quality graphics Fully programmable Highly reproducible Full LaTeX, Sweave, knitr and R Markdown support. Vast number of R packages with graphics utilities  Documentation on Graphics in R  General  Graphics Task Page R Graph Gallery R Graphical Manual Paul Murrell’s book R (Grid) Graphics   Interactive graphics  rggobi (GGobi) iplots Open GL (rgl)    Graphics Environments  Viewing and savings graphics in R  On-screen graphics postscript, pdf, svg jpeg/png/wmf/tiff/…   Four major graphics environments  Low-level infrastructure  R Base Graphics (low- and high-level) grid: Manual, Book   High-level infrastructure  lattice: Manual, Intro, Book ggplot2: Manual, Intro, Book      Base Graphics Overview  Important high-level plotting functions  plot: generic x-y plotting barplot: bar plots boxplot: box-and-whisker plot hist: histograms pie: pie charts dotchart: cleveland dot plots image, heatmap, contour, persp: functions to generate image-like plots qqnorm, qqline, qqplot: distribution comparison plots pairs, coplot: display of multivariant data   Help on these functions  ?myfct ?plot ?par    Preferred Input Data Objects  Matrices and data frames Vectors Named vectors  Scatter Plots Basic scatter plots Sample data set for subsequent plots\nset.seed(1410) y \u003c- matrix(runif(30), ncol=3, dimnames=list(letters[1:10], LETTERS[1:3])) plot(y[,1], y[,2])  All pairs pairs(y)  Plot labels plot(y[,1], y[,2], pch=20, col=\"red\", main=\"Symbols and Labels\") text(y[,1]+0.03, y[,2], rownames(y))  More examples Print instead of symbols the row names\nplot(y[,1], y[,2], type=\"n\", main=\"Plot of Labels\") text(y[,1], y[,2], rownames(y))  Usage of important plotting parameters\ngrid(5, 5, lwd = 2) op \u003c- par(mar=c(8,8,8,8), bg=\"lightblue\") plot(y[,1], y[,2], type=\"p\", col=\"red\", cex.lab=1.2, cex.axis=1.2, cex.main=1.2, cex.sub=1, lwd=4, pch=20, xlab=\"x label\", ylab=\"y label\", main=\"My Main\", sub=\"My Sub\") par(op)  Important arguments} - mar: specifies the margin sizes around the plotting area in order: c(bottom, left, top, right) - col: color of symbols - pch: type of symbols, samples: example(points) - lwd: size of symbols - cex.*: control font sizes - For details see ?par\nAdd a regression line to a plot\nplot(y[,1], y[,2]) myline \u003c- lm(y[,2]~y[,1]); abline(myline, lwd=2)  summary(myline)  ## ## Call: ## lm(formula = y[, 2] ~ y[, 1]) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.40357 -0.17912 -0.04299 0.22147 0.46623 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u003e|t|) ## (Intercept) 0.5764 0.2110 2.732 0.0258 * ## y[, 1] -0.3647 0.3959 -0.921 0.3839 ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## Residual standard error: 0.3095 on 8 degrees of freedom ## Multiple R-squared: 0.09589, Adjusted R-squared: -0.01712 ## F-statistic: 0.8485 on 1 and 8 DF, p-value: 0.3839  Same plot as above, but on log scale\nplot(y[,1], y[,2], log=\"xy\")  Add a mathematical expression to a plot\nplot(y[,1], y[,2]); text(y[1,1], y[1,2], expression(sum(frac(1,sqrt(x^2*pi)))), cex=1.3)  Exercise 1  Task 1: Generate scatter plot for first two columns in iris data frame and color dots by its Species column. Task 2: Use the xlim/ylim arguments to set limits on the x- and y-axes so that all data points are restricted to the left bottom quadrant of the plot.  Structure of iris data set:\nclass(iris)  ## [1] \"data.frame\"  iris[1:4,]  ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa  table(iris$Species)  ## ## setosa versicolor virginica ## 50 50 50  Line Plots Single Data Set plot(y[,1], type=\"l\", lwd=2, col=\"blue\")  Many Data Sets Plots line graph for all columns in data frame y. The split.screen function is used in this example in a for loop to overlay several line graphs in the same plot.\nsplit.screen(c(1,1))  ## [1] 1  plot(y[,1], ylim=c(0,1), xlab=\"Measurement\", ylab=\"Intensity\", type=\"l\", lwd=2, col=1) for(i in 2:length(y[1,])) { screen(1, new=FALSE) plot(y[,i], ylim=c(0,1), type=\"l\", lwd=2, col=i, xaxt=\"n\", yaxt=\"n\", ylab=\"\", xlab=\"\", main=\"\", bty=\"n\") }  close.screen(all=TRUE)  Bar Plots Basics barplot(y[1:4,], ylim=c(0, max(y[1:4,])+0.3), beside=TRUE, legend=letters[1:4]) text(labels=round(as.vector(as.matrix(y[1:4,])),2), x=seq(1.5, 13, by=1) +sort(rep(c(0,1,2), 4)), y=as.vector(as.matrix(y[1:4,]))+0.04)  Error bars bar \u003c- barplot(m \u003c- rowMeans(y) * 10, ylim=c(0, 10)) stdev \u003c- sd(t(y)) arrows(bar, m, bar, m + stdev, length=0.15, angle = 90)  Mirrored bar plot df \u003c- data.frame(group = rep(c(\"Above\", \"Below\"), each=10), x = rep(1:10, 2), y = c(runif(10, 0, 1), runif(10, -1, 0))) plot(c(0,12),range(df$y),type = \"n\") barplot(height = df$y[df$group == \"Above\"], add = TRUE,axes = FALSE) barplot(height = df$y[df$group == \"Below\"], add = TRUE,axes = FALSE)  Histograms hist(y, freq=TRUE, breaks=10)  Density Plots} plot(density(y), col=\"red\")  Pie Charts pie(y[,1], col=rainbow(length(y[,1]), start=0.1, end=0.8), clockwise=TRUE) legend(\"topright\", legend=row.names(y), cex=1.3, bty=\"n\", pch=15, pt.cex=1.8, col=rainbow(length(y[,1]), start=0.1, end=0.8), ncol=1)  Color Selection Utilities Default color palette and how to change it\npalette()  ## [1] \"black\" \"#DF536B\" \"#61D04F\" \"#2297E6\" \"#28E2E5\" \"#CD0BBC\" \"#F5C710\" \"gray62\"  palette(rainbow(5, start=0.1, end=0.2)) palette()  ## [1] \"#FF9900\" \"#FFBF00\" \"#FFE600\" \"#F2FF00\" \"#CCFF00\"  palette(\"default\")  The gray function allows to select any type of gray shades by providing values from 0 to 1\ngray(seq(0.1, 1, by= 0.2))  ## [1] \"#1A1A1A\" \"#4D4D4D\" \"#808080\" \"#B3B3B3\" \"#E6E6E6\"  Color gradients with colorpanel function from gplots library\nlibrary(gplots) colorpanel(5, \"darkblue\", \"yellow\", \"white\")  Much more on colors in R see Earl Glynn’s color chart\nArranging Several Plots on Single Page With par(mfrow=c(nrow,ncol)) one can define how several plots are arranged next to each other.\npar(mfrow=c(2,3)); for(i in 1:6) { plot(1:10) }  Arranging Plots with Variable Width The layout function allows to divide the plotting device into variable numbers of rows and columns with the column-widths and the row-heights specified in the respective arguments.\nnf \u003c- layout(matrix(c(1,2,3,3), 2, 2, byrow=TRUE), c(3,7), c(5,5), respect=TRUE) # layout.show(nf) for(i in 1:3) { barplot(1:10) }  Saving Graphics to Files After the pdf() command all graphs are redirected to file test.pdf. Works for all common formats similarly: jpeg, png, ps, tiff, …\npdf(\"test.pdf\"); plot(1:10, 1:10); dev.off()  Generates Scalable Vector Graphics (SVG) files that can be edited in vector graphics programs, such as InkScape.\nsvg(\"test.svg\"); plot(1:10, 1:10); dev.off()  Exercise 2 Bar plots\n Task 1: Calculate the mean values for the Species components of the first four columns in the iris data set. Organize the results in a matrix where the row names are the unique values from the iris Species column and the column names are the same as in the first four iris columns. Task 2: Generate two bar plots: one with stacked bars and one with horizontally arranged bars.  Structure of iris data set:\nclass(iris)  ## [1] \"data.frame\"  iris[1:4,]  ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa  table(iris$Species)  ## ## setosa versicolor virginica ## 50 50 50  Grid Graphics  What is grid?  Low-level graphics system Highly flexible and controllable system Does not provide high-level functions Intended as development environment for custom plotting functions Pre-installed on new R distributions   Documentation and Help  Manual Book    lattice Graphics  What is lattice?  High-level graphics system Developed by Deepayan Sarkar Implements Trellis graphics system from S-Plus Simplifies high-level plotting tasks: arranging complex graphical features Syntax similar to R’s base graphics   Documentation and Help  Manual Intro Book    Open a list of all functions available in the lattice package\nlibrary(help=lattice)  Accessing and changing global parameters:\n?lattice.options ?trellis.device  Scatter Plot Sample library(lattice) p1 \u003c- xyplot(1:8 ~ 1:8 | rep(LETTERS[1:4], each=2), as.table=TRUE) plot(p1)  Line Plot Sample library(lattice) p2 \u003c- parallelplot(~iris[1:4] | Species, iris, horizontal.axis = FALSE, layout = c(1, 3, 1)) plot(p2)  ggplot2 Graphics  What is ggplot2?  High-level graphics system developed by Hadley Wickham Implements grammar of graphics from Leland Wilkinson Streamlines many graphics workflows for complex plots Syntax centered around main ggplot function Simpler qplot function provides many shortcuts   Documentation and Help  Manual Intro Book Cookbook for R    ggplot2 Usage  ggplot function accepts two arguments  Data set to be plotted Aesthetic mappings provided by aes function   Additional parameters such as geometric objects (e.g. points, lines, bars) are passed on by appending them with + as separator. List of available geom_* functions see here Settings of plotting theme can be accessed with the command theme_get() and its settings can be changed with theme(). Preferred input data object  qplot: data.frame or tibble (support for vector, matrix, ...) ggplot: data.frame or tibble   Packages with convenience utilities to create expected inputs  plyr reshape    qplot Function The syntax of qplot is similar as R’s basic plot function\n Arguments  x: x-coordinates (e.g. col1) y: y-coordinates (e.g. col2) data: data.frame or tibble with corresponding column names xlim, ylim: e.g. xlim=c(0,10) log: e.g. log=\"x\" or log=\"xy\" main: main title; see ?plotmath for mathematical formula xlab, ylab: labels for the x- and y-axes color, shape, size ...: many arguments accepted by plot function    qplot: scatter plot basics Create sample data\nlibrary(ggplot2) x \u003c- sample(1:10, 10); y \u003c- sample(1:10, 10); cat \u003c- rep(c(\"A\", \"B\"), 5)  Simple scatter plot\nqplot(x, y, geom=\"point\")  Prints dots with different sizes and colors\nqplot(x, y, geom=\"point\", size=x, color=cat, main=\"Dot Size and Color Relative to Some Values\")  Drops legend\nqplot(x, y, geom=\"point\", size=x, color=cat) + theme(legend.position = \"none\")  Plot different shapes\nqplot(x, y, geom=\"point\", size=5, shape=cat)  Colored groups p \u003c- qplot(x, y, geom=\"point\", size=x, color=cat, main=\"Dot Size and Color Relative to Some Values\") + theme(legend.position = \"none\") print(p)  Regression line set.seed(1410) dsmall \u003c- diamonds[sample(nrow(diamonds), 1000), ] p \u003c- qplot(carat, price, data = dsmall) + geom_smooth(method=\"lm\") print(p)  Local regression curve (loess) p \u003c- qplot(carat, price, data=dsmall, geom=c(\"point\", \"smooth\")) print(p) # Setting se=FALSE removes error shade  ggplot Function  More important than qplot to access full functionality of ggplot2 Main arguments  data set, usually a data.frame or tibble aesthetic mappings provided by aes function   General ggplot syntax  ggplot(data, aes(...)) + geom() + ... + stat() + ...   Layer specifications  geom(mapping, data, ..., geom, position) stat(mapping, data, ..., stat, position)   Additional components  scales coordinates facet   aes() mappings can be passed on to all components (ggplot, geom, etc.). Effects are global when passed on to ggplot() and local for other components.  x, y color: grouping vector (factor) group: grouping vector (factor)    Changing Plotting Themes in ggplot  Theme settings can be accessed with theme_get() Their settings can be changed with theme()  Example how to change background color to white\n... + theme(panel.background=element_rect(fill = \"white\", colour = \"black\"))  Storing ggplot Specifications Plots and layers can be stored in variables\np \u003c- ggplot(dsmall, aes(carat, price)) + geom_point() p # or print(p)  Returns information about data and aesthetic mappings followed by each layer\nsummary(p)  Print dots with different sizes and colors\nbestfit \u003c- geom_smooth(method = \"lm\", se = F, color = alpha(\"steelblue\", 0.5), size = 2) p + bestfit # Plot with custom regression line  Syntax to pass on other data sets\np %+% diamonds[sample(nrow(diamonds), 100),]  Saves plot stored in variable p to file\nggsave(p, file=\"myplot.pdf\")  ggplot: scatter plots Basic example set.seed(1410) dsmall \u003c- as.data.frame(diamonds[sample(nrow(diamonds), 1000), ]) p \u003c- ggplot(dsmall, aes(carat, price, color=color)) + geom_point(size=4) print(p)  Regression line p \u003c- ggplot(dsmall, aes(carat, price)) + geom_point() + geom_smooth(method=\"lm\", se=FALSE) + theme(panel.background=element_rect(fill = \"white\", colour = \"black\")) print(p)  Several regression lines p \u003c- ggplot(dsmall, aes(carat, price, group=color)) + geom_point(aes(color=color), size=2) + geom_smooth(aes(color=color), method = \"lm\", se=FALSE) print(p)  Local regression curve (loess) p \u003c- ggplot(dsmall, aes(carat, price)) + geom_point() + geom_smooth() print(p) # Setting se=FALSE removes error shade  ggplot: line plot p \u003c- ggplot(iris, aes(Petal.Length, Petal.Width, group=Species, color=Species)) + geom_line() print(p)  Faceting p \u003c- ggplot(iris, aes(Sepal.Length, Sepal.Width)) + geom_line(aes(color=Species), size=1) + facet_wrap(~Species, ncol=1) print(p)  Exercise 3 Scatter plots with ggplot2\n Task 1: Generate scatter plot for first two columns in iris data frame and color dots by its Species column. Task 2: Use the xlim and ylim arguments to set limits on the x- and y-axes so that all data points are restricted to the left bottom quadrant of the plot. Task 3: Generate corresponding line plot with faceting show individual data sets in saparate plots.  Structure of iris data set\nclass(iris)  ## [1] \"data.frame\"  iris[1:4,]  ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa  table(iris$Species)  ## ## setosa versicolor virginica ## 50 50 50  Bar Plots Sample Set: the following transforms the iris data set into a ggplot2-friendly format.\nCalculate mean values for aggregates given by Species column in iris data set\niris_mean \u003c- aggregate(iris[,1:4], by=list(Species=iris$Species), FUN=mean)  Calculate standard deviations for aggregates given by Species column in iris data set\niris_sd \u003c- aggregate(iris[,1:4], by=list(Species=iris$Species), FUN=sd)  Reformat iris_mean with melt\nlibrary(reshape2) # Defines melt function df_mean \u003c- melt(iris_mean, id.vars=c(\"Species\"), variable.name = \"Samples\", value.name=\"Values\")  Reformat iris_sd with melt\ndf_sd \u003c- melt(iris_sd, id.vars=c(\"Species\"), variable.name = \"Samples\", value.name=\"Values\")  Define standard deviation limits\nlimits \u003c- aes(ymax = df_mean[,\"Values\"] + df_sd[,\"Values\"], ymin=df_mean[,\"Values\"] - df_sd[,\"Values\"])  Verical orientation p \u003c- ggplot(df_mean, aes(Samples, Values, fill = Species)) + geom_bar(position=\"dodge\", stat=\"identity\") print(p)  To enforce that the bars are plotted in the order specified in the input data, one can instruct ggplot to do so by turning the corresponding column (here Species) into an ordered factor as follows.\ndf_mean$Species \u003c- factor(df_mean$Species, levels=unique(df_mean$Species), ordered=TRUE)  In the above example this is not necessary since ggplot uses this order already.\nHorizontal orientation p \u003c- ggplot(df_mean, aes(Samples, Values, fill = Species)) + geom_bar(position=\"dodge\", stat=\"identity\") + coord_flip() + theme(axis.text.y=element_text(angle=0, hjust=1)) print(p)  Faceting p \u003c- ggplot(df_mean, aes(Samples, Values)) + geom_bar(aes(fill = Species), stat=\"identity\") + facet_wrap(~Species, ncol=1) print(p)  Error bars p \u003c- ggplot(df_mean, aes(Samples, Values, fill = Species)) + geom_bar(position=\"dodge\", stat=\"identity\") + geom_errorbar(limits, position=\"dodge\") print(p)  Mirrored df \u003c- data.frame(group = rep(c(\"Above\", \"Below\"), each=10), x = rep(1:10, 2), y = c(runif(10, 0, 1), runif(10, -1, 0))) p \u003c- ggplot(df, aes(x=x, y=y, fill=group)) + geom_bar(stat=\"identity\", position=\"identity\") print(p)  Changing Color Settings library(RColorBrewer) # display.brewer.all() p \u003c- ggplot(df_mean, aes(Samples, Values, fill=Species, color=Species)) + geom_bar(position=\"dodge\", stat=\"identity\") + geom_errorbar(limits, position=\"dodge\") + scale_fill_brewer(palette=\"Blues\") + scale_color_brewer(palette = \"Greys\") print(p)  Using standard colors p \u003c- ggplot(df_mean, aes(Samples, Values, fill=Species, color=Species)) + geom_bar(position=\"dodge\", stat=\"identity\") + geom_errorbar(limits, position=\"dodge\") + scale_fill_manual(values=c(\"red\", \"green3\", \"blue\")) + scale_color_manual(values=c(\"red\", \"green3\", \"blue\")) print(p)  Exercise 4 Bar plots\n Task 1: Calculate the mean values for the Species components of the first four columns in the iris data set. Use the melt function from the reshape2 package to bring the data into the expected format for ggplot. Task 2: Generate two bar plots: one with stacked bars and one with horizontally arranged bars.  Structure of iris data set\nclass(iris)  ## [1] \"data.frame\"  iris[1:4,]  ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa  table(iris$Species)  ## ## setosa versicolor virginica ## 50 50 50  Data reformatting example Here for line plot\ny \u003c- matrix(rnorm(500), 100, 5, dimnames=list(paste(\"g\", 1:100, sep=\"\"), paste(\"Sample\", 1:5, sep=\"\"))) y \u003c- data.frame(Position=1:length(y[,1]), y) y[1:4, ] # First rows of input format expected by melt()  ## Position Sample1 Sample2 Sample3 Sample4 Sample5 ## g1 1 1.5336975 -1.0365027 -2.0276195 -0.4580396 -0.06460952 ## g2 2 -2.0960304 2.1878704 0.7260334 0.8274617 0.24192162 ## g3 3 -0.8233125 0.4250477 0.6526331 -0.4509962 -1.06778801 ## g4 4 1.0961555 0.8101104 -0.3403762 -0.7222191 -0.72737741  df \u003c- melt(y, id.vars=c(\"Position\"), variable.name = \"Samples\", value.name=\"Values\") p \u003c- ggplot(df, aes(Position, Values)) + geom_line(aes(color=Samples)) + facet_wrap(~Samples, ncol=1) print(p)  Same data can be represented in box plot as follows\nggplot(df, aes(Samples, Values, fill=Samples)) + geom_boxplot()  Jitter Plots p \u003c- ggplot(dsmall, aes(color, price/carat)) + geom_jitter(alpha = I(1 / 2), aes(color=color)) print(p)  Box plots p \u003c- ggplot(dsmall, aes(color, price/carat, fill=color)) + geom_boxplot() print(p)  Violin plots p \u003c- ggplot(dsmall, aes(color, price/carat, fill=color)) + geom_violin() print(p)  Density plots Line coloring p \u003c- ggplot(dsmall, aes(carat)) + geom_density(aes(color = color)) print(p)  Area coloring p \u003c- ggplot(dsmall, aes(carat)) + geom_density(aes(fill = color)) print(p)  Histograms p \u003c- ggplot(iris, aes(x=Sepal.Width)) + geom_histogram(aes(y = ..density.., fill = ..count..), binwidth=0.2) + geom_density() print(p)  Pie Chart df \u003c- data.frame(variable=rep(c(\"cat\", \"mouse\", \"dog\", \"bird\", \"fly\")), value=c(1,3,3,4,2)) p \u003c- ggplot(df, aes(x = \"\", y = value, fill = variable)) + geom_bar(width = 1, stat=\"identity\") + coord_polar(\"y\", start=pi / 3) + ggtitle(\"Pie Chart\") print(p)  Wind Rose Pie Chart p \u003c- ggplot(df, aes(x = variable, y = value, fill = variable)) + geom_bar(width = 1, stat=\"identity\") + coord_polar(\"y\", start=pi / 3) + ggtitle(\"Pie Chart\") print(p)  Arranging Graphics on Page Using grid package\nlibrary(grid) a \u003c- ggplot(dsmall, aes(color, price/carat)) + geom_jitter(size=4, alpha = I(1 / 1.5), aes(color=color)) b \u003c- ggplot(dsmall, aes(color, price/carat, color=color)) + geom_boxplot() c \u003c- ggplot(dsmall, aes(color, price/carat, fill=color)) + geom_boxplot() + theme(legend.position = \"none\") grid.newpage() # Open a new page on grid device pushViewport(viewport(layout = grid.layout(2, 2))) # Assign to device viewport with 2 by 2 grid layout print(a, vp = viewport(layout.pos.row = 1, layout.pos.col = 1:2)) print(b, vp = viewport(layout.pos.row = 2, layout.pos.col = 1)) print(c, vp = viewport(layout.pos.row = 2, layout.pos.col = 2, width=0.3, height=0.3, x=0.8, y=0.8))  Using gridExtra package\nlibrary(gridExtra) grid.arrange(a, b, c, nrow = 2, ncol=2)  Inserting Graphics into Plots library(grid) print(a) print(b, vp=viewport(width=0.3, height=0.3, x=0.8, y=0.8))  Specialty Graphics Venn Diagrams library(systemPipeR) setlist5 \u003c- list(A=sample(letters, 18), B=sample(letters, 16), C=sample(letters, 20), D=sample(letters, 22), E=sample(letters, 18)) OLlist5 \u003c- overLapper(setlist=setlist5, sep=\"_\", type=\"vennsets\") vennPlot(OLlist5, mymain=\"\", mysub=\"\", colmode=2, ccol=c(\"blue\", \"red\"))  Compound Structures Plots depictions of small molecules with ChemmineR package\nlibrary(ChemmineR) data(sdfsample) plot(sdfsample[1], print=FALSE)  ROC Plots A variety of libraries are available for plotting receiver operating characteristic (ROC) curves in R:\n ROCR ROC pROC ggplot2  Example Most commonly, in an ROC we plot the true positive rate (y-axis) against the false positive rate (x-axis) at decreasing thresholds. An illustrative example is provided in the ROCR package where one wants to inspect the content of the ROCR.simple object defining the structure of the input data in two vectors.\n# install.packages(\"ROCR\") # Install if necessary on your laptop library(ROCR) data(ROCR.simple) ROCR.simple  ## $predictions ## [1] 0.612547843 0.364270971 0.432136142 0.140291078 0.384895941 0.244415489 0.970641299 ## [8] 0.890172812 0.781781371 0.868751832 0.716680598 0.360168796 0.547983407 0.385240464 ## [15] 0.423739359 0.101699993 0.628095575 0.744769966 0.657732644 0.490119891 0.072369921 ## [22] 0.172741714 0.105722115 0.890078186 0.945548941 0.984667270 0.360180429 0.448687336 ## [29] 0.014823599 0.543533783 0.292368449 0.701561487 0.715459280 0.714985914 0.120604738 ## [36] 0.319672178 0.911723615 0.757325590 0.090988280 0.529402244 0.257402979 0.589909284 ## [43] 0.708412104 0.326672910 0.086546283 0.879459891 0.362693564 0.230157183 0.779771989 ## [50] 0.876086217 0.353281048 0.212014560 0.703293499 0.689075677 0.627012496 0.240911145 ## [57] 0.402801992 0.134794140 0.120473353 0.665444679 0.536339509 0.623494622 0.885179651 ## [64] 0.353777439 0.408939895 0.265686095 0.932159806 0.248500489 0.858876675 0.491735594 ## [71] 0.151350957 0.694457482 0.496513160 0.123504905 0.499788081 0.310718619 0.907651100 ## [78] 0.340078180 0.195097957 0.371936985 0.517308606 0.419560072 0.865639036 0.018527600 ## [85] 0.539086009 0.005422562 0.772728821 0.703885141 0.348213542 0.277656869 0.458674210 ## [92] 0.059045866 0.133257805 0.083685883 0.531958184 0.429650397 0.717845453 0.537091350 ## [99] 0.212404891 0.930846938 0.083048377 0.468610247 0.393378108 0.663367560 0.349540913 ## [106] 0.194398425 0.844415442 0.959417835 0.211378771 0.943432189 0.598162949 0.834803976 ## [113] 0.576836208 0.380396459 0.161874325 0.912325837 0.642933593 0.392173971 0.122284044 ## [120] 0.586857799 0.180631658 0.085993218 0.700501359 0.060413627 0.531464015 0.084254795 ## [127] 0.448484671 0.938583020 0.531006532 0.785213140 0.905121019 0.748438143 0.605235403 ## [134] 0.842974300 0.835981859 0.364288579 0.492596896 0.488179708 0.259278968 0.991096434 ## [141] 0.757364019 0.288258273 0.773336236 0.040906997 0.110241034 0.760726142 0.984599159 ## [148] 0.253271061 0.697235328 0.620501132 0.814586047 0.300973098 0.378092079 0.016694412 ## [155] 0.698826511 0.658692553 0.470206008 0.501489336 0.239143340 0.050999138 0.088450984 ## [162] 0.107031842 0.746588080 0.480100183 0.336592126 0.579511087 0.118555284 0.233160827 ## [169] 0.461150807 0.370549294 0.770178504 0.537336015 0.463227453 0.790240205 0.883431431 ## [176] 0.745110673 0.007746305 0.012653524 0.868331219 0.439399995 0.540221346 0.567043171 ## [183] 0.035815400 0.806543942 0.248707470 0.696702150 0.081439129 0.336315317 0.126480399 ## [190] 0.636728451 0.030235062 0.268138293 0.983494405 0.728536415 0.739554341 0.522384507 ## [197] 0.858970526 0.383807972 0.606960209 0.138387070 ## ## $labels ## [1] 1 1 0 0 0 1 1 1 1 0 1 0 1 0 0 0 1 1 1 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1 0 0 1 1 0 1 0 1 0 1 0 1 0 ## [48] 1 0 1 1 0 1 0 1 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 1 0 0 1 0 ## [95] 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 1 1 0 0 0 0 1 1 ## [142] 0 1 0 1 0 1 1 1 1 1 0 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 ## [189] 0 0 0 1 0 1 1 0 1 0 1 0  pred \u003c- prediction(ROCR.simple$predictions, ROCR.simple$labels) perf \u003c- performance( pred, \"tpr\", \"fpr\" ) plot(perf)  Obtain area under the curve (AUC)\nauc \u003c- performance( pred, \"tpr\", \"fpr\", measure = \"auc\") auc@y.values[[1]]  ## [1] 0.8341875  Trees The ape package provides many useful utilities for phylogenetic analysis and tree plotting. Another useful package for plotting trees is ggtree. The following example plots two trees face to face with links to identical leaf labels.\nlibrary(ape) tree1 \u003c- rtree(40) tree2 \u003c- rtree(20) association \u003c- cbind(tree2$tip.label, tree2$tip.label) cophyloplot(tree1, tree2, assoc = association, length.line = 4, space = 28, gap = 3)  Genome Graphics ggbio  What is ggbio?  A programmable genome browser environment   Genome broswer concepts  A genome browser is a visulalization tool for plotting different types of genomic data in separate tracks along chromosomes. The ggbio package (Yin, Cook, and Lawrence 2012) facilitates plotting of complex genome data objects, such as read alignments (SAM/BAM), genomic context/annotation information (gff/txdb), variant calls (VCF/BCF), and more. To easily compare these data sets, it extends the faceting facility of ggplot2 to genome browser-like tracks. Most of the core object types for handling genomic data with R/Bioconductor are supported: GRanges, GAlignments, VCF, etc. For more details, see Table 1.1 of the ggbio vignette here. ggbio’s convenience plotting function is autoplot. For more customizable plots, one can use the generic ggplot function. Apart from the standard ggplot2 plotting components, ggbio defines serval new components useful for genomic data visualization. A detailed list is given in Table 1.2 of the vignette here. Useful web sites: - ggbio manual  ggbio functions autoplot demo      Tracks: aligning plots along chromosomes library(ggbio) df1 \u003c- data.frame(time = 1:100, score = sin((1:100)/20)*10) p1 \u003c- qplot(data = df1, x = time, y = score, geom = \"line\") df2 \u003c- data.frame(time = 30:120, score = sin((30:120)/20)*10, value = rnorm(120-30 +1)) p2 \u003c- ggplot(data = df2, aes(x = time, y = score)) + geom_line() + geom_point(size = 2, aes(color = value)) tracks(time1 = p1, time2 = p2) + xlim(1, 40) + theme_tracks_sunset()  Plotting genomic ranges GRanges objects are essential for storing alignment or annotation ranges in R/Bioconductor. The following creates a sample GRanges object and plots its content.\nlibrary(GenomicRanges) set.seed(1); N \u003c- 100; gr \u003c- GRanges(seqnames = sample(c(\"chr1\", \"chr2\", \"chr3\"), size = N, replace = TRUE), IRanges(start = sample(1:300, size = N, replace = TRUE), width = sample(70:75, size = N,replace = TRUE)), strand = sample(c(\"+\", \"-\"), size = N, replace = TRUE), value = rnorm(N, 10, 3), score = rnorm(N, 100, 30), sample = sample(c(\"Normal\", \"Tumor\"), size = N, replace = TRUE), pair = sample(letters, size = N, replace = TRUE)) autoplot(gr, aes(color = strand, fill = strand), facets = strand ~ seqnames)  Plotting coverage autoplot(gr, aes(color = strand, fill = strand), facets = strand ~ seqnames, stat = \"coverage\")  Mirrored coverage pos \u003c- sapply(coverage(gr[strand(gr)==\"+\"]), as.numeric) pos \u003c- data.frame(Chr=rep(names(pos), sapply(pos, length)), Strand=rep(\"+\", length(unlist(pos))), Position=unlist(sapply(pos, function(x) 1:length(x))), Coverage=as.numeric(unlist(pos))) neg \u003c- sapply(coverage(gr[strand(gr)==\"-\"]), as.numeric) neg \u003c- data.frame(Chr=rep(names(neg), sapply(neg, length)), Strand=rep(\"-\", length(unlist(neg))), Position=unlist(sapply(neg, function(x) 1:length(x))), Coverage=-as.numeric(unlist(neg))) covdf \u003c- rbind(pos, neg) p \u003c- ggplot(covdf, aes(Position, Coverage, fill=Strand)) + geom_bar(stat=\"identity\", position=\"identity\") + facet_wrap(~Chr) p  Circular genome plots ggplot(gr) + layout_circle(aes(fill = seqnames), geom = \"rect\")  More complex circular example\nseqlengths(gr) \u003c- c(400, 500, 700) values(gr)$to.gr \u003c- gr[sample(1:length(gr), size = length(gr))] idx \u003c- sample(1:length(gr), size = 50) gr \u003c- gr[idx] ggplot() + layout_circle(gr, geom = \"ideo\", fill = \"gray70\", radius = 7, trackWidth = 3) + layout_circle(gr, geom = \"bar\", radius = 10, trackWidth = 4, aes(fill = score, y = score)) + layout_circle(gr, geom = \"point\", color = \"red\", radius = 14, trackWidth = 3, grid = TRUE, aes(y = score)) + layout_circle(gr, geom = \"link\", linked.to = \"to.gr\", radius = 6, trackWidth = 1)    Alignments and variants To make the following example work, please download and unpack this data archive containing GFF, BAM and VCF sample files.\nlibrary(rtracklayer); library(GenomicFeatures); library(Rsamtools); library(GenomicAlignments); library(VariantAnnotation) ga \u003c- readGAlignments(\"./data/SRR064167.fastq.bam\", use.names=TRUE, param=ScanBamParam(which=GRanges(\"Chr5\", IRanges(4000, 8000)))) p1 \u003c- autoplot(ga, geom = \"rect\") p2 \u003c- autoplot(ga, geom = \"line\", stat = \"coverage\") vcf \u003c- readVcf(file=\"data/varianttools_gnsap.vcf\", genome=\"ATH1\") p3 \u003c- autoplot(vcf[seqnames(vcf)==\"Chr5\"], type = \"fixed\") + xlim(4000, 8000) + theme(legend.position = \"none\", axis.text.y = element_blank(), axis.ticks.y=element_blank()) txdb \u003c- makeTxDbFromGFF(file=\"./data/TAIR10_GFF3_trunc.gff\", format=\"gff3\") p4 \u003c- autoplot(txdb, which=GRanges(\"Chr5\", IRanges(4000, 8000)), names.expr = \"gene_id\") tracks(Reads=p1, Coverage=p2, Variant=p3, Transcripts=p4, heights = c(0.3, 0.2, 0.1, 0.35)) + ylab(\"\")  Additional examples See autoplot demo here\nAdditional genome graphics  Gviz RCircos (Zhang, Meltzer, and Davis 2013) Genome Graphs genoPlotR  Genome Browser: IGV View genome data in IGV\n Download and open IGV Select in menu in top left corner A. thaliana (TAIR10) Upload the following indexed/sorted Bam files with File -\u003e Load from URL...  http://faculty.ucr.edu/~tgirke/HTML_Presentations/Manuals/Workshop_Dec_6_10_2012/Rrnaseq/results/SRR064154.fastq.bam http://faculty.ucr.edu/~tgirke/HTML_Presentations/Manuals/Workshop_Dec_6_10_2012/Rrnaseq/results/SRR064155.fastq.bam http://faculty.ucr.edu/~tgirke/HTML_Presentations/Manuals/Workshop_Dec_6_10_2012/Rrnaseq/results/SRR064166.fastq.bam http://faculty.ucr.edu/~tgirke/HTML_Presentations/Manuals/Workshop_Dec_6_10_2012/Rrnaseq/results/SRR064167.fastq.bam   To view area of interest, enter its coordinates Chr1:49,457-51,457 in position menu on top.    Create symbolic links For viewing BAM files in IGV as part of systemPipeR workflows.\n systemPipeR: utilities for building NGS analysis pipelines.  library(\"systemPipeR\") symLink2bam(sysargs=args, htmldir=c(\"~/.html/\", \"somedir/\"), urlbase=\"http://myserver.edu/~username/\", urlfile=\"IGVurl.txt\")  Controlling IGV from R Open IGV before running the following routine. Alternatively, open IGV from within R with startIGV(\"lm\") . Note this may not work on all systems.\nlibrary(SRAdb) myurls \u003c- readLines(\"http://biocluster.ucr.edu/~tgirke/Documents/R_BioCond/Samples/bam_urls.txt\") #startIGV(\"lm\") # opens IGV sock \u003c- IGVsocket() session \u003c- IGVsession(files=myurls, sessionFile=\"session.xml\", genome=\"A. thaliana (TAIR10)\") IGVload(sock, session) IGVgoto(sock, 'Chr1:45296-47019')  References Yin, T, D Cook, and M Lawrence. 2012. “Ggbio: An R Package for Extending the Grammar of Graphics for Genomic Data.” Genome Biol. 13 (8). https://doi.org/10.1186/gb-2012-13-8-r77.\n Zhang, H, P Meltzer, and S Davis. 2013. “RCircos: An R Package for Circos 2D Track Plots.” BMC Bioinformatics 14: 244–44. https://doi.org/10.1186/1471-2105-14-244.\n  ","categories":"","description":"","excerpt":"document.addEventListener(\"DOMContentLoaded\", function() { …","ref":"/manuals/rgraphics/rgraphics/","tags":"","title":"Graphics and Data Visualization in R"},{"body":"document.addEventListener(\"DOMContentLoaded\", function() { document.querySelector(\"h1\").className = \"title\"; });  document.addEventListener(\"DOMContentLoaded\", function() { var links = document.links; for (var i = 0, linksLength = links.length; i Introduction  What is Clustering?  Clustering is the classification of data objects into similarity groups (clusters) according to a defined distance measure. It is used in many fields, such as machine learning, data mining, pattern recognition, image analysis, genomics, systems biology, etc. Machine learning typically regards data clustering as a form of unsupervised learning.   Why Clustering and Data Mining in R?}  Efficient data structures and functions for clustering Reproducible and programmable Comprehensive set of clustering and machine learning libraries Integration with many other data analysis tools   Useful Links  Cluster Task Views Machine Learning Task Views UCR Manual    Data Preprocessing Data Transformations Choice depends on data set!\n Center and standardize  Center: subtract from each value the mean of the corresponding vector Standardize: devide by standard deviation   Result: Mean = 0 and STDEV = 1   Center and scale with the scale() function  Center: subtract from each value the mean of the corresponding vector Scale: divide centered vector by their root mean square (rms): [ x_{rms} = \\sqrt[]{\\frac{1}{n-1}\\sum_{i=1}^{n}{x_{i}{^2}}} ]   Result: Mean = 0 and STDEV = 1   Log transformation Rank transformation: replace measured values by ranks No transformation  Distance Methods List of most common ones!\n Euclidean distance for two profiles X and Y: [ d(X,Y) = \\sqrt[]{ \\sum_{i=1}^{n}{(x_{i}-y_{i})^2} }]  Disadvantages: not scale invariant, not for negative correlations   Maximum, Manhattan, Canberra, binary, Minowski, … Correlation-based distance: 1-r  Pearson correlation coefficient (PCC): $$r = \\frac{n\\sum_{i=1}^{n}{x_{i}y_{i}} - \\sum_{i=1}^{n}{x_{i}} \\sum_{i=1}^{n}{y_{i}}}{ \\sqrt[]{(\\sum_{i=1}^{n}{x_{i}^2} - (\\sum_{i=1}^{n}{x_{i})^2}) (\\sum_{i=1}^{n}{y_{i}^2} - (\\sum_{i=1}^{n}{y_{i})^2})} }$$  Disadvantage: outlier sensitive   Spearman correlation coefficient (SCC)  Same calculation as PCC but with ranked values!      There are many more distance measures\n If the distances among items are quantifiable, then clustering is possible. Choose the most accurate and meaningful distance measure for a given field of application. If uncertain then choose several distance measures and compare the results.  Cluster Linkage   Clustering Algorithms Hierarchical Clustering Overview of algorithm  Identify clusters (items) with closest distance Join them to new clusters Compute distance between clusters (items) Return to step 1  Hierarchical clustering: agglomerative Approach   Hierarchical Clustering with Heatmap    A heatmap is a color coded table. To visually identify patterns, the rows and columns of a heatmap are often sorted by hierarchical clustering trees. In case of gene expression data, the row tree usually represents the genes, the column tree the treatments and the colors in the heat table represent the intensities or ratios of the underlying gene expression data set.  Hierarchical Clustering Approaches  Agglomerative approach (bottom-up)  R functions: hclust() and agnes()   Divisive approach (top-down)  R function: diana()    Tree Cutting to Obtain Discrete Clusters  Node height in tree Number of clusters Search tree nodes by distance cutoff  Examples Using hclust and heatmap.2 library(gplots) y \u003c- matrix(rnorm(500), 100, 5, dimnames=list(paste(\"g\", 1:100, sep=\"\"), paste(\"t\", 1:5, sep=\"\"))) heatmap.2(y) # Shortcut to final result  Stepwise Approach with Tree Cutting ## Row- and column-wise clustering hr \u003c- hclust(as.dist(1-cor(t(y), method=\"pearson\")), method=\"complete\") hc \u003c- hclust(as.dist(1-cor(y, method=\"spearman\")), method=\"complete\") ## Tree cutting mycl \u003c- cutree(hr, h=max(hr$height)/1.5); mycolhc \u003c- rainbow(length(unique(mycl)), start=0.1, end=0.9); mycolhc \u003c- mycolhc[as.vector(mycl)] ## Plot heatmap mycol \u003c- colorpanel(40, \"darkblue\", \"yellow\", \"white\") # or try redgreen(75) heatmap.2(y, Rowv=as.dendrogram(hr), Colv=as.dendrogram(hc), col=mycol, scale=\"row\", density.info=\"none\", trace=\"none\", RowSideColors=mycolhc)  K-Means Clustering Overview of algorithm  Choose the number of k clusters Randomly assign items to the k clusters Calculate new centroid for each of the k clusters Calculate the distance of all items to the k centroids Assign items to closest centroid Repeat until clusters assignments are stable    Examples km \u003c- kmeans(t(scale(t(y))), 3) km$cluster  ## g1 g2 g3 g4 g5 g6 g7 g8 g9 g10 g11 g12 g13 g14 g15 g16 g17 g18 g19 g20 ## 2 3 1 1 1 1 1 3 3 3 3 1 1 2 3 3 3 2 1 3 ## g21 g22 g23 g24 g25 g26 g27 g28 g29 g30 g31 g32 g33 g34 g35 g36 g37 g38 g39 g40 ## 1 3 3 2 1 3 1 2 3 1 3 3 3 1 3 2 2 1 2 3 ## g41 g42 g43 g44 g45 g46 g47 g48 g49 g50 g51 g52 g53 g54 g55 g56 g57 g58 g59 g60 ## 1 1 3 3 3 3 1 1 2 1 2 2 3 1 3 2 1 1 2 3 ## g61 g62 g63 g64 g65 g66 g67 g68 g69 g70 g71 g72 g73 g74 g75 g76 g77 g78 g79 g80 ## 1 3 3 3 2 2 2 3 3 3 3 3 2 3 3 1 1 2 1 1 ## g81 g82 g83 g84 g85 g86 g87 g88 g89 g90 g91 g92 g93 g94 g95 g96 g97 g98 g99 g100 ## 1 2 1 2 1 1 3 3 1 3 1 3 3 2 2 1 3 2 2 2  Fuzzy C-Means Clustering  In contrast to strict (hard) clustering approaches, fuzzy (soft) clustering methods allow multiple cluster memberships of the clustered items (Hathaway, Bezdek, and Pal 1996). This is commonly achieved by assigning to each item a weight of belonging to each cluster. Thus, items at the edge of a cluster, may be in a cluster to a lesser degree than items at the center of a cluster. Typically, each item has as many coefficients (weights) as there are clusters that sum up for each item to one.  Examples Fuzzy Clustering with fanny library(cluster) # Loads the cluster library. fannyy \u003c- fanny(y, k=4, metric = \"euclidean\", memb.exp = 1.2) round(fannyy$membership, 2)[1:4,]  ## [,1] [,2] [,3] [,4] ## g1 0.57 0.08 0.14 0.21 ## g2 0.06 0.80 0.08 0.06 ## g3 0.08 0.39 0.15 0.38 ## g4 0.03 0.02 0.83 0.13  fannyy$clustering  ## g1 g2 g3 g4 g5 g6 g7 g8 g9 g10 g11 g12 g13 g14 g15 g16 g17 g18 g19 g20 ## 1 2 2 3 4 2 4 2 1 2 1 4 4 1 2 3 2 3 4 2 ## g21 g22 g23 g24 g25 g26 g27 g28 g29 g30 g31 g32 g33 g34 g35 g36 g37 g38 g39 g40 ## 4 2 2 4 4 3 3 1 2 4 1 1 2 2 2 1 1 4 4 2 ## g41 g42 g43 g44 g45 g46 g47 g48 g49 g50 g51 g52 g53 g54 g55 g56 g57 g58 g59 g60 ## 3 4 3 2 2 2 3 4 4 2 1 4 1 2 3 1 2 4 1 2 ## g61 g62 g63 g64 g65 g66 g67 g68 g69 g70 g71 g72 g73 g74 g75 g76 g77 g78 g79 g80 ## 3 3 3 1 1 4 4 2 2 2 1 3 1 2 3 4 2 1 3 3 ## g81 g82 g83 g84 g85 g86 g87 g88 g89 g90 g91 g92 g93 g94 g95 g96 g97 g98 g99 g100 ## 4 4 4 1 4 2 2 2 3 2 4 2 2 4 1 3 3 3 1 1  Principal Component Analysis (PCA) Principal components analysis (PCA) is a data reduction technique that allows to simplify multidimensional data sets to 2 or 3 dimensions for plotting purposes and visual variance analysis.\nBasic Steps  Center (and standardize) data First principal component axis  Across centroid of data cloud Distance of each point to that line is minimized, so that it crosses the maximum variation of the data cloud   Second principal component axis  Orthogonal to first principal component Along maximum variation in the data   First PCA axis becomes x-axis and second PCA axis y-axis Continue process until the necessary number of principal components is obtained    Example pca \u003c- prcomp(y, scale=T) summary(pca) # Prints variance summary for all principal components  ## Importance of components: ## PC1 PC2 PC3 PC4 PC5 ## Standard deviation 1.1151 1.0232 1.0133 0.9760 0.8545 ## Proportion of Variance 0.2487 0.2094 0.2054 0.1905 0.1460 ## Cumulative Proportion 0.2487 0.4581 0.6634 0.8540 1.0000  plot(pca$x, pch=20, col=\"blue\", type=\"n\") # To plot dots, drop type=\"n\" text(pca$x, rownames(pca$x), cex=0.8)  1st and 2nd principal components explain x% of variance in data.\nMultidimensional Scaling (MDS)  Alternative dimensionality reduction approach Represents distances in 2D or 3D space Starts from distance matrix (PCA uses data points)  Example The following example performs MDS analysis with cmdscale on the geographic distances among European cities.\nloc \u003c- cmdscale(eurodist) plot(loc[,1], -loc[,2], type=\"n\", xlab=\"\", ylab=\"\", main=\"cmdscale(eurodist)\") text(loc[,1], -loc[,2], rownames(loc), cex=0.8)  Biclustering Finds in matrix subgroups of rows and columns which are as similar as possible to each other and as different as possible to the remaining data points.\n   Unclustered ————————–\u003e Clustered\n Similarity Measures for Clusters  Compare the numbers of identical and unique item pairs appearing in cluster sets Achieved by counting the number of item pairs found in both clustering sets (a) as well as the pairs appearing only in the first (b) or the second (c) set. With this a similarity coefficient, such as the Jaccard index, can be computed. The latter is defined as the size of the intersect divided by the size of the union of two sample sets: a/(a+b+c). In case of partitioning results, the Jaccard Index measures how frequently pairs of items are joined together in two clustering data sets and how often pairs are observed only in one set. Related coefficient are the Rand Index and the Adjusted Rand Index. These indices also consider the number of pairs (d) that are not joined together in any of the clusters in both sets.  Example: Jaccard index for cluster sets The following imports the cindex() function and computes the Jaccard Index for two sample clusters.\nsource(\"http://faculty.ucr.edu/~tgirke/Documents/R_BioCond/My_R_Scripts/clusterIndex.R\") library(cluster); y \u003c- matrix(rnorm(5000), 1000, 5, dimnames=list(paste(\"g\", 1:1000, sep=\"\"), paste(\"t\", 1:5, sep=\"\"))); clarax \u003c- clara(y, 49); clV1 \u003c- clarax$clustering; clarax \u003c- clara(y, 50); clV2 \u003c- clarax$clustering ci \u003c- cindex(clV1=clV1, clV2=clV2, self=FALSE, minSZ=1, method=\"jaccard\") ci[2:3] # Returns Jaccard index and variables used to compute it  ## $variables ## a b c ## 8793 5814 5296 ## ## $Jaccard_Index ## [1] 0.4417927  Clustering cluster sets with Jaccard index The following example shows how one can cluster entire cluster result sets. First, 10 sample cluster results are created with Clara using k-values from 3 to 12. The results are stored as named clustering vectors in a list object. Then a nested sapply loop is used to generate a similarity matrix of Jaccard Indices for the clustering results. After converting the result into a distance matrix, hierarchical clustering is performed with hclust.}\nclVlist \u003c- lapply(3:12, function(x) clara(y[1:30, ], k=x)$clustering); names(clVlist) \u003c- paste(\"k\", \"=\", 3:12) d \u003c- sapply(names(clVlist), function(x) sapply(names(clVlist), function(y) cindex(clV1=clVlist[[y]], clV2=clVlist[[x]], method=\"jaccard\")[[3]])) hv \u003c- hclust(as.dist(1-d)) plot(as.dendrogram(hv), edgePar=list(col=3, lwd=4), horiz=T, main=\"Similarities of 10 Clara Clustering Results for k: 3-12\")   Remember: there are many additional clustering algorithms. Additional details can be found in the Clustering Section of the R/Bioconductor Manual.  Clustering Exercises Data Preprocessing Scaling ## Sample data set set.seed(1410) y \u003c- matrix(rnorm(50), 10, 5, dimnames=list(paste(\"g\", 1:10, sep=\"\"), paste(\"t\", 1:5, sep=\"\"))) dim(y)  ## [1] 10 5  ## Scaling yscaled \u003c- t(scale(t(y))) # Centers and scales y row-wise apply(yscaled, 1, sd)  ## g1 g2 g3 g4 g5 g6 g7 g8 g9 g10 ## 1 1 1 1 1 1 1 1 1 1  Distance Matrices Euclidean distance matrix dist(y[1:4,], method = \"euclidean\")  ## g1 g2 g3 ## g2 4.793697 ## g3 4.932658 6.354978 ## g4 4.033789 4.788508 1.671968  Correlation-based distance matrix Correlation matrix\nc \u003c- cor(t(y), method=\"pearson\") as.matrix(c)[1:4,1:4]  ## g1 g2 g3 g4 ## g1 1.00000000 -0.2965885 -0.00206139 -0.4042011 ## g2 -0.29658847 1.0000000 -0.91661118 -0.4512912 ## g3 -0.00206139 -0.9166112 1.00000000 0.7435892 ## g4 -0.40420112 -0.4512912 0.74358925 1.0000000  Correlation-based distance matrix\nd \u003c- as.dist(1-c) as.matrix(d)[1:4,1:4]  ## g1 g2 g3 g4 ## g1 0.000000 1.296588 1.0020614 1.4042011 ## g2 1.296588 0.000000 1.9166112 1.4512912 ## g3 1.002061 1.916611 0.0000000 0.2564108 ## g4 1.404201 1.451291 0.2564108 0.0000000  Hierarchical Clustering with hclust Hierarchical clustering with complete linkage and basic tree plotting\nhr \u003c- hclust(d, method = \"complete\", members=NULL) names(hr)  ## [1] \"merge\" \"height\" \"order\" \"labels\" \"method\" \"call\" ## [7] \"dist.method\"  par(mfrow = c(1, 2)); plot(hr, hang = 0.1); plot(hr, hang = -1)  Tree plotting I plot(as.dendrogram(hr), edgePar=list(col=3, lwd=4), horiz=T)  Tree plotting II The ape library provides more advanced features for tree plotting\nlibrary(ape) plot.phylo(as.phylo(hr), type=\"p\", edge.col=4, edge.width=2, show.node.label=TRUE, no.margin=TRUE)  Tree Cutting Accessing information in hclust objects\nhr  ## ## Call: ## hclust(d = d, method = \"complete\", members = NULL) ## ## Cluster method : complete ## Number of objects: 10  ## Print row labels in the order they appear in the tree hr$labels[hr$order]  ## [1] \"g10\" \"g3\" \"g4\" \"g2\" \"g9\" \"g6\" \"g7\" \"g1\" \"g5\" \"g8\"  Tree cutting with cutree\nmycl \u003c- cutree(hr, h=max(hr$height)/2) mycl[hr$labels[hr$order]]  ## g10 g3 g4 g2 g9 g6 g7 g1 g5 g8 ## 3 3 3 2 2 5 5 1 4 4  Heatmaps With heatmap.2 All in one step: clustering and heatmap plotting\nlibrary(gplots) heatmap.2(y, col=redgreen(75))  With pheatmap All in one step: clustering and heatmap plotting\nlibrary(pheatmap); library(\"RColorBrewer\") pheatmap(y, color=brewer.pal(9,\"Blues\"))  Customizing heatmaps Customizes row and column clustering and shows tree cutting result in row color bar. Additional color schemes can be found here.\nhc \u003c- hclust(as.dist(1-cor(y, method=\"spearman\")), method=\"complete\") mycol \u003c- colorpanel(40, \"darkblue\", \"yellow\", \"white\") heatmap.2(y, Rowv=as.dendrogram(hr), Colv=as.dendrogram(hc), col=mycol, scale=\"row\", density.info=\"none\", trace=\"none\", RowSideColors=as.character(mycl))  K-Means Clustering with PAM Runs K-means clustering with PAM (partitioning around medoids) algorithm and shows result in color bar of hierarchical clustering result from before.\nlibrary(cluster) pamy \u003c- pam(d, 4) (kmcol \u003c- pamy$clustering)  ## g1 g2 g3 g4 g5 g6 g7 g8 g9 g10 ## 1 2 3 3 4 4 4 4 2 3  heatmap.2(y, Rowv=as.dendrogram(hr), Colv=as.dendrogram(hc), col=mycol, scale=\"row\", density.info=\"none\", trace=\"none\", RowSideColors=as.character(kmcol))  K-Means Fuzzy Clustering Performs k-means fuzzy clustering\nlibrary(cluster) fannyy \u003c- fanny(d, k=4, memb.exp = 1.5) round(fannyy$membership, 2)[1:4,]  ## [,1] [,2] [,3] [,4] ## g1 1.00 0.00 0.00 0.00 ## g2 0.00 0.99 0.00 0.00 ## g3 0.02 0.01 0.95 0.03 ## g4 0.00 0.00 0.99 0.01  fannyy$clustering  ## g1 g2 g3 g4 g5 g6 g7 g8 g9 g10 ## 1 2 3 3 4 4 4 4 2 3  ## Returns multiple cluster memberships for coefficient above a certain ## value (here \u003e0.1) fannyyMA \u003c- round(fannyy$membership, 2) \u003e 0.10 apply(fannyyMA, 1, function(x) paste(which(x), collapse=\"_\"))  ## g1 g2 g3 g4 g5 g6 g7 g8 g9 g10 ## \"1\" \"2\" \"3\" \"3\" \"4\" \"4\" \"4\" \"2_4\" \"2\" \"3\"  Multidimensional Scaling (MDS) Performs MDS analysis on the geographic distances between European cities\nloc \u003c- cmdscale(eurodist) ## Plots the MDS results in 2D plot. The minus is required in this example to ## flip the plotting orientation. plot(loc[,1], -loc[,2], type=\"n\", xlab=\"\", ylab=\"\", main=\"cmdscale(eurodist)\") text(loc[,1], -loc[,2], rownames(loc), cex=0.8)  Principal Component Analysis (PCA) Performs PCA analysis after scaling the data. It returns a list with class prcomp that contains five components: (1) the standard deviations (sdev) of the principal components, (2) the matrix of eigenvectors (rotation), (3) the principal component data (x), (4) the centering (center) and (5) scaling (scale) used.\nlibrary(scatterplot3d) pca \u003c- prcomp(y, scale=TRUE) names(pca)  ## [1] \"sdev\" \"rotation\" \"center\" \"scale\" \"x\"  summary(pca) # Prints variance summary for all principal components.  ## Importance of components: ## PC1 PC2 PC3 PC4 PC5 ## Standard deviation 1.3611 1.1777 1.0420 0.69264 0.4416 ## Proportion of Variance 0.3705 0.2774 0.2172 0.09595 0.0390 ## Cumulative Proportion 0.3705 0.6479 0.8650 0.96100 1.0000  scatterplot3d(pca$x[,1:3], pch=20, color=\"blue\")  Additional Exercises See here\nVersion Information sessionInfo()  ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C LC_TIME=en_US.UTF-8 ## [4] LC_COLLATE=en_US.UTF-8 LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C LC_ADDRESS=C ## [10] LC_TELEPHONE=C LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] scatterplot3d_0.3-41 RColorBrewer_1.1-2 pheatmap_1.0.12 cluster_2.1.1 ## [5] gplots_3.1.1 ape_5.4-1 ggplot2_3.3.2 BiocStyle_2.18.0 ## ## loaded via a namespace (and not attached): ## [1] Rcpp_1.0.5 pillar_1.4.7 compiler_4.0.4 BiocManager_1.30.10 ## [5] bitops_1.0-6 tools_4.0.4 digest_0.6.27 evaluate_0.14 ## [9] lifecycle_0.2.0 tibble_3.0.4 gtable_0.3.0 nlme_3.1-149 ## [13] lattice_0.20-41 pkgconfig_2.0.3 rlang_0.4.8 yaml_2.2.1 ## [17] parallel_4.0.4 blogdown_1.1.7 xfun_0.20 withr_2.3.0 ## [21] stringr_1.4.0 dplyr_1.0.2 knitr_1.30 caTools_1.18.1 ## [25] gtools_3.8.2 generics_0.1.0 vctrs_0.3.5 grid_4.0.4 ## [29] tidyselect_1.1.0 glue_1.4.2 R6_2.5.0 rmarkdown_2.5 ## [33] bookdown_0.21 purrr_0.3.4 magrittr_2.0.1 codetools_0.2-18 ## [37] scales_1.1.1 ellipsis_0.3.1 htmltools_0.5.1.1 colorspace_2.0-0 ## [41] KernSmooth_2.23-18 stringi_1.5.3 munsell_0.5.0 crayon_1.3.4  References Hathaway, R J, J C Bezdek, and N R Pal. 1996. “Sequential Competitive Learning and the Fuzzy c-Means Clustering Algorithms.” Neural Netw. 9 (5): 787–96. http://www.hubmed.org/display.cgi?uids=12662563.\n  ","categories":"","description":"","excerpt":"document.addEventListener(\"DOMContentLoaded\", function() { …","ref":"/manuals/rclustering/rclustering/","tags":"","title":"Cluster Analysis in R"},{"body":"","categories":"","description":"","excerpt":"","ref":"/manuals/","tags":"","title":"Manuals"},{"body":"","categories":"","description":"","excerpt":"","ref":"/blog/news/","tags":"","title":"News"},{"body":"\n\n Teaching material will be posted one day before each class meeting.\n [ Download ]\n ","categories":"","description":"","excerpt":"\n\n Teaching material will be posted one day before each class meeting. …","ref":"/slides/slides_01/","tags":"","title":"Course Introduction"},{"body":"\n\n [ Download ]\n","categories":"","description":"","excerpt":"\n\n [ Download ]\n","ref":"/slides/slides_02/","tags":"","title":"Genome Basics"},{"body":"\n\n [ Download ]\n","categories":"","description":"","excerpt":"\n\n [ Download ]\n","ref":"/slides/slides_03/","tags":"","title":"Databases and Software"},{"body":"\n\n [ Download ]\n","categories":"","description":"","excerpt":"\n\n [ Download ]\n","ref":"/slides/slides_04/","tags":"","title":"Sequencing Technologies"},{"body":"\n\n [ Download ]\n\n  \nThis is a test for an HTML slide show. Please ignore…\n[ View Slides in Separate Browser Tab ]\n  ","categories":"","description":"","excerpt":"\n\n [ Download ]\n\n  \nThis is a test for an HTML slide show. Please …","ref":"/slides/slides_05/","tags":"","title":"Introduction to R"},{"body":"\n\nSlide show to be posted.\n[ Download ]\n","categories":"","description":"","excerpt":"\n\nSlide show to be posted.\n[ Download ]\n","ref":"/slides/slides_06/","tags":"","title":"Sequence Alignments and Similarity Searching"},{"body":"\n\nSlide show to be posted.\n[ Download ]\n","categories":"","description":"","excerpt":"\n\nSlide show to be posted.\n[ Download ]\n","ref":"/slides/slides_07/","tags":"","title":"Programming in R"},{"body":"\n\nSlide show to be posted.\n[ Download ]\n","categories":"","description":"","excerpt":"\n\nSlide show to be posted.\n[ Download ]\n","ref":"/slides/slides_08/","tags":"","title":"Multiple Alignments"},{"body":"\n\nSlide show to be posted.\n[ Download ]\n","categories":"","description":"","excerpt":"\n\nSlide show to be posted.\n[ Download ]\n","ref":"/slides/slides_09/","tags":"","title":"Short Read Alignments"},{"body":"\n\nSlide show to be posted.\n[ Download ]\n","categories":"","description":"","excerpt":"\n\nSlide show to be posted.\n[ Download ]\n","ref":"/slides/slides_10/","tags":"","title":"NGS Analysis Basics"},{"body":"\n\nSlide show to be posted.\n[ Download ]\n","categories":"","description":"","excerpt":"\n\nSlide show to be posted.\n[ Download ]\n","ref":"/slides/slides_11/","tags":"","title":"Analysis of Gene Expression Data"},{"body":"\n\nSlide show to be posted.\n[ Download ]\n","categories":"","description":"","excerpt":"\n\nSlide show to be posted.\n[ Download ]\n","ref":"/slides/slides_12/","tags":"","title":"Introduction to NGS Workflows"},{"body":"\n\nSlide show to be posted.\n[ Download ]\n","categories":"","description":"","excerpt":"\n\nSlide show to be posted.\n[ Download ]\n","ref":"/slides/slides_13/","tags":"","title":"RNA-Seq Overview"},{"body":"\n\nSlide show to be posted.\n[ Download ]\n","categories":"","description":"","excerpt":"\n\nSlide show to be posted.\n[ Download ]\n","ref":"/slides/slides_14/","tags":"","title":"scRNA-Seq Overview"},{"body":"\n\nSlide show to be posted.\n[ Download ]\n","categories":"","description":"","excerpt":"\n\nSlide show to be posted.\n[ Download ]\n","ref":"/slides/slides_15/","tags":"","title":"ChIP-Seq Overview"},{"body":"\n\nSlide show to be posted.\n[ Download ]\n","categories":"","description":"","excerpt":"\n\nSlide show to be posted.\n[ Download ]\n","ref":"/slides/slides_16/","tags":"","title":"VAR-Seq Overview"},{"body":"\n\nSlide show to be posted.\n[ Download ]\n","categories":"","description":"","excerpt":"\n\nSlide show to be posted.\n[ Download ]\n","ref":"/slides/slides_17/","tags":"","title":"Gene Annotation, Ontologies and Enrichment Methods"},{"body":"\n\nSlide show to be posted.\n[ Download ]\n","categories":"","description":"","excerpt":"\n\nSlide show to be posted.\n[ Download ]\n","ref":"/slides/slides_18/","tags":"","title":"Assembly of Genomes and Transcriptomes"},{"body":"\n\nSlide show to be posted.\n[ Download ]\n","categories":"","description":"","excerpt":"\n\nSlide show to be posted.\n[ Download ]\n","ref":"/slides/slides_19/","tags":"","title":"Cluster Analysis"},{"body":"\n\nTutorial to be posted.\n","categories":"","description":"","excerpt":"\n\nTutorial to be posted.\n","ref":"/tutorials/tutorial_03/","tags":"","title":"Introduction to R"},{"body":"\n\nTutorial to be posted.\n","categories":"","description":"","excerpt":"\n\nTutorial to be posted.\n","ref":"/tutorials/tutorial_04/","tags":"","title":"Programming in R"},{"body":"\n\nTutorial to be posted.\n","categories":"","description":"","excerpt":"\n\nTutorial to be posted.\n","ref":"/tutorials/tutorial_05/","tags":"","title":"NGS Analysis Basics"},{"body":"\n\nTutorial to be posted.\n","categories":"","description":"","excerpt":"\n\nTutorial to be posted.\n","ref":"/tutorials/tutorial_06/","tags":"","title":"RNA-Seq Workflow"},{"body":"\n\nTutorial to be posted.\n","categories":"","description":"","excerpt":"\n\nTutorial to be posted.\n","ref":"/tutorials/tutorial_07/","tags":"","title":"scRNA-Seq Workflow"},{"body":"\n\nTutorial to be posted.\n","categories":"","description":"","excerpt":"\n\nTutorial to be posted.\n","ref":"/tutorials/tutorial_08/","tags":"","title":"ChIP-Seq Workflow"},{"body":"\n\nTutorial to be posted.\n","categories":"","description":"","excerpt":"\n\nTutorial to be posted.\n","ref":"/tutorials/tutorial_09/","tags":"","title":"VAR-Seq Workflow"},{"body":"\n\nTutorial to be posted.\n","categories":"","description":"","excerpt":"\n\nTutorial to be posted.\n","ref":"/tutorials/tutorial_10/","tags":"","title":"Graphics and Visualization"},{"body":"\n\nTutorial to be posted.\n","categories":"","description":"","excerpt":"\n\nTutorial to be posted.\n","ref":"/tutorials/tutorial_11/","tags":"","title":"Cluster Analysis and Data Mining"},{"body":"The homework assignments will be posted in this section.\n","categories":"","description":"","excerpt":"The homework assignments will be posted in this section.\n","ref":"/assignments/homework/","tags":"","title":"Homework Assignments"},{"body":"A. Online Excercise: Databases and Software Tools This is an easy warm-up homework exposing students to a variety of online databases and software tools.\n Go to http://www.ncbi.nlm.nih.gov, select Protein database in dropdown, and then run query: P450 \u0026 hydroxylase \u0026 human [organism], select under Source databases UniProtKB/Swiss-Prot  Report final query syntax from Search Details field.    \nSave GIs of the final query result to a file. For this select under Send to dropdown GI List format.  Report the number of retrieved GIs.    \nRetrieve the corresponding sequences through Batch-Entrez using GI list file as query input -\u003e save sequences in FASTA format  \nGenerate multiple alignment and tree of these sequences using MultAalin  Save multiple alignment and tree to file Identify putative heme binding cysteine in multiple alignment    \nOpen corresponding UniProt page and search for first P450 sequence in your list.  Compare putative heme binding cysteine with consensus pattern from Prosite database (Syntax) Report corresponding Pfam ID    \nBLASTP against PDF database (use again first P450 in your list); on result page click first entry in BLAST hit list (here 3K9V_A); then select ‘Identify Conserved Domains’ on side bar; click blue bar labelled ‘CYP24A1’; then select ‘Interactive View’ which will download ‘cd20645.cn3’ file.  Compare resulting alignment with result from MultAlin View 3D structure in Cn3D*, save structure (screen shot) and highlight heme binding cysteine. Note, Cn3D* can be downloaded from here.    *If there are problems in the last step (6.2) with the install of Cn3D, then please use this online only alternative: (i) click in the 3K9V_A page ‘Protein 3D Structure’ instead of ‘Identify Conserved Domains’; (ii) choose one of the two structure entries provided on the subsequent page; (iii) select option “full-featured 3D viewer” in the bottom right corner of the structure image; (iv) choose the ‘Details’ tab on the right; (v) after this the structure of the protein is shown on the left and the underlying protein sequence on the right; (vi) highlight the heme binding cysteine in the structure by selecting it in the sequence; and (vii) then save the structure view to a PNG file or take a screenshot.\nB. Homework Submission to a Private GitHub Repository To learn the basics of GitHub, this homework assignment will be uploaded to a private GitHub respository that will be shared with the instructors. To do so, follow these steps: In this homework, you are asked to create a github private repository.\n Login to your GitHub account. Click the “New” button in the sidebar on the left. Under “Repository name”, use “learn-github” as the name. Choose “Private”. Choose to add a README file (optional). Click “Create repository”. You should redirected to your new repo’s page. In the new page, click “Settings”. Click “Manage access”, and the choose “Invite a collaborator”. Invite both “tgirke” and “lz100” and send out the invitation.   Note, the creator of this demo cannot search for an invitation created by the same user (here lz100). Thus, the message ‘could not find lz100’ at the end of the video. This will not be the case for students in the class.\nPlease assemble the results of part A of HW1 in one PDF file named hw1.pdf and upload it to your private GitHub repository generated in part B. To do so, follow the upload instructions here.\nC. Homework Submission via GitHub Classroom To also submit your homework to GitHub Classroom click this link to accept the homework. This will create a private homework repository in GitHub Classroom for you. Note: this new repository is different from the repository in part A. It belongs to the GEN242-2021 Github classroom that will be used for all subsequent homework submissions.\nDue date Most homework will be due one week after they are assigned. This one is due on Thu, April 8th at 6:00 PM. You have unlimited attempts. Students can edit and re-upload files anytime before the deadline.\nHomework solution A solution for this homework is not required since the tasks are identical to the steps described above under sections HW1A-B.\n","categories":"","description":"","excerpt":"A. Online Excercise: Databases and Software Tools This is an easy …","ref":"/assignments/homework/hw01/hw01/","tags":"","title":"HW1 - Online Exercise and Basic GitHub Usage"},{"body":"Topic: Linux Basics   Download code from this page\nwget https://cluster.hpcc.ucr.edu/~tgirke/Linux.sh --no-check-certificate    Download Halobacterium proteome and inspect it\nwget https://ftp.ncbi.nlm.nih.gov/genomes/genbank/archaea/Halobacterium_salinarum/representative/GCA_004799605.1_ASM479960v1/GCA_004799605.1_ASM479960v1_protein.faa.gz gunzip GCA_004799605.1_ASM479960v1_protein.faa.gz mv GCA_004799605.1_ASM479960v1_protein.faa halobacterium.faa less halobacterium.faa # press q to quit    How many protein sequences are stored in the downloaded file?\ngrep '\u003e' halobacterium.faa | wc grep '^\u003e' halobacterium.faa --count    How many proteins contain the pattern WxHxxH or WxHxxHH?\negrep 'W.H..H{1,2}' halobacterium.faa --count    Use less to find IDs for pattern matches or use awk\nawk --posix -v RS='\u003e' '/W.H..(H){1,2}/ { print \"\u003e\" $0;}' halobacterium.faa | less awk --posix -v RS='\u003e' '/W.H..(H){1,2}/ { print \"\u003e\" $0;}' halobacterium.faa | grep '^\u003e' | cut -c 2- | cut -f 1 -d\\ \u003e myIDs    Create a BLASTable database with formatdb\nmodule load ncbi-blast makeblastdb -in halobacterium.faa -out halobacterium.faa -dbtype prot -hash_index -parse_seqids    Query BLASTable database by IDs stored in a file (e.g. myIDs)\nblastdbcmd -db halobacterium.faa -dbtype prot -entry_batch myIDs -get_dups -out myseq.fasta    Run BLAST search for sequences stored in myseq.fasta\nblastp -query myseq.fasta -db halobacterium.faa -outfmt 0 -evalue 1e-6 -out blastp.out blastp -query myseq.fasta -db halobacterium.faa -outfmt 6 -evalue 1e-6 -out blastp.tab    Return system time and host name\ndate hostname    Additional exercise material in Linux Manual\nHomework assignment Perform above analysis on the protein sequences from E. coli. A right click on the link will allow you to copy the URL so that it can be used together with wget. Record result from final BLAST command (with outfmt 6) in text file.\nHomework submission Submit your homework to GEN242-2021 HW2 on GitHub Classroom by following these stepwise instructions:\n Upload your script and name it hw2.sh. Upload the unzipped faa file from step 1, name it ecoli.faa. Upload IDs from step 5 in a file named myIDs. Upload the final file generated with outfmt 6 from step 8, and name it ecoli.txt.  Due date Most homeworks will be due one week after they are assigned. This one is due on Thu, April 8th at 6:00 PM.\nHomework solution See here.\n","categories":"","description":"","excerpt":"Topic: Linux Basics   Download code from this page\nwget …","ref":"/assignments/homework/hw02/hw02/","tags":"","title":"HW2 - Introduction to Biocluster and Linux"},{"body":"A. Object Subsetting, Import and Export  Task 1: Sort the rows of the iris data frame by its first column and sort its columns alphabetically by column names. Task 2: Subset the first 12 rows, export the result to a text file and view it in a spreadsheet program like Excel or Google Sheets. Task 3: Change some column titles in your spreadsheet program, save the result to a tab delimited text file and import it back into R. Note, for this task you only want to include the read.table command in the homework result (here R script).  Before you start it can be helpful to evaluate the structure of the iris data set with the following commands:\nclass(iris) dim(iris) colnames(iris)  B. Scatter Plots  Task 1: Generate a scatter plot for the first two columns of the iris data frame and color the dots by the Species column. Task 2: Use the xlim/ylim arguments to set limits on the x- and y-axes so that all data points are restricted to the bottom left quadrant of the plot.  Again before you start, evaluate the structure of iris data set. The following commands are useful:\niris[1:4,] table(iris$Species)  C. Bar Plots  Task 1: Calculate the mean values for the Species components of the first four columns in the iris data frame. Organize the results in a matrix where the row names are the unique values from the iris Species column and the column names are the names of the first four iris columns. Task 2: Generate two bar plots for the matrix generated in the previous step: one with stacked bars and one with horizontally arranged bars.  D-H. Analysis Worflow The instructions for these homework assignments are here.\nHomework submission Accept the homework3 on Github classroom, and follow the upload instructions in the README.md.\n Use the hw3_template.R script, finish the code in there and rename it hw3.R. Upload your two plots from part B and name it plot3B_1.png and plot3B_2.png. Upload your two plots from part C and name it plot3C_1.png and plot3C_2.png.  Due date This homework is due on Thu, April 15th at 6:00 PM.\nHomework Solutions to be posted\n","categories":"","description":"","excerpt":"A. Object Subsetting, Import and Export  Task 1: Sort the rows of the …","ref":"/assignments/homework/hw03/hw03/","tags":"","title":"HW3 - Introduction to R"},{"body":"\n\nHW to be posted.\n","categories":"","description":"","excerpt":"\n\nHW to be posted.\n","ref":"/assignments/homework/hw4/","tags":"","title":"Homework 4"},{"body":"\n\nHW to be posted.\n","categories":"","description":"","excerpt":"\n\nHW to be posted.\n","ref":"/assignments/homework/hw5/","tags":"","title":"Homework 5"},{"body":"Projects will be posted here.\n","categories":"","description":"","excerpt":"Projects will be posted here.\n","ref":"/assignments/projects/","tags":"","title":"Projects"},{"body":"\n\nProject to be posted.\n","categories":"","description":"","excerpt":"\n\nProject to be posted.\n","ref":"/assignments/projects/project_01/","tags":"","title":"Project 1"},{"body":"\n\nRNA-Seq Workflow  Read quality assessment, filtering and trimming Map reads against reference genome Perform read counting for required ranges (e.g. exonic gene ranges) Normalization of read counts Identification of differentially expressed genes (DEGs) Clustering of gene expression profiles Gene set enrichment analysis  Challenge Project: Comparison of DEG analysis methods  Run workflow from start to finish (steps 1-7) on RNA-Seq data set from Howard et al. (2013) Challenge project tasks  Each student compares at least 2 RNA-Seq DEG analysis methods (e.g. edgeR vs baySeq and DESeq2 vs limma/voom) and assesses the results as follows:  Analyze the similarities and differences in the DEG lists obtained from the two methods Does it affect the results from the downstream gene set enrichment analysis? Plot the performance of the DEG methods in form of an ROC curve. The DEG set from the Howard et al., 2013 paper could be used as benchmark (true result).      References  Howard, B.E. et al., 2013. High-throughput RNA sequencing of pseudomonas-infected Arabidopsis reveals hidden transcriptome complexity and novel splice variants. PloS one, 8(10), p.e74183. PubMed Guo Y, Li C-I, Ye F, Shyr Y (2013) Evaluation of read count based RNAseq analysis methods. BMC Genomics 14 Suppl 8: S2 PubMed Hardcastle TJ, Kelly KA (2010) baySeq: empirical Bayesian methods for identifying differential expression in sequence count data. BMC Bioinformatics 11: 422 PubMed Liu R, Holik AZ, Su S, Jansz N, Chen K, Leong HS, Blewitt ME, Asselin-Labat M-L, Smyth GK, Ritchie ME (2015) Why weight? Modelling sample and observational level variability improves power in RNA-seq analyses. Nucleic Acids Res. doi: 10.1093/nar/gkv412. PubMed Love MI, Huber W, Anders S (2014) Moderated estimation of fold change and dispersion for RNA-seq data with DESeq2. Genome Biol 15: 550 PubMed Zhou X, Lindsay H, Robinson MD (2014) Robustly detecting differential expression in RNA sequencing data using observation weights. Nucleic Acids Res 42: e91 PubMed  ","categories":"","description":"","excerpt":"\n\nRNA-Seq Workflow  Read quality assessment, filtering and trimming …","ref":"/assignments/projects/project_02/","tags":"","title":"RNA-Seq - Comparison of DEG analysis methods"},{"body":"\n\nProject to be posted.\n","categories":"","description":"","excerpt":"\n\nProject to be posted.\n","ref":"/assignments/projects/project_03/","tags":"","title":"Project 3"},{"body":"\n\nProject to be posted.\n","categories":"","description":"","excerpt":"\n\nProject to be posted.\n","ref":"/assignments/projects/project_04/","tags":"","title":"Project 4"},{"body":"\n\nProject to be posted.\n","categories":"","description":"","excerpt":"\n\nProject to be posted.\n","ref":"/assignments/projects/project_05/","tags":"","title":"Project 5"},{"body":"Presentation will be posted here.\n","categories":"","description":"","excerpt":"Presentation will be posted here.\n","ref":"/assignments/presentations/","tags":"","title":"Project and Paper Presentations"},{"body":"\n\nPresentation to be posted.\n","categories":"","description":"","excerpt":"\n\nPresentation to be posted.\n","ref":"/assignments/presentations/presentation_01/","tags":"","title":"Presentation 1"},{"body":"\n\nPresentation to be posted.\n","categories":"","description":"","excerpt":"\n\nPresentation to be posted.\n","ref":"/assignments/presentations/presentation_02/","tags":"","title":"Presentation 2"},{"body":"\n\nPresentation to be posted.\n","categories":"","description":"","excerpt":"\n\nPresentation to be posted.\n","ref":"/assignments/presentations/presentation_03/","tags":"","title":"Presentation 3"},{"body":"\n\nPresentation to be posted.\n","categories":"","description":"","excerpt":"\n\nPresentation to be posted.\n","ref":"/assignments/presentations/presentation_04/","tags":"","title":"Presentation 4"},{"body":"\n\nPresentation to be posted.\n","categories":"","description":"","excerpt":"\n\nPresentation to be posted.\n","ref":"/assignments/presentations/presentation_05/","tags":"","title":"Presentation 5"},{"body":"Suggestions  Single cell profiling (e.g. scRNA-Seq) Comparative genomics (e.g. ortholog assignments and/or assembly) Tool development (e.g. design of Shiny Apps)  ","categories":"","description":"...","excerpt":"...","ref":"/blog/2021/03/11/special-topics/","tags":"","title":"Special Topics"},{"body":"Welcome to GEN242 - Spring 2021  Due to COVID-19 restrictions, this class will be instructed entirely online via Zoom. The Zoom URLs for lectures, discussion sections and office hours will be provided shortly before the class starts. First Lecture: 02:00-03:20 PM, Tue, March 30, 2021  ","categories":"","description":"...","excerpt":"...","ref":"/blog/2021/02/13/first-day-of-instructions/","tags":"","title":"First Day of Instructions"},{"body":"","categories":"","description":"","excerpt":"","ref":"/about/","tags":"","title":"About GEN242"},{"body":"","categories":"","description":"","excerpt":"","ref":"/assignments/","tags":"","title":"Assignments"},{"body":"  #td-cover-block-0 { background-image: url(\"background.jpg\") }  Data Analysis in Genome Biology  --  About Course  Piazza   Instructors     GEN242 is a graduate class taught at the University of California, Riverside         Overview This course introduces algorithms, statistical methods and data analysis programming routines relevant for genome biology. It consists of three main components: lectures, hands-on practicals and student course projects. The lecture topics cover databases, sequence (NGS) analysis, phylogenetics, comparative genomics, genome-wide profiling methods, network biology and more. The hands-on practicals include homework assignments and course projects focusing on data analysis programming of next generation genome data using command-line tools on a computer cluster and the programming environment R. Depending on student interests, one or more specialty topics may be included, such as the analysis of single cell (e.g. scRNA-Seq) experiments, multi-omics data, or the development of web-based analysis tools (e.g. Shiny Apps).  Who should take this class? Students with a strong interest and motivation in acquiring the skills required for mastering the computational aspects of modern genome research. The class is mainly targeting graduate students but senior undergraduate students are welcome to enroll as well. The main audience of this class are usually students from bioscience, biomedical and bioengineering programs as well as CS and statistics students with interest in computational biology.  Can I audit this class? It is possible to audit this class. However, due to the emphasis on active participation in practicals and course projects, students usually learn much more if they enroll into the class rather than auditing it in a passive manner.      University of California, Riverside    ","categories":"","description":"","excerpt":"  #td-cover-block-0 { background-image: url(\"background.jpg\") }  Data …","ref":"/","tags":"","title":"GEN242"},{"body":"","categories":"","description":"The pages under this _Internal Section_ provide information about internal resources that are mainly relevant for the instructor(s) of this class.","excerpt":"The pages under this _Internal Section_ provide information about …","ref":"/about/internal/","tags":"","title":"Internal Resources"},{"body":"This is the blog section. It has two categories: News and Releases.\nFiles in these directories will be listed in reverse chronological order.\n","categories":"","description":"","excerpt":"This is the blog section. It has two categories: News and Releases. …","ref":"/blog/","tags":"","title":"GEN242 News"},{"body":"This page provides URLs to external resources  Piazza GitHub Repo Bioconductor Hugo, Docsy and R  ","categories":"","description":"","excerpt":"This page provides URLs to external resources  Piazza GitHub Repo …","ref":"/external_resources/","tags":"","title":"Links"},{"body":"","categories":"","description":"","excerpt":"","ref":"/search/","tags":"","title":"Search Results"},{"body":"","categories":"","description":"","excerpt":"","ref":"/slides/","tags":"","title":"Slides"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tutorials/","tags":"","title":"Tutorials"}]